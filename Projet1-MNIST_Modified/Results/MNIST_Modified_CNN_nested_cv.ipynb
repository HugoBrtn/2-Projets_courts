{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "afcc3634",
      "metadata": {
        "id": "afcc3634"
      },
      "source": [
        "## 0 - Librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "66c334b9",
      "metadata": {
        "id": "66c334b9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential, clone_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.layers import RandomRotation, RandomTranslation, RandomZoom, RandomBrightness\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "from tensorflow.config import run_functions_eagerly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "152213ab",
      "metadata": {
        "id": "152213ab"
      },
      "source": [
        "## 1 - Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a2f5f66b",
      "metadata": {
        "id": "a2f5f66b"
      },
      "outputs": [],
      "source": [
        "X_train = np.load(\"train_images.npy\")\n",
        "y_train = np.load(\"train_labels.npy\")\n",
        "X_test = np.load(\"test_images.npy\")\n",
        "y_test = np.load(\"test_labels.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b43a404c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b43a404c",
        "outputId": "945dcca4-7e0e-444f-803f-79c3160ad9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data X_train:(60000, 28, 28, 1)\n",
            "\n",
            "Shape of data y_train:(60000,)\n",
            "\n",
            "Shape of data X_test:(10000, 28, 28, 1)\n",
            "\n",
            "Shape of data y_test:(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of data X_train:{X_train.shape}\\n')\n",
        "print(f'Shape of data y_train:{y_train.shape}\\n')\n",
        "print(f'Shape of data X_test:{X_test.shape}\\n')\n",
        "print(f'Shape of data y_test:{y_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2e5fe987",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e5fe987",
        "outputId": "5ced07af-052b-4538-f71e-4793fbfb32f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data X_train:(60000, 28, 28, 1)\n",
            "\n",
            "Shape of data X_test:(10000, 28, 28, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Normalize images\n",
        "X_train = X_train.astype('float32') # already normalized\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "print(f'Shape of data X_train:{X_train.shape}\\n')\n",
        "print(f'Shape of data X_test:{X_test.shape}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "02d4eda9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02d4eda9",
        "outputId": "a36984df-b725-4ea8-c007-fe24546158f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data X_train_cnn :(60000, 28, 28, 1)\n",
            "\n",
            "Shape of data X_test_cnn :(10000, 28, 28, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Reshape images for CNN model\n",
        "X_train_cnn = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test_cnn = X_test.reshape(-1, 28, 28, 1)\n",
        "print(f'Shape of data X_train_cnn :{X_train_cnn .shape}\\n')\n",
        "print(f'Shape of data X_test_cnn :{X_test_cnn .shape}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a843acae",
      "metadata": {
        "id": "a843acae"
      },
      "source": [
        "## 2 - Data Viz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d25a9450",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d25a9450",
        "outputId": "59df09b3-0ff4-4145-d05c-8603a4cdf358"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 25 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_train[i], cmap=plt.cm.gray)\n",
        "    plt.xlabel(y_train[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "66d478bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "66d478bf",
        "outputId": "6710e964-6b22-4a11-8398-134787fc8fe3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 25 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAMpCAYAAACDrkVRAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAiAFJREFUeJzt3Xl41dW1//EVEiAhhHlKmGcEBBkEmUQEJyjihNXSOtvaH9qit73V3qdqr9rh3tba3jrfClacaBUEBxBUQBBkjMxDACEQIMwkYQpJfn/cR8rea2FOwk5OkvN+PU+fuj/sJJtk53vO5pz1XXFFRUVFAgAAAAABVYv2AgAAAABUPRw0AAAAAATHQQMAAABAcBw0AAAAAATHQQMAAABAcBw0AAAAAATHQQMAAABAcAmRTCosLJSsrCxJSUmRuLi4sl4TKoGioiLJycmRtLQ0qVatbM+r7D/4ynP/ibAH4WL/Idp4DEY0lWT/RXTQyMrKkpYtWwZZHKqWzMxMadGiRZl+DfYfzqU89p8IexA29h+ijcdgRFMk+y+ig0ZKSkqQBcWS+vXrq6ywsNAZHzlypLyWU2bKY2988zU+/vhjSU5OPpPv3LnTmbdw4UL1sffff7/KVqxYobK77rrLGR87dqxUa0X5Kq9rU6xcA3//+9+r7ODBg8XOiVXsP0RbeT4Gx6IxY8YUO+e9994rh5VUTJHsjYgOGrxUVnLW96wqfh/L4+/0zddITk6W2rVrn8lr1arlzKtZs6b6WOuXwP+4s78GKpfy+rnFyv5ISkpSmfV7hf/D/kO0ledjcCyqXr16tJdQoUWyNygGBwAAABAcBw0AAAAAwUX01imUnP++Zpy/Jk2aOG+F8l/S9GtgRETq1q2rsrZt26qsb9++znjevHmlXSZQaU2ZMkVljRs3jsJKACD65s6d64z3798fnYVUYryiAQAAACA4DhoAAAAAguOgAQAAACA4ajRQaSQkJDh1Gf6tOK3eJdat1xITE1Vm1XIAsebLL79UWcOGDaOwEgCIPmoyzh+vaAAAAAAIjoMGAAAAgOA4aAAAAAAIjoMGAAAAgOAoBkelcfz4cUlI+NeWPXLkiPPnX3/9tfqYXr16qcz/OBGRrKys818gUMndfffdKktNTXXGjz32WHktBwCiql+/fs7Yep6RnZ1dTqupnHhFAwAAAEBwHDQAAAAABMdBAwAAAEBwHDQAAAAABEcxeBnp2rWryqpVc891a9asKa/lVAmbNm2S5OTkM+Pt27c7fz5nzhz1MVYxeHp6usqWLVt2/gsEKrmBAweqbOXKlVFYCQBEX/v27Z3xoEGD1JxnnnlGZUVFRWW1pEqHVzQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwFIMHUK9ePZXddtttKmvbtq0znjRpkprz0UcfhVpWlfPAAw84BfUHDhxw/jw3N1d9zOrVq1W2Y8eO8IsDKplLLrlEZfXr11fZxx9/XB7LAYAzvvOd76hsw4YNKsvIyCjTdaxbt84Z33TTTWrOZ599pjLrpjOxilc0AAAAAATHQQMAAABAcBw0AAAAAARHjUYAOTk5KrPeS9i7d29nfP/996s52dnZKlu+fPl5rK7qyMzMLPHHrF27tgxW8u0SExOdcatWrdQc6+d8+PDhsloSoIwcOVJlX3/9tcqi8TsEILZZzXZTUlJUVtY1GsePH3fGdevWVXOsJn7UaPwLr2gAAAAACI6DBgAAAIDgOGgAAAAACI6DBgAAAIDgKAYPoKCgQGVvvvmmyk6ePOmMH3zwQTXnRz/6kcoee+wxle3evbskS0QZ6dy5s8p++ctfOmOrGNz6+f3jH/9Q2dSpU89jdcD/qVWrlsquuuoqlb300kvlsRwA+FY1atRQmdUcuaydOHHCGSck6KfN7dq1K6/lVEq8ogEAAAAgOA4aAAAAAILjoAEAAAAgOA4aAAAAAIKjGLyM+IXfIiLvvvuuM+7YsaOac9ddd6nMKhz+61//6oz37dtX0iWihPyO3yIizz77rMr69OnjjA8dOqTmtGnTRmUNGjRQmf+zX7x4cXHLBJShQ4eqrGvXrirbuXNneSwHABypqanOuGbNmmrO119/XU6r+Ze0tDRnbN1YY8eOHeW1nEqJVzQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwFIOXI79A/MUXX1RzmjdvrrLLL79cZXXq1HHGzz//vJqzadOmki4R3+Lmm29WmdX1+4svvnDGEydOVHP69u2rsjvuuENlflf4sWPHqjm5ubkqq6isDqo33XSTM161apWaM3PmzDJbUywYPny4yjIzM1W2Zs2a8lgOADi6devmjOvWravmbN68ubyWc0azZs2ccbVq+t/n/e7hcPGKBgAAAIDgOGgAAAAACI6DBgAAAIDgqNGIor1796rs0UcfVdkPf/hDlY0cOdIZW83erLqN0jZ882sRCgsLq3RzL/99mSIio0ePVllSUpLK/MaM//znP9WcrKwslQ0bNkxl7du3d8bWe+3fe+89lVUETZo0UdkvfvELlfXo0cMZ9+/fX83x3wN7+vRpWbBgwXmusOry39/sXy9ERKZPn66yXbt2ldmagLPFxcWprKioKAorQUXQpUsXZ2zthePHj5fXcs5ITk52xtZjfqNGjcprOZUSr2gAAAAACI6DBgAAAIDgOGgAAAAACI6DBgAAAIDgKAavYKwCcavhW35+vjMeNWqUmvPv//7vKvvb3/6mslmzZjnjzp07qzn33nuvMz5x4oQ8/PDDal5VYRXXt27dWmXWz2vOnDnFfv5FixapbOXKlSq74YYbnHGvXr3UnIpaDH7bbbepbMiQISr76quvnHFaWpqa84Mf/MAZHz9+nGLwb3HnnXc645YtW6o5n3zySXktBzHGb2pWq1YtNccqoC0sLFTZ6dOnnXFeXp6aYxWWHzt2TGWnTp3Si0WF0LRp02LnRKMY3H+uZe1l6/lCzZo1VeY3bY4VvKIBAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACCoxi8ErA6cPsF4lZR8oQJE1RmFXCnpqY644svvljNGTp0qDPOzc0111pVWAWHR48eVZnVJTSS743V9dQqBr/uuuuccadOndSchAT9a+wXUJa1du3aqWzMmDEqO3z4sMreeustZ2x1P/e7plf1/Xe+/O/9+vXr1ZxIbloAnM0qcG3SpInKatSo4Yz9318Rkf79+6vsxIkTKvOvZTk5OWqOdT2wbhaxZcuWb/3cInbBuPU1EZZfZG0V+Jd1MXirVq1UNnjwYGdcp04dNcf6HbDWH6t4RQMAAABAcBw0AAAAAATHQQMAAABAcBw0AAAAAARHMXglEB8fr7J69eo5Y6tQ2eqyeuGFF6rML8rr2bOnmuMXQFX1Qqft27erbM2aNSqzuqhbBeKR+Oyzz1R2yy23OOMuXbqoOVZmrbUsWTceaN68ucr+4z/+Q2V+Z/P09HQ1p1u3bs7YKtaPVe3bt1fZJZdc4ox///vfqznWDQkQu/ybSljXlWuuuUZl1v5r3LixM+7Xr5+aY10frOJs/3HM7zouInLo0CGVWQXoGRkZKvN9+eWXKps8eXKxH4fzs23bNmdsPVdp27atytatW1fs505LS1PZoEGDVDZq1CiV+fvI6gJu3aQlJSVFZdbNDmIBr2gAAAAACI6DBgAAAIDgOGgAAAAACI4ajSiyGr9Y72W13kvo11FY73e1TJkyRWV+bUBmZqaa4zdRi8X3yP/nf/6nyqwGP1aDxUhY7x/2G1H5tQoi9vumy7pGY8SIEc64b9++as7ChQtV9vbbbxf7ua36mBkzZjjjkydPFvt5YsVtt92mssTERGe8fPny8loOylDNmjWd+rjSvufbep/59ddf74xvvPFGNcdq5lq7dm2V+b+f1mOKVUPYqFEjlfmN3CxWw7Srr75aZX4NiFXvYV1jly5dqrKNGzcWuy5E7uOPP3bGAwcOVHN+85vfqGzevHkqq1u3rjP2a9ZERJKTk1X2z3/+U2UffvihM7777rvVHKtO6corr1TZ66+/rrJYwCsaAAAAAILjoAEAAAAgOA4aAAAAAILjoAEAAAAgOIrBS6hGjRoqs4rhmjVrprKWLVs646FDh6o5VrFdw4YNVbZ3715nbDV7W7x4scq++OILlWVnZztj6+/z6aefOmOrsVJVd/DgwYiy0rKKI/3vu3VjgF69eqmsfv36KrOaWkXC2qd+QdypU6fUnDfeeENl1t8xEtOmTQvyeaoiq+jQ35erVq0qr+WgDF144YVOY72VK1c6f27dJMG6nvs3cxAR+dGPfuSML7roIjXHuobMmTNHZdOnT3fG69evV3OsG5h0795dZddee60zbteunZpj/R0tflNC/2YbIvbfsXr16hF9fpTepk2bnLF14xrrxieXX365yrKyspzxa6+9pubMnTtXZbt27SpumdK6dWuVWQ37rIaXsYpXNAAAAAAEx0EDAAAAQHAcNAAAAAAEx0EDAAAAQHAxWwxes2ZNlaWmpqqsTZs2ztjvkC2iu1CKiKSlpRU7r6CgQM1Zu3atytLT01XmFwFanVdLW6hsFcgtWLCgVJ8L52fWrFnO2C/YFPm/AlGfVTT+/vvvF/v1rG66TzzxhMr8mx28+eabas5HH31U7NeL1Ndffx3sc1VmPXv2VFm/fv1U5l8frG7rqHwuu+wy57Fry5Ytzp9b13zrxiR+F3ARXfydkZGh5kycOFFlM2bMUJn/eHT8+HE1x+9eLyKycOFClX311VfOuH///mqO9bhs/a74j21+0bqIfRML6/EVZcu/Aci5svj4eJVZz61CWbZsmcqOHDmiMutxuU6dOs746NGj4RZWgfGKBgAAAIDgOGgAAAAACI6DBgAAAIDgOGgAAAAACO68isH9Dp1W0dmaNWtUVtYFMH6XUKsw1iooszos+wXcjRs3VnMOHDigsn379qnM7/JsFXlbnbutQiPEhnXr1jnj+fPnqzlWAbfVldQvBu/WrZua8+tf/1plVlGb33X+b3/7m5qD8MaMGaOyatX0vxdFUviPyqdx48ZOEbX1s/dZxbItWrRQmd/92rqBwIoVK1RmFY2fPn262HUdO3ZMZVbR+IcffuiMrWLcPXv2qCw5OVll/uP58uXL1RzrxifWDVJQMZRl4bfF72B+ruzkyZMq85+bUgwOAAAAAKXEQQMAAABAcBw0AAAAAARXohqNpk2bOu8J/bd/+zfnz3v06KE+5t1331XZn/70p5J82RL7wQ9+4IzvueceNad79+4qy8nJUZnfiGzVqlVqzubNm1W2bds2lflNfwoLC9Uc4NtYNTzXXnutym688UaV+e9lHTlypJrTsWNHlc2ePVtl//3f/+2MN27cqBeL4Fq2bKkyv/ZLROTZZ58tj+WgnCUkJDi1FJHUaPi1FyIiNWrUKPbj+vbtq7L77rtPZVYzTb+RYKSKiopU5tdyZGVlqTlWrYU1r2HDhsV+vfz8/IjWhdi0e/dule3cuVNlS5YsUZm1J2MBr2gAAAAACI6DBgAAAIDgOGgAAAAACI6DBgAAAIDgSlQMXrNmTaf4rH79+s6fN2/eXH3M2c2FykutWrWcsd8kRURk69atKvvoo49U9vTTTztjq+gHKC+LFi1SmXUzgsGDB6vMb1J54sQJNee9995T2a9+9SuVWU26UPaeeuoplVk/R6thKCq/oqIipzDZv8GDVbR86tQplcXFxRX7tRo1aqSy0aNHq2zDhg0q++Mf/+iM8/Ly1BzrZiiRNF/zH99F7BvR+A2FRXRDQKvRmlUMDnzD2rd//vOfVWY1vIxVvKIBAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACCK1Ex+PHjx51i8N/85jfOn7du3Vp9zOLFi1XWpk0blfmFZ1axafv27VV26NAhlU2cONEZr127Vs05ffq0ytavX6+yXbt2qQyIFqsDt9UFumbNmipLTU11xunp6WqOX8QpQuF3RWJ1YUbsWLFihdPVOycnx/lzq1A1OztbZfPmzVOZ//jdpEkTNce6rljdwv3H8y+//FLNWbduncqsAlq/cL1nz55qzne+8x2VWTeBeeedd5zxsmXL1JxICtKBs1H4/e14RQMAAABAcBw0AAAAAATHQQMAAABAcBw0AAAAAARXomLwsWPHOsVgf/rTn5w/X7NmjfoYq3jM/zhr3syZM9WcESNGqCwhQf8V7rnnnmI/F1BVvPXWWypbvXq1yrp16+aMv/rqKzXHKjYHUDHMmTPHuSGL1RXed/ToUZVNmjRJZYmJic547Nixak7Tpk1VZnUQ//73v++Mhw4dquZYN2mxbsjis7qADxgwQGU7d+5U2axZs5yxdTMZAGHxigYAAACA4DhoAAAAAAiOgwYAAACA4EpUo3HxxRdLrVq1zoz9uoqTJ0+qj7He0zls2DC9EK/WIj4+Xs3p37+/ypKSklSWlpbmjHnfOWKN9f5nKwNQeezbt89pYFdUVFTsx1hN/KwmnG+++aYzPn78uJozaNAglVk1E36zvAsuuEDN6dixo8qsOsyza1JE7LpPq8neokWLVOZfA2nOB5Q9XtEAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBlagY/MSJE04hml+IbRWD16lTR2WHDx9WWfv27Z2xVSjWoEEDle3atUtldevWVRkAAJVZUVFRRAXgxbEeq1euXOmMrcfW2bNnq2zIkCEqu/fee52x9Zicl5enMr/wW0Q/h8jKylJzPv/8c5X97W9/U9n27dudcYjvJYBvxysaAAAAAILjoAEAAAAgOA4aAAAAAILjoAEAAAAguBIVg6enpztdOa2ibt+OHTtUtmLFCpV17drVGbdu3VrNObsr+dlr8m3durXYdQEAgP/jdwL3C6dF7AJxv9u2iMimTZuK/Xpn31jmG4mJiSpr0qSJM96wYYOak5mZqTK/uF1EJD8/v9h1AQiLVzQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwJSoGb9GihVOs5RdnHzt2TH2M1c27ZcuWKisoKHDGhw4dUnOsYvAWLVqorFGjRs54//79ag4AAIjc6dOnVZadna2y6dOnO2OrCDshQT/9qF69usqSkpKcsXUTGv/5w7m+JoDyxysaAAAAAILjoAEAAAAgOA4aAAAAAIIrUY3GoUOHnIZ9J0+eLPZjrLoNq/6iWjX3zOO/L1NEJD4+XmXW+zXz8vKKXRcAAIic/zgtIlK7dm2VdenSxRkXFRWpOZE27KtXr54z3rlzp5pj1WFaTfysWg4AZYtXNAAAAAAEx0EDAAAAQHAcNAAAAAAEx0EDAAAAQHAlKgZv3LixU6zlF25ZRdh16tRRmd9QT0QXaVmfq379+ipr2LBhRF8TAADY/AZ6VpF3s2bNVNa3b1+V3XXXXc7YarZr3UzGatjnN/3dtm2bmvPll1+qbPLkySrbvn27M6apH1D2eEUDAAAAQHAcNAAAAAAEx0EDAAAAQHAR1Wh802znxIkTZv5tCgsLVWbVXxw9etQZ5+TkFDtHRCQ3N1dlNOUpP5HsgcrwNVA5ldfeYA/CUpX2n/81rK9pPbaeOnVKZf5jvPW5Iq3RqFGjxrd+bhH93ETEfu5RFX+PeQxGNEWyN+KKIpi1c+dOadmyZZBFoWrJzMyUFi1alOnXYP/hXMpj/4mwB2Fj/yHaeAxGNEWy/yI6aBQWFkpWVpakpKRIXFxcsAWi8ioqKpKcnBxJS0uTatXK9h147D/4ynP/ibAH4WL/Idp4DEY0lWT/RXTQAAAAAICSoBgcAAAAQHAcNAAAAAAEx0EDAAAAQHAcNAAAAAAEx0EjAm3atJG4uDj1v/Hjx0d7aYgBv/3tb+Xiiy+WlJQUadKkiVx33XWycePGaC8LMWT+/PkyevRoSUtLk7i4OJk2bVq0l4QY9Oyzz0qbNm0kMTFR+vfvL0uWLIn2khCDfve730lcXJxMmDAh2kupFDhoRGDp0qWye/fuM/+bPXu2iIiMHTs2yitDLJg3b56MHz9eFi9eLLNnz5b8/Hy58sorzcZVQFnIy8uTnj17yrPPPhvtpSBGvf322/LQQw/JY489JitWrJCePXvKVVddJdnZ2dFeGmLI0qVL5cUXX5QePXpEeymVBre3LYUJEybI+++/L5s3b+ae0ih3+/btkyZNmsi8efPk0ksvjfZyEGPi4uJk6tSpct1110V7KYgh/fv3l4svvlj++te/isj/9XZo2bKlPPDAA/Lwww9HeXWIBbm5udK7d2957rnn5Mknn5SLLrpInnnmmWgvq8LjFY0SOnXqlEyePFnuuusuDhmIiiNHjoiISIMGDaK8EgAoe6dOnZLly5fLiBEjzmTVqlWTESNGyKJFi6K4MsSS8ePHy6hRo5x9iOIlRHsBlc20adPk8OHDcscdd0R7KYhBhYWFMmHCBBk0aJB079492ssBgDK3f/9+KSgokKZNmzp506ZNZcOGDVFaFWLJW2+9JStWrJClS5dGeymVDgeNEvrb3/4m11xzjaSlpUV7KYhB48ePlzVr1siCBQuivRQAAKq8zMxM+elPfyqzZ8+WxMTEaC+n0uGgUQLbt2+XOXPmyLvvvhvtpSAG3X///fL+++/L/PnzpUWLFtFeDgCUi0aNGkl8fLzs3bvXyffu3SvNmjWL0qoQK5YvXy7Z2dnSu3fvM1lBQYHMnz9f/vrXv8rJkyclPj4+iius2KjRKIGJEydKkyZNZNSoUdFeCmJIUVGR3H///TJ16lT59NNPpW3bttFeEgCUmxo1akifPn3kk08+OZMVFhbKJ598IgMGDIjiyhALhg8fLqtXr5b09PQz/+vbt6+MGzdO0tPTOWQUg1c0IlRYWCgTJ06U22+/XRIS+Lah/IwfP17eeOMNee+99yQlJUX27NkjIiJ169aVpKSkKK8OsSA3N1cyMjLOjLdt2ybp6enSoEEDadWqVRRXhljx0EMPye233y59+/aVfv36yTPPPCN5eXly5513RntpqOJSUlJUTWRycrI0bNiQWskI8Iw5QnPmzJEdO3bIXXfdFe2lIMY8//zzIiJy2WWXOfnEiRO5KQHKxbJly2TYsGFnxg899JCIiNx+++0yadKkKK0KseS73/2u7Nu3Tx599FHZs2ePXHTRRTJz5kxVIA6gYqGPBgAAAIDgqNEAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBRdQZvLCwULKysiQlJUXi4uLKek2oBIqKiiQnJ0fS0tKkWrWyPa+y/+Arz/0nwh6Ei/2HaOMxGNFUkv0X0UEjKytLWrZsGWRxqFoyMzOlRYsWZfo12H84l/LYfyLsQdjYf4g2HoMRTZHsv4gOGikpKUEWhKqnPPYG++9fIv3XpKKiojJeScVQXnuDPQgL+w/RxmMwoimSvRHRQYOXynAu5bE3Ynn/+X/38/leVMXDR3ntjVjegzg39h+ijcdgRFMke4NicAAAAADBcdAAAAAAEFxEb50CEB3+252q4tufAABA1cQrGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACCS4j2AoBYVK2aPuMnJOhfx/j4eGdcVFSk5sTFxamssLBQZadPny52jvX5AQAASoNXNAAAAAAEx0EDAAAAQHAcNAAAAAAEx0EDAAAAQHAUgwOB+cXZNWrUUHPatm2rskGDBqmscePGzvjgwYNqTnJyssqOHTumsl27djnjNWvWqDmZmZkqKygoUBkAAEBxeEUDAAAAQHAcNAAAAAAEx0EDAAAAQHDUaACB+TUarVu3VnPuvPNOlY0cOVJlfhM/q0ajTp06Ea3L/9j3339fzXnttddUtmfPnog+PwBEqn79+irr3LmzylJTU53x8ePH1Zz9+/erzLpu7du3zxmfPHmy2HUCOD+8ogEAAAAgOA4aAAAAAILjoAEAAAAgOA4aAAAAAIKjGBwIzC8Gb9KkiZpzySWXqKxevXoqe/PNN53x8uXL1Zzq1aurLD4+XmV169Z1xjk5ORF9nP/3EREpKipSGWJDtWr636d69Oihsp49e6rss88+c8Y7duwItzBUWNb17u6771ZZ165dVeY3PLWakVpF3Xv37lXZihUrnPEbb7wR0ccBKD1e0QAAAAAQHAcNAAAAAMFx0AAAAAAQHAcNAAAAAMHFRDG4VbxYu3ZtlaWkpKjML5jNzc1VcwoLC89jdajqrE62fodaEXtP+sWL06ZNK/U6/KJxq/DbKrREbPNvUjBhwgQ15+abb47oc2VnZztjisFjw/Dhw1V27bXXqiwxMVFl06dPd8azZs1Sc9LS0lRmXU/9a3HNmjX1YgEExSsaAAAAAILjoAEAAAAgOA4aAAAAAILjoAEAAAAguCpZDO53Mq5fv76ac8stt6js6quvVplfiPb222+rOVaHZTonxy7/5gBHjhxRc6ysQYMGKmvfvr0zTkpKUnMOHz4c0bqs7rnA2awbZ/zgBz9wxvfee6+ak5qaqjLrxhljxoxxxqtWrVJzdu3aVew6UbH5+8gquvZvTiEismfPHpV98MEHznjKlClqjvV4a33+SG7cYnUntzrfZ2RkOONly5YV+7mBWMQrGgAAAACC46ABAAAAIDgOGgAAAACCq5I1Gv77Qzt37qzm+O8VFhHp37+/ytavX++MrfeaWjUaiF3++4UPHDig5vj7SkTkkksuUVmHDh2csdWYytp/BQUFxa4T8A0ZMkRlN954ozO29lZmZqbKGjVqpLLvfe97zrhp06ZqzpNPPqmy5cuX68WiwvJrIaxrlNXI1KpB8xuLRtog99SpU8XOseo4xo0bp7Lvfve7Ktu8ebMzfumll9ScDz/8UGXUypWeX397rsxn1fBQR1t+eEUDAAAAQHAcNAAAAAAEx0EDAAAAQHAcNAAAAAAEVyWLwf2CskGDBqk53bp1U5nVLGjlypXO2GpCRVERvs3Ro0dV9v7776usefPmKuvTp48zHjp0qJqTnZ2tMqsAnX2K4vTr109lfsHs//zP/6g5O3fuVNnIkSNVduWVVzrjYcOGqTlWE78NGzaoLC8vT2WomJYuXaoy6wYCrVq1UlmTJk2csdVUMtICcV9+fr7KrMZ71157rcoGDBjgjBMTE9WclJQUlb3zzjsq8/eyVeDsX/tPnz4tCxYsUPOqCuvnXK9evYgy/2Ot521W01yrUL+0ewv/wisaAAAAAILjoAEAAAAgOA4aAAAAAILjoAEAAAAguCpZDO4X1VrdblNTU1X2wQcfqMwvBqerJ0rK6qS8bds2lU2bNk1lLVu2dMZXXXWVmrN7926VzZ07V2V+8RvF4bHN6tzdtWtXlW3atMkZv/baa2qOdSMNq9i3Xbt2zrh///5qjnW9fuONN1S2ceNGlaFi2rJli8qsov8OHTqo7JJLLnHGn376qZrz1VdfncfqXNbn79Gjh8r8buH+jTtEdCG7iF1cPH36dGds/R4++OCDzvjYsWNVuhi8du3aKrNuhvKd73xHZX5hvvUYuXDhQpWtWLFCZf61zeo4z2Ppt+MVDQAAAADBcdAAAAAAEBwHDQAAAADBcdAAAAAAEFyVLAbv2bOnM7YKq6yuslZx2t69e50xXSJRHL+rq99ZWUQkIUH/6vlFtyIib775pjP+4Q9/qOb827/9m8qaNm2qMr/47fDhw2qO9XthZf7vgfV7YRXIlbZozv+eUnx3/mrUqKGyhg0bqiwpKckZW12LLVZXZH9fxsfHqzn+NfdcGSqPunXrqszfVyL2tdLvHm/d6GL9+vUqs4p2I2F1jH7hhRdU5l+D7rzzTjXnggsuUNntt9+usuzsbGd8+eWXqzmXXnqpMz569KiaU5n515XGjRurOd/73vdUdtNNNxX7uU+fPq2y0aNHq8y6IdBHH33kjK2CcWvPWDeBidXHLV7RAAAAABAcBw0AAAAAwXHQAAAAABBcpa/RsN7n6TfO8Rv4iYisW7dOZXPmzFFZbm7ueawOlYX//lDr/evWPvIbkImI1K9f3xlb79Nt1qxZsWsQEWnTpo0zvuyyy9Qca63WujZv3uyMrdqL/Px8lVnNjvzfC+v3yX9vq4j9XvtI3reanJysPsZaPyJn/Sy2b9+uspEjRzrju+++W82xai1GjBihslq1ajnjEydOqDlWfZF1nbdqjFAx+D+vG264Qc2xmq9ZdT116tRxxta++uyzz1S2YcOGYtcZKet35ZVXXnHGVk3BbbfdprJevXqpzK8X6N27t5rjN6ErbQ1KReU/DljNka26B0tGRoYz3rlzp5rTtm1bld11110q8/fpP/7xDzXn3XffVZl1LfV/ZrFSs8ErGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAILhKXwzevn17lV1yySXOuGbNmmrOmjVrVLZ161aVWY1eULlZRdd+Id+1116r5tx8880q84u1RXRxtlW0ZxW1WcWtflOm5cuXqzkW62seP37cGVvF1FbRrVWcm5qa6oz9QkURka+++kpl+/btU5n/vahWTf/7R4MGDZxxYWEhxeDnydqDH374ocr69+/vjH/xi1+oOVbzsHnz5qnsueeec8ZWs63u3burbODAgSp75513VIaKYfjw4c7Yup76N3gQsa8P/u++/7lFRJYuXaqyl156SWUHDx7Uiy0lv8D42WefVXOsG3V85zvfUdl1111X7Nfzf5+q+vXv0KFDKrOet11zzTUqS09Pd8bWtcJ6rLNutjJkyBBn/MADD6g5VkPKadOmFbsuq+C9KuIVDQAAAADBcdAAAAAAEBwHDQAAAADBcdAAAAAAEFylKgZPSNDLtbou+wW6Vmdjq5Po/v37VRYrnRsri7MLuUv7s7GKjTt06OCMx4wZo+Z069ZNZevXr1fZsmXLnPGWLVvUHKt49sCBAyrziyOtomuLVWR27Nixbx2LiNSrVy+iz++zOopnZWWprLCwsNjPZf1cs7Ozi52D8zd79myV+cW4w4YNU3M2btyosjfeeENlu3btcsbWjTqsjr0XX3yxymbNmuWM/W71iJ527do5Y+uGEtbj7dq1a1XWt29fZ9yiRQs1x9qTM2fOVFnIYnCf1Yn873//u8pat26tMv8GNlZXab+guap1BvdZfz+/mFrEvvb4e8b6fk6aNEllK1euVNmCBQucsdXtfdy4cSqzOsX/6U9/csbW84dIHiMrG17RAAAAABAcBw0AAAAAwXHQAAAAABAcBw0AAAAAwVXYYvBIujeLiFx++eUqa9WqlTNevHixmmN1mPQ7J6PiCVEEbH0OvzDRKuC29t+iRYtU9vbbbztjq+O81ZXZKgILWRjm/72t74NVwG39Lkbyc7DmlPbj/OJ2isHLxunTp1X2+uuvO2Or421puxR/+umnKrvyyitVZt30o1OnTs54xYoVpVoDwrNuuOFr2LChypo3b66y+Ph4Z2xdjxo1aqSy+vXrF7uGsvbFF1+obMaMGSqrXr26M161apWa8/HHHzvjilA0bP0sfJFeq/09Yz1Gfv755yqbOHGiyu6//35nPHLkSDVn8+bNKvvnP/+psoyMDL1Yzy9/+UuVjRgxQmV+d3fruUFVfB7KKxoAAAAAguOgAQAAACA4DhoAAAAAgquwNRrWezytpj9+ozUR/Z5A6/2OfiM0kYrxnkeUPevn7Df0eeWVV9ScvXv3qsxqJDZw4EBnvHPnTjXnyJEjKqsIdQcVYQ2WirquWFTaegzLjh07VGbV1I0ePVplflM4ajQqjnXr1jlj62c6aNAglfXs2VNlfv2Cde20Gv1Z9WblzbpuWU383n//fWdsNVO1nrOUt/r1639r09xI6/ms53d169Z1xklJSWqOVb+wcOFClfmPwdddd52ac/fdd6vMaqS7ZMkSZ1y7du2IPs5vHC2ia81q1aql5lCjAQAAAAAR4KABAAAAIDgOGgAAAACC46ABAAAAILgKUwzuFxHVrFlTzenVq5fKunbtqrJdu3Y5488++0zNyc7OLukSUYWdOnXKGfvFjCJ2Md7SpUtVduLECWdsNR6iuBmwzZkzR2WXXXaZyvr37++Mrev8gQMHgq0LkfOby1mNycaMGaOyoUOHqsxvvGcVfr/xxhsq27hxY7HrjIacnJyIsoro5z//uSQmJp4Z+41UI2UVVPsNcRs0aKDmRPq985t5Wl/PupHLww8/rDK/ufPBgwfVHH+/i4j88Ic/VNmQIUOcsd/cV0Tk0KFDKqvsNyriFQ0AAAAAwXHQAAAAABAcBw0AAAAAwXHQAAAAABBchS0Gb9SokZpjFe9Y3cI/+eQTZ7xhwwY1xy/YReXj7xmrK2mkRVR+cfbp06fVHKszuFVsGsnnAmCzbsRg3XRh8ODBzvjCCy9Uc+bOnRtsXSi9jIwMlf35z39W2eTJk1XWrFkzZ2x1k7cKaBHe+PHjpU6dOtFeRpnp0aOHytq1a+eMFyxYoOb43etFxCma/4Zf8G49f7VudkAxOAAAAAB4OGgAAAAACI6DBgAAAIDgOGgAAAAACK7CFINXq+aeeaxicL8oTMQuAvM7y27fvl3NoTNz5efvGX8sYv+cS/uztwqy/I7iAMKbNWuWyvwuu3379lVzKAavuCK94YaVIToyMjKcLtv+Y6712GrdpCU/P19l/mOp9blq1aqlsqSkJJUdOXLEGVuP3ampqSrzi7VFdFfxq6++Ws2xPr/1fMS/kUF2draaUxWfm/KKBgAAAIDgOGgAAAAACI6DBgAAAIDgKkyNRnx8vDO23j9nZdZ73FavXu2M/ffroWrw90yNGjXUHJrlAZXfihUrVDZ//nxn3LNnTzXHes/1vn37wi0MiCH/9m//JgkJ/3ra6DeqO/vPvnH8+HGVWXUIubm5zjjSJnh+DYWI/h23nhv4jfhERLp06VJsdtFFF6k5Vj2GdZ2ZMWOGM7aaT1b25nwWXtEAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBVdhi8Dp16qg5VtGPVeidk5PjjKticQ30z5XCbyB2LF682BlffPHFak7Xrl1VNm/evFJ9vZYtW57578LCQtm1a1epPg9QWc2fP99swPcN688ibUAXyTzr81uZ/9zAmrNw4UKVWcXmDRo0cMYdOnRQc6zCdauZ9KZNm5zx4cOH1Rwa9gEAAABABDhoAAAAAAiOgwYAAACA4DhoAAAAAAiuwhSD+4W8mZmZas6yZcuK/TgRuwgHVV9VLKICYJs7d64zbtKkiZpz8uTJYF/P6v4LxJKqdGOdgoIClZ06dUplR48edcbbt29Xc6xrg/W9itXnKFw5AQAAAATHQQMAAABAcBw0AAAAAATHQQMAAABAcBWmGDw/P98Zr127Vs156623VFa3bl2VHTx4MNzCUGElJLjbt2bNmmqOv69EYrcgC6jKpkyZUqaf3yoCBRBbrOcPVmE5/oVXNAAAAAAEx0EDAAAAQHAcNAAAAAAEV2FqNOLj451xamqqmtOrVy+V+e/TF7Eb+6Hq8d8XaTVvpB4DiA2dOnVSmdW8dd++faX6/DVq1Djz30VFRWb9F4DYYzXss557xOrzEV7RAAAAABAcBw0AAAAAwXHQAAAAABAcBw0AAAAAwVWYYvDq1as74wsuuEDNufbaa1WWl5enstmzZzvjrVu3nufqUBH5hVVWMTiAqqlbt27OePz48WrOO++8o7JPPvmkVF8vLS3tzH8XFhbKjh07SvV5AERfXFycyqyi7uTkZGfcpEkTNefsG0V8IycnR2XZ2dnO+NSpU2pOVSwY5xUNAAAAAMFx0AAAAAAQHAcNAAAAAMFFVKNRHu8Z87+G1QzJqsewMt6rX36isTfOldMgJ/aU18+XfVTx+A07jx8/ruaEfCwoLCxU/83+Q7RF8zG4Mov0+YKfnX0d+IZ/LTrXvEies1Q2kfwd4ooimLVz505p2bJlkEWhasnMzJQWLVqU6ddg/+FcymP/ibAHYWP/Idp4DEY0RbL/IjpoFBYWSlZWlqSkpJiV+og9RUVFkpOTI2lpaeadGkJi/8FXnvtPhD0IF/sP0cZjMKKpJPsvooMGAAAAAJQExeAAAAAAguOgAQAAACA4DhoAAAAAguOgAQAAACA4DhoRmj9/vowePVrS0tIkLi5Opk2bFu0lIUb97ne/k7i4OJkwYUK0l4IYkpOTIxMmTJDWrVtLUlKSDBw4UJYuXRrtZSEGPP744xIXF+f8r0uXLtFeFmII17/S46ARoby8POnZs6c8++yz0V4KYtjSpUvlxRdflB49ekR7KYgx99xzj8yePVtee+01Wb16tVx55ZUyYsQI2bVrV7SXhhjQrVs32b1795n/LViwINpLQgzh+ld63N62FOLi4mTq1Kly3XXXRXspiCG5ubnSu3dvee655+TJJ5+Uiy66SJ555ploLwsx4Pjx45KSkiLvvfeejBo16kzep08fueaaa+TJJ5+M4upQ1T3++OMybdo0SU9Pj/ZSEIO4/p0fXtEAKonx48fLqFGjZMSIEdFeCmLM6dOnpaCgQBITE508KSmJf1lGudi8ebOkpaVJu3btZNy4cbJjx45oLwkxguvf+eGgAVQCb731lqxYsUJ++9vfRnspiEEpKSkyYMAAeeKJJyQrK0sKCgpk8uTJsmjRItm9e3e0l4cqrn///jJp0iSZOXOmPP/887Jt2zYZMmSI5OTkRHtpiAFc/84PBw2ggsvMzJSf/vSn8vrrr6t/UQHKy2uvvSZFRUXSvHlzqVmzpvzlL3+RW2+9VapV42EEZeuaa66RsWPHSo8ePeSqq66SDz/8UA4fPixTpkyJ9tIQI7j+lR7fIaCCW758uWRnZ0vv3r0lISFBEhISZN68efKXv/xFEhISpKCgINpLRAxo3769zJs3T3JzcyUzM1OWLFki+fn50q5du2gvDTGmXr160qlTJ8nIyIj2UhAjuP6VHgcNoIIbPny4rF69WtLT08/8r2/fvjJu3DhJT0+X+Pj4aC8RMSQ5OVlSU1Pl0KFDMmvWLBkzZky0l4QYk5ubK1u2bJHU1NRoLwUxhutfySVEewGVRW5urvOvJ9u2bZP09HRp0KCBtGrVKoorQ1WXkpIi3bt3d7Lk5GRp2LChyoGyMmvWLCkqKpLOnTtLRkaG/PznP5cuXbrInXfeGe2loYr72c9+JqNHj5bWrVtLVlaWPPbYYxIfHy+33nprtJeGGMH1r/Q4aERo2bJlMmzYsDPjhx56SEREbr/9dpk0aVKUVgUA5ePIkSPyyCOPyM6dO6VBgwZy4403ylNPPSXVq1eP9tJQxe3cuVNuvfVWOXDggDRu3FgGDx4sixcvlsaNG0d7aYgRXP9Kjz4aAAAAAIKjRgMAAABAcBw0AAAAAATHQQMAAABAcBw0AAAAAATHQQMAAABAcBw0AAAAAATHQQMAAABAcBE17CssLJSsrCxJSUmRuLi4sl4TKoGioiLJycmRtLQ0qVatbM+r7D/4ynP/ibAH4WL/Idp4DEY0lWT/RXTQyMrKkpYtWwZZHKqWzMxMadGiRZl+DfYfzqU89p8IexA29h+ijcdgRFMk+y+ig0ZKSkqQBVVG8fHxzrigoCBKK6mYymNvxMr+q1GjhsratWvnjOvUqaPmZGVlRZQVFhaex+oqpvLaG5VtD/rrTUtLU3Nq166tsl27dqlsz5494RZWxbD/EG08BiOaItkbER00Yvmlskj+7tacoqKislhOhVMeeyNW9p/19/QPugkJ+lfWetkylr9nlfnrhOKv199HIpHvJZwb+w/RxmMwoimSvcGjCgAAAIDgOGgAAAAACC6it07FstOnTxc7J1beJoWydfLkSZWtW7eu2I9j/8F39OhRZxzJPgIARJf1VqQhQ4ao7ODBg854zZo1Zbam88UrGgAAAACC46ABAAAAIDgOGgAAAACCo0YDqMCovwAAIDZYPY8uvfRSle3evdsZr127Vs2pKM8feEUDAAAAQHAcNAAAAAAEx0EDAAAAQHAcNAAAAAAERzE4UIFVq1b8vwUUFhaWw0oAAEBZ2rVrl8r+9Kc/qez48ePOuKIUflt4RQMAAABAcBw0AAAAAATHQQMAAABAcBw0AAAAAARXJYvB4+LiSvVx8fHxKktMTHTGp0+fVnOsYtz8/HyVVeRiHZQva4/WqVNHZUOGDHHGjRs3VnNWrVoVUWbtSVR+CQn6Mt6+fXtn3LlzZzWnQYMGKtu0aZPK0tPTnfGxY8dKuEIAQGnl5eVFewnnhVc0AAAAAATHQQMAAABAcBw0AAAAAATHQQMAAABAcBWmGNwvjrU6IlvF2vXr11dZUlJSsR/nzxGxC20vvPBCZ1yzZk01Z+vWrSpbuXKlyrZv3+6MCwoK1BxUPZEWfl9zzTUqe/TRR51xw4YN1Zzf/va3KrOKeikGr1z8G1GI2EXdAwcOVNkNN9zgjDt06KDm1KhRI6J1LF261Bm/8MILas7MmTMj+lxARVK3bl2VpaSkqCwnJ0dlR44cKZM1AVUNr2gAAAAACI6DBgAAAIDgOGgAAAAACK5ENRo1a9Z03m9+8uRJ58+thnTW+9Nr166tMr8+wqqXaNmypcr69OmjMr9uw2poZb0Ps1atWirr0aOHM7aa8x06dEhlb7zxhspeeeUVZ3zw4EE1B1WPVSPUvXt3ld1xxx0q8+sq/vSnP6k51vvjaapW+TRp0sQZjxw5Us257rrrVNalSxeV+ftmw4YNas7+/ftV1rp1a5X5dWq33367muM/FoiIZGVlqcyvZ6sodUP+4xTNVSsXq1azU6dOKuvVq5cz9h/fRew6uOzsbJWtWLHCGa9bt07NWb58ucqspr9AVcYrGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAILgSFYP36tXLKaz+6quvnD/Py8tTH2MVVg0ePFhll19+uTNu1aqVmmMVkR89elRlp06dcsbVq1dXc6y1WsWLfsF2s2bN1Jy2bduq7Morr1TZggULnPGSJUvUHKvYHJWb1XzS2t9t2rRR2fvvv++MJ06cqOZYhYoUs1ZsVsPQ733ve874vvvui+jj3nvvPZXNnz/fGVvF4NYNAxo0aKCyYcOGOWOrgHbChAkq27Fjh8pefPFFZ7xmzRo1JxratWvnjA8cOKDmHD58uJxWg2/Tvn17ld16660qu+qqq4r9WKuI3Lp5jFXA7V93rZu7/POf/1TZM888ozL/+Yh1E50bb7zRGefn55u/+0BFwysaAAAAAILjoAEAAAAgOA4aAAAAAILjoAEAAAAguBIVg//kJz9xumf7halr165VHzN69GiV3XLLLSqrW7euM7YKCf3CWBGRL7/8UmV+MbjlxIkTKsvJyVGZX5RlFYNbHXzHjh2rsnHjxjnj48ePqzl+gX158DtXW4XEFKmXXs2aNVVmdbm3uiTPnTvXGVtFqhR+l5/ExETnmmD9DkeiadOmKvOvGR06dFBzXnnlFZU9/fTTKvOvn5H+/u7Zs0dlfrdw/zomYt/cYMaMGSqrqF2RCwoKvnWM8mHdOMO/+cAvf/lLNefSSy9VWePGjVXmd7A/dOiQmpOZmakya9/Wq1fPGVudyO+44w6VWTdh+Mc//uGMe/bsqeb86Ec/csZ5eXkUg6NS4BUNAAAAAMFx0AAAAAAQHAcNAAAAAMFx0AAAAAAQXImKwZs2bep05/a7webm5qqPiaQgS0Tkf//3f53xZ599puZkZGSozOoM7heUWYWQVufNSObt3LlTzbEKxbp06aIyv1v4vn371ByrU27IwkSr2M7vNmwV00dSYI//4+8Zv5hWRGTEiBEqs4rB161b54zPp5jWL/qvXr26mtOwYUOVWcXsfhG01RXX+j2v7OrVq+f8DpW2GNy6qURqaqoztn7n5syZozLrmhRJ8XedOnVUNnz4cJXde++9zrh79+5qjtUB+bnnnlPZxo0bi11XNHz99dfRXgLEvi4++OCDznjw4MERfa5Vq1apbObMmc74008/VXPWr1+vMuuGGwMGDHDG//mf/6nmXHDBBSq75pprVObf1KZfv35qzsUXX+yMrec+QEXEKxoAAAAAguOgAQAAACA4DhoAAAAAgitRjcYrr7wiNWrUODP2azSs9+5aDegeffRRlfnvi7TefxhprUIk8yJtcubPsz73hg0bVPbRRx+pzH+/ZteuXdUc6/38W7duLXadkTr75/cNv55k9+7dak5WVpYzpkncufm1EBdeeKGa4zehErHfL2zVPRX39URE6tevrzL/Pb59+vRRc9q1a6cyv4ZHRGT//v3O2G8sKKLfDy3yf02mSiMhwb1UFRUVRaWp2pEjR8z6rpKymoJ9/vnnzviGG25Qc3784x+rrG3btirzr7vWz7B///4qsxqs+s0lp06dquY888wzKlu2bJnKuG7gG1atxT333FPsPL9uTURkwYIFKrMa/C5dutQZR3J9PRe/ZtRqMmzValq1cf71zR+L6Ou8dd1H5Xd2U+xvjBo1SmX+Y7BV11xR8IoGAAAAgOA4aAAAAAAIjoMGAAAAgOA4aAAAAAAIrkTF4EeOHHEKmfxGXmc38/uGVbC0Z88elR06dKgkS4kaq5jx2LFjKlu5cqXK/MZa3bp1U3PS0tJUVtbF4G3atHHGJ06cUHOsAnEKO23+74X//RWxbyowY8YMlR0+fNgZJycnqzkdO3ZU2fXXX6+ym266yRm3aNFCzbGaSFoF3P4+veiii9SctWvXqsxq2BbJPqpbt64zLiwsjMo1o7QN+nz+zRVERCZNmuSMrZ+1dcMNq4DW/55a19xevXqpLDExUWXTp093xk899ZSak56erjLgG1ZRtLVvrYZ9/uPfY489puYsXrxYZf61MzT/d9i6wYO1hilTpqjMv3GCdcOJq6++2hmfTyE7Kq4rrrhCZb/4xS9UtmXLlm8di9g3KIgGXtEAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBlagYfNCgQU6xYJMmTZw/twoJrULYYcOGqSxkwXNFkJ+fr7Jq1dxznVX4bWUhWV1J/W7kVuGoVZxGMbitcePGztjqwOzfGEDELp7298zw4cPVnB/96EcqGzJkiMqys7Od8eTJk9Wc2bNnq8y62cEtt9zijK+66io1p3nz5iqzisEjUVGKwUOxfnf8glbr72d1lLe+z37xrf87LmLfqMPq8P700087Y7/rOFAcq3u9dTMCa88/+eSTznjmzJnhFnYe/Guz1dG5sLBQZbt27VKZf409cOCAmuPflMO6LqPysx7jrRsHHTlyxBnXqVOnzNZ0vnhFAwAAAEBwHDQAAAAABMdBAwAAAEBwHDQAAAAABFeiYvD+/fs73b/9wmKrkCs1NVVlVufDTz75xBl//fXXJVlaVFkF1p06dVKZXxjvF5OJ2J2HrXlWkVlp+R1GT58+Hexzx6J69eo5Y6srrtXF0+r06u+Zxx9/XM2xiio/++wzlf35z392xgsXLlRzrE62Vjf59u3bO+MBAwaoOSdPnlRZaW8g4O/JkPu/ovB/961u29YNA5o1a6ay//zP/3TG/s9LxC7qfu6551T2xRdfOGNuAoGS8q+JIvbj2sSJE1U2bdq0MljR+fP/Ttbf0Xo8b9iwocpq1qzpjM9+nvUN//eO38PKr0WLFiqzbvhx6tQplS1ZssQZl/ZGK+WBVzQAAAAABMdBAwAAAEBwHDQAAAAABFeiGo22bds6TUH89wv77+UVsZuJ9e3bV2UjRoxwxm+++aaaY73fsazfq+03qktI0N8y6/3P1157rcr8pmMzZsxQc1auXKmykO/F9Jv+iOj36u/bt0/N8b/PvD/03PzGTfXr11dzrDqYpKQklV155ZXO2KrHeP/991X2q1/9SmWrV692xgUFBWqOxarR8PfDjh071JyQTTj9JpKxuv+sPTJo0CCV3XHHHc44MzNTzbEaNvq1ciKx+71G6fmPm1bNgcW6JvmNJa1muGXNakY8ePBgZ2w12z148KDK1q9frzK/ns1q6udfY63nQ6hcrEbI1v4+evSoytatW1fsx1UUvKIBAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACCK1Ex+MmTJ+XEiRNnxn4x89tvv60+pnfv3irr1q2byr7//e87Y6sozCp6tRqM+R8baTGj3zRHRJzidxG7mcro0aNVNnDgQJX5DVWs75df9CoSthjTaqLmN4+zCpUpCLVZxVx+8bRfzChi38TAKvTt37+/M7Z+L+bPn68yq7FbJMXf1t/Hv4mBiEiHDh2csXWTASsrLathUVVnNfbyr5MiuvBbRGTz5s3O+Pnnn1dzpkyZojKr6BAoqUiay1mPdVaj3rOfc0TLkCFDVHbTTTc5Y6th3x//+EeVLVu2rNivZ9284e9//7szprFu5effBEnEvlmSdV22bkxUUfGKBgAAAIDgOGgAAAAACI6DBgAAAIDgOGgAAAAACK5E1STvvvuu0yHzvffec/7c6g78hz/8QWV33323yvxiqx/+8IdqTvXq1VW2adMmle3evdsZ5+bmqjlW4bdf4Coicskllzjjiy++WM2xOoNbRW1+J94lS5aoOWVd4GUV5VWEYrvKqlo1fVb3i7qtYnCrMPvYsWMqmz17tjO2ihKt7Msvv1TZ8uXLnbH1c2/QoIHKLr/8cpX5RepWR2nrxgM4N7+4z7/2iIjceeedKrOuP0899ZQzfvPNN9Wcffv2lXSJQKns3btXZfv371eZdXOX8ta5c2eV3XjjjSrr2bOnM/7iiy/UnDlz5qistI/x/vWbG7RUPv413u8uL2LfVMC/YY+ISHZ2drB1lTVe0QAAAAAQHAcNAAAAAMFx0AAAAAAQHAcNAAAAAMGVqBj89ddfdwpb/ULs/Px89TGfffaZyqwuv36BlF9oJSLy05/+VGVWkZlfOGOtyyosb926tcpatWrljK0CnKlTp6ps7ty5KvOLuSpC4ZsIRWXnwyr0Tk5OdsaRdA8XsYsE/RsunH0zhm+MHTs2oszfb1Yhu9Xlfvjw4SrbuXPnt65TJDa7eZ+PTp06OePvfe97ak5qaqrKPvjgA5VNmzbNGVtdmIHysmvXLpVZN6OoVatWeSznDKvw27rhwjXXXKOygwcPOuMZM2aoOdZNYUrL/3qofFq0aOGMe/TooeZYz8es3x+rQLyi4hUNAAAAAMFx0AAAAAAQHAcNAAAAAMGVqEZjw4YNzvvNI2k8k5eXp7L58+erzG/eYzUJ6969u8qaNWumMv99b40aNVJzrLVb74GcMmWKM541a5aak5GRobIDBw6ozG/SRm1E5WftI79x5erVq9Wcjh07qsxqvOc3wps+fbqaY71X02ri5tdajBo1Ss2xfsesZnzPPfecM167dq2aU1hYqDKcW9euXZ3xgAED1Byryefvfvc7lW3YsCHcwoDzZDXWtZqKXnTRRSrzr2/W463VlLdx48Yq69atmzO+77771Bzrucf27dtV9o9//MMZz5w5U82hGS7O5j/ut2vXTs05fvy4ytLT01VWma7xvKIBAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACCK1ExuF/MXFpWgdRXX33ljK1GN/Xq1VNZSkqKytLS0pyx1QTIathnfc3Nmzc7Y6vIG7HLKnhet26dM/YLp0VEHn74YZX96le/Utlll13mjK0mj9YNEfr27asyv1mQVUT+0ksvqeyNN95QmV+QGcmNIfAvVqNHv4HiqlWr1Byr4NSaB1QkVrH2mjVrVNanTx+VPfvss87YKoI9evSoyvznASK6EbD1nMa6XlvN+PwbYFD4jeL4NyPwm/uKiGzcuFFlVlPWyoRXNAAAAAAEx0EDAAAAQHAcNAAAAAAEx0EDAAAAQHAlKgYvS35RltWl2yqEtfjFYmd3M/+GX3gpInLy5Mli1wUUJy8vzxlbBbyWMWPGqMzv1N20aVM1Z+fOnRFls2fPdsbvv/++mjN37lyVWYWcdP0+P9Z1xf/e+x3mReyfKz8LVEYLFixQ2Z49e1R29dVXO+OBAweqOX6RrYjIqVOnVOYXdVtr8K+TIiLHjh1TGfBtEhL002v/8dy6KZF1k4TKfsMPXtEAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBVZhi8EhEWvRoFXUD5aWoqMgZWzcxmDp1qsq+/PJLlfndbevXr6/m7N27V2VWp+6srCxnvH///og+Dq6zby7h/6wjZRUKZmdnf+sYqOoyMjJU9sorrzhjq0t38+bNVWbdcGHLli3O2LoGAiE0aNBAZVa3ep91E5DK3nWeVzQAAAAABMdBAwAAAEBwHDQAAAAABFepajSAysh6H7/1nsutW7dGlCG6SluXcTarFsav26hbt66ak5OTozKrMRlQVfjN8rZv367mWBkQTR07dlRZvXr1nLHVCDI/P7+slhQ1vKIBAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACCoxgcAMrZ2U3/vjF48GBnPHToUDVn0aJFKvv444/DLQwV2gMPPCA1a9Y8M16/fr3z59bNAlJTU1V2wQUXqCwpKckZW3t09+7dEWXvvfeeMz5+/LiaA1QVVsPI7373uyrr0KGDM7aa+e7bty/YuioKXtEAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBUQwOAOXMKrRt0aKFM77lllvUnAYNGqhs2bJlKjt48OB5rA4VVXJyslMM7hdwW13iExMTVZaSkqKySIrBjx49WuzHnetjgarqzjvvVNmYMWNUVqdOHWecnp6u5qxZsybYuioKXtEAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBUQwOAOWssLBQZQcOHHDGCQn68jxkyBCVWR3E33//fWecn59f0iWiAvrLX/7iFFr7HbetfXV28fg3pk6dqjJ/vxUVFak5BQUFKsvNzVWZtQ6gKrC6gHfr1k1lp0+fVtn8+fOd8RtvvKHmLFq06DxWVzHxigYAAACA4DhoAAAAAAiOgwYAAACA4KjRAIAKIDk52Rlb74ffunVrRBk1GVXTkCFDpHr16mfGmZmZzp9b9RKNGzdWmd8cUsSu5fBZjSCtbOnSpc6Ymg1UFX4tnYjI3r17VRYfH6+y9u3bO+NBgwapOVaNxsaNG0uyxAqHVzQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwFIMDQDmrVk3/G8+JEyec8eLFi9Wczz77TGWrV68OtzBUaH379pXExMQzY/8GAkeOHFEfYzUY69mzp8pq1apV7NfftWuXynbu3KmyNWvWOOO8vLxiPzdQGfjXaRGRKVOmqKxNmzYqGz58uDMeMWKEmrNw4UKVUQwOAAAAAB4OGgAAAACC46ABAAAAILiIajSKiorKeh2opMpjb7D/cC7ltTdCfx3r8/lN9o4fP67mnDp1KqLPhfJR3vvv5MmTTu7vmdOnT6uPtfaMtbfi4uKKXYf1/nT2ZHTxGBx91u/dsWPHVHb06FFnnJOTo+ZYv08VWSR7I64oglk7d+6Uli1bBlkUqpbMzEyzy2xI7D+cS3nsPxH2IGzsP0Qbj8GIpkj2X0QHjcLCQsnKypKUlJSI/tUDVV9RUZHk5ORIWlqaeQedkNh/8JXn/hNhD8LF/kO08RiMaCrJ/ovooAEAAAAAJUExOAAAAIDgOGgAAAAACI6DBgAAAIDgOGgAAAAACI6DRgk8++yz0qZNG0lMTJT+/fvLkiVLor0kxIhdu3bJ97//fWnYsKEkJSXJhRdeKMuWLYv2shBDcnJyZMKECdK6dWtJSkqSgQMHytKlS6O9LMQQHoMRLfPnz5fRo0dLWlqaxMXFybRp06K9pEqDg0aE3n77bXnooYfksccekxUrVkjPnj3lqquukuzs7GgvDVXcoUOHZNCgQVK9enX56KOPZN26dfLHP/5R6tevH+2lIYbcc889Mnv2bHnttddk9erVcuWVV8qIESNk165d0V4aYgCPwYimvLw86dmzpzz77LPRXkqlw+1tI9S/f3+5+OKL5a9//auI/N99pVu2bCkPPPCAPPzww1FeHaqyhx9+WBYuXCiff/55tJeCGHX8+HFJSUmR9957T0aNGnUm79Onj1xzzTXy5JNPRnF1iAU8BqOiiIuLk6lTp8p1110X7aVUCryiEYFTp07J8uXLZcSIEWeyatWqyYgRI2TRokVRXBliwfTp06Vv374yduxYadKkifTq1UtefvnlaC8LMeT06dNSUFAgiYmJTp6UlCQLFiyI0qoQK3gMBiovDhoR2L9/vxQUFEjTpk2dvGnTprJnz54orQqxYuvWrfL8889Lx44dZdasWfLjH/9YfvKTn8irr74a7aUhRqSkpMiAAQPkiSeekKysLCkoKJDJkyfLokWLZPfu3dFeHqo4HoOByouDBlDBFRYWSu/eveU3v/mN9OrVS374wx/KvffeKy+88EK0l4YY8tprr0lRUZE0b95catasKX/5y1/k1ltvlWrVeBgBANh4hIhAo0aNJD4+Xvbu3evke/fulWbNmkVpVYgVqamp0rVrVye74IILZMeOHVFaEWJR+/btZd68eZKbmyuZmZmyZMkSyc/Pl3bt2kV7aajieAwGKi8OGhGoUaOG9OnTRz755JMzWWFhoXzyyScyYMCAKK4MsWDQoEGyceNGJ9u0aZO0bt06SitCLEtOTpbU1FQ5dOiQzJo1S8aMGRPtJaGK4zEYqLwSor2AyuKhhx6S22+/Xfr27Sv9+vWTZ555RvLy8uTOO++M9tJQxT344IMycOBA+c1vfiM333yzLFmyRF566SV56aWXor00xJBZs2ZJUVGRdO7cWTIyMuTnP/+5dOnShWsgygWPwYim3NxcycjIODPetm2bpKenS4MGDaRVq1ZRXFnFx+1tS+Cvf/2r/Pd//7fs2bNHLrroIvnLX/4i/fv3j/ayEAPef/99eeSRR2Tz5s3Stm1beeihh+Tee++N9rIQQ6ZMmSKPPPKI7Ny5Uxo0aCA33nijPPXUU1K3bt1oLw0xgsdgRMvcuXNl2LBhKr/99ttl0qRJ5b+gSoSDBgAAAIDgqNEAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBcdAAAAAAEFxEncELCwslKytLUlJSJC4urqzXhEqgqKhIcnJyJC0tTapVK9vzKvsPvvLcfyLsQbjYf4g2HoMRTSXZfxEdNLKysqRly5ZBFoeqJTMzU1q0aFGmX4P9h3Mpj/0nwh6Ejf2HaOMxGNEUyf6L6KCRkpIiIiI1atRwTrNjxoxx5g0dOlR97J/+9CeVZWRkRPJlg7FO4LHQEN06Zfbu3VtlY8eOdcZfffWVmvPBBx8446KiIjl69OiZvVGWyuNroHIqr73BHoSF/Ydo4zEY0RTJ3ojooPHNE/W4uDjnSXuNGjWceUlJSepj4+PjI/kSQfkHi0hf6qtqhw/r752QoH/kiYmJztj/uZ7rc31bHhIv1eJcymtvsAdhYf8h2ngMRjRFsjcoBgcAAAAQHAcNAAAAAMFF9Napb5w8edIZz5kzxxmvWrVKfcyWLVtKsazzk5yc7Iyt95AdOHBAZadOnSqzNUVDQUGBytLT01W2fft2Z3zs2DE1JycnxxlXtbeZAQAAICxe0QAAAAAQHAcNAAAAAMFx0AAAAAAQXIlqNHwHDx50xnl5eWqOVSdQ1vzb7DZu3FjNOXToUHktp0I5ceKEynbv3h2FlQAAcP6qV6+usvz8/CisBICPVzQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBw51UM3qpVK2fcsWNHNeezzz5TmVWQHJJfpJ6bm6vmxGqhWJ06dVTm/xytQvk9e/Y446KiIiksLAy7OAAASihWH8+ByoBXNAAAAAAEx0EDAAAAQHAcNAAAAAAEx0EDAAAAQHAlKgZPSUmRuLi4M+ObbrrJ+fORI0eqj8nJyVHZggULSvJlS8zvRn78+PEy/XoVVY0aNVQ2bNgwlT344IPOeN68eWrOCy+84IwLCwtl796957lCAAAAVFW8ogEAAAAgOA4aAAAAAILjoAEAAAAgOA4aAAAAAIIrUTF4/fr1pVq1f51NunXr5vx5amqq+pghQ4aorKyLwfF/kpKSVNa1a9dis3379qk5DRs2dMYFBQUUgwMAAOCceEUDAAAAQHAcNAAAAAAEx0EDAAAAQHAlqtE4ePCg07Dvyy+/dP68Vq1a6mM+/fTTUi6t9M5eY0kUFRUFXkl0WY0Kly9frrLZs2c746VLl6o52dnZzriwsPA8VwdffHx8sXP8ZpQAAAAVFa9oAAAAAAiOgwYAAACA4DhoAAAAAAiOgwYAAACA4EpUDJ6bm+uMZ8yY4YzT09PVx6xcubLkqzpPNWrUcMbJyclqztGjR1V2+vTpMltTNJw6dUplVrPEjIwMZ5yTk6PmHDhwwBlXtcL5kPybEdSuXVvNqVevnsoaN26sMn9Pbtq0Sc2xfs5WYblfSE5BP4CKzr9WNm3aVM1p1aqVyqybmhw+fDjUsgBEiFc0AAAAAATHQQMAAABAcBw0AAAAAATHQQMAAABAcCUqBvdlZmY64507d6o5ZV1wWrNmTZX17NnTGVsdyxctWqSyqlYMbjl27JjKtm7dGoWVVA3VqumzeqNGjZzxjTfeqObccsstKrMKxLdt2+aMX3zxRTXH6vbeoUMHlfm/n9H4fQUAEZF27dqp7Kc//anKLrjgAmds3VyjQYMGKvviiy9U9vTTTzvjNWvWFLtO4Gz+zV5KIlZvosMrGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAILjzKgYv78JRv+O3iEj//v1VNm7cOGf82muvqTknT54MtzDEBKvwu1OnTiq75557nPGoUaPUnBMnTqjML/wW0R1vhw8fruZYvxc/+9nPVOZ3hX/qqafUnNzcXJUBwPno16+fyu677z6VDRgwQGW7du0q9vNb3cJvuOEGlRUUFDhjq/jcumEKKi6rONt/rLYeIxMS9NPfxMRElVWvXt0Z16lTJ6KPs262cuDAAWccK8XhvKIBAAAAIDgOGgAAAACC46ABAAAAILjzqtEoS9b74a0GPw8++KDK/PfsZWRkhFtYhCJp6mLNsd43aM3Lz893xjRaC8v6nvuN+ETs9/jecccdznjKlClqzssvv6yytWvXqqxz587ftkwRERkxYoTKLrnkEpXt37/fGcfHxxf7uQGftW+Sk5NV5r+3WUS/R96qCfLniMTOe5mrqm7duqns0KFDKrv33ntVtnr1amds1WNcf/31KvvRj36ksq5duzrjhg0bqjnUaFRc1uOy1cDRf/zr27evmmM1ebQaQDdp0sQZ169fX83JyspSmfW4/+mnnzrjWKkV5hUNAAAAAMFx0AAAAAAQHAcNAAAAAMFx0AAAAAAQXIUpBveLfKyCmxtvvFFlI0eOVNnjjz/ujI8cOXJ+izuLVYxkFT1aDVz8oiWr8YtVcJySkqKyrVu3OmOr2dupU6dUhshYNyO46KKLVPad73xHZStXrnTG//Vf/6XmbN68WWV+gb+IyNKlS51xrVq11ByryZV1UwF//1mfK+TvCqoGv9lVly5d1JyhQ4eqLDU1VWX+dWrVqlVqTmZmpsr27NmjMm6AUXn84x//UNm8efNUZjU58x/HrGvUBx98oLIrrrhCZf418Pjx43qxqLCs519paWkqe+SRR5zxwIED1Rz/cVpEZP369Srzr1kbN25Uc/znYyL2zV2sx/hYwCsaAAAAAILjoAEAAAAgOA4aAAAAAILjoAEAAAAguApTDO53m23fvr2ac/XVV6vs6NGjKlu0aJEzjrTgyyo08ouCrcLsDh06qOzCCy9Umd/ZvE2bNmqO1anU6oTqFxo9/fTTao7fUVXE7robCf97U9U79VrF/FZBWYsWLVT26KOPOmOrwCzSQlb/53XixAk1x+pka31+/3fMuokBYpt1DWzWrJkzvv3229Wc2267TWXWDT327dvnjK3fjTfeeENl06dPV5nf6Z7i8IqrefPmKrO6gO/du1dlzz33nDPOy8tTc06fPq0yaz/4NxWwupOj4rKed1jPARcsWOCMredVGzZsUNmf//xnle3atcsZW4/B1rqsebF6jeIVDQAAAADBcdAAAAAAEBwHDQAAAADBcdAAAAAAEFyFKQb3OxlbxWN169ZVmVUk6HdytAocrSw5OVllbdu2dcbDhw9Xc/r27auyzp07q2z37t3O2CoWsjp8+8VIIrowedy4cWrOE088oTKrcCoSflF8UVFRlS5ssorH+vTpozKrCNH/OYcsnLcKuK2CdKuzud9hNycnJ9i6UPlY18AGDRqozL/m3XjjjWpOpMWWfmfmYcOGqTktW7ZUmdXpfurUqc44OztbzanqN60ob506dVLZli1bVObfxKJ3795qzrXXXqsyv8BfRGT27NnOOD09Xc0ZMGCAyqwO9v6NBkp7cxREh/X7bN1A4Nlnn3XG1g2BLrvsMpVZe2bdunXOOFa7e58PXtEAAAAAEBwHDQAAAADBcdAAAAAAEFxUajSs9wb77/G13nNpvT/vo48+UtmOHTucsd+oTEQkLS1NZZdffrnKrrnmGmdsNW377LPPVPbHP/5RZX4jQev9/db75q16Ff/v1Lp1azXHaphV2hqNpKQkZ1xUVGQ2TqrKrO9dpM3ySsuvtbDeC2+9p91y4MABZ2z9XiB2+PUSIiJXXHGFyh544AFn3KRJEzXn7bffVtmrr76qsjp16jjjBx98UM255JJLVHbPPfeozK9d89/LL2LXwSEyVj3iv//7v6vMf1wT0fWBhw8fVnOs649V2+g3v83MzFRzevbsqTLrffkbN25UGSo36/HWr/Wxanmt54BDhw5V2Zw5c5yx/zh6LpHUBlu1lNbvhVWj5teK+DWYFQmvaAAAAAAIjoMGAAAAgOA4aAAAAAAIjoMGAAAAgOBKVAweFxfnFLOUtui1Ro0aKuvVq5czvuqqq8yv79u3b5/K/MZ+fgGiiMgNN9ygMqvpnV8A/Otf/1rNmT9/vsoyMjJU5rO+f9bf0SoE8pvIWMXzVgPC0qpZs6YzLiwsrNLF4AcPHlSZVVxo7S3/+27td+tGAFYRmF/QP2bMGDXHv2HBuaSkpDhja6+harL2lt+MVETkpptuUpl/bbZufvG3v/1NZQsXLlRZrVq1nLG/J0Xsm1h069ZNZWPHjnXGVpHwmjVrVGb97kXi7N+XqtgI0P/ZWA31evToobJNmzapzG+EZzWitYpqreaj1113nTNOTExUcwYNGqQy6+Ydq1evVhmqHn//bd26Vc356quvVHb77berbNSoUc74nXfeUXMiucGRiL4Bh3Wjn/bt26vM2vP+TRiWLVum5pT2Whcar2gAAAAACI6DBgAAAIDgOGgAAAAACI6DBgAAAIDgSlQMXr16dafo5eTJk6X6olZhS5cuXZxxu3bt1ByrePq+++5T2dy5c52xVYxrFdVaBWuvv/66M541a5aa43doPNdaS8svxBYRadCgQbEfF7Irrv93rIrFkGezCr937twZ0cf6e2v37t1qzqFDh1Rm7Xm/S3K/fv3UnOzsbJVZ3Zv9grWq/jPEv1hdwPv06aOyrl27qmzDhg3O+M0331RzVqxYoTLrd8h/zJgxY4aaU69ePZVNmDBBZSNHjnTGVtdn63fW7xocqbOvw0VFRaV+/Kuohg0b5owHDx6s5lg/Z6s41mfdHMUqxvVvPGCtq1mzZmqOde209hadwSu3SLpti+jnTNZNJ3bt2hXR1xw/frwztp57WZ+/Q4cOKvNvVGSxbtxh3cTAL/S2uoxXFBV3ZQAAAAAqLQ4aAAAAAILjoAEAAAAgOA4aAAAAAIIrUTF4fn5+kG7CVpGyX3D46aefqjlWx9jOnTurzC+YtTpr79mzR2VvvPGGymbPnu2MrQLAkEW1ViFQmzZtVOYXz1sFx0eOHAm2Lv9nVtULia2/38yZM1V2xRVXqOzqq692xi1btlRzsrKyVGYVcPt7/qOPPlJzrA7M3bt3V5lfLGb9XqBq8K8jF154oZozevRolVk36vj73//ujD/88EM1J9JrjX+TjH379qk5H3zwgcouuugilfldzIcPH67mzJs3T2V+R10R3UnYKqw8u2t1YWGh2W24MvO7r1vXh5dfflll/s1XLFaH4s8//1xl1p5s2rSpM7b2glVY/vbbb6ssJyfn25aJKPKfW1rPhazngFYnbf96d8EFF6g51o0vrL3l30jDem5g3dzl4MGDKluwYIEzzszMVHO2b9+ush07dhT7+a2bElUUvKIBAAAAIDgOGgAAAACC46ABAAAAILgSvUm7qKgoyHvzT506pTK/FmLlypVqTlJSksr8WgURkR//+MfO2G/sJCLy8ccfq2zJkiUq85tOlXVtQnJyssqsJm3++/6nTZum5uTm5gZbl/8e21is0Vi2bJnKxo0bp7JHHnnEGffo0UPNsd5X+uWXX6rMf5/x2rVr1RyrsZbVqMz/XbHej2/VYFX1n3VVVKtWLWc8dOhQNad3794qW7duncr8mgyrvqi0e8T6OOs9ylaj1P79+zvjgQMHqjl+Hce5Pr/fvMtqrHV2DcipU6eqXI2Gv2esxoaRNi2NhFXzdu+996rMr12zfn7PP/+8yqx6Npy/sx8jSvt7b9VA+c9prrzySjXHqj206s/82t0DBw6oOf5+F7EfE/0mj3/+85/VnOXLl6vMqpv1n/v6tWEidrPnkA2go4FXNAAAAAAEx0EDAAAAQHAcNAAAAAAEx0EDAAAAQHBR6dhlFRD5jfD84rxzsQoT/QZ3ffv2VXP8Ah8Ru8FKWRbCWoW3jRs3VplVtOk3OLQK2UM2cKnsxUglZf3craZTX3/9tcoeffRRZ2wV+Fufy2pk6TcCsorHrM9lNdtq1KiRM7aK4VA19OzZ0xnfcMMNao61L7/44guV+deasr45gH8DDhG7KVyfPn2c8f3336/m3HjjjSqzbqjw/vvvO2OrmdfYsWPP/HdeXp5MnDhRzanM/KaLKSkpao51I5fSys7OVtmMGTNU5u9lq/D2rbfeCrYunFvNmjWd5y3WY1YkGjRooDL/xg133HGHmtOwYUOVWTcV+J//+R9nbD2ftK5/1s1dtm3b5oz9a4UIjSCLwysaAAAAAILjoAEAAAAgOA4aAAAAAILjoAEAAAAguKgUg4fkF5GLiKSnpzvjzz77TM2xOkVaxdkh+Z/fKra74oorVNaxY0eVvfHGG87YKoqPtQLuimLv3r3OONJ9FUmRrdVR1cpq1qypMr/Tr7X/UPlUr15dZSNHjnTGVid6q3OyleXm5p7H6sKwulTPnz/fGV9++eVqTo8ePVRmFZn618p+/fqpOYMGDTrz30ePHj3nWisrv9O5dX2wvserVq0KtgbrZhf+9bN27dpqTsgbn+DcTp8+HeR5Ul5enspWrFjhjK2v4xdmi4gsW7ZMZf5jsPU80drf1vPCw4cPO2MKv0uOVzQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwlb4Y3Cp4Xr9+vTP+wx/+oOZYxdNWR9pIRFocVaNGDWfsd7YVEbn55ptVlpGRobJ58+Y544pQsAlbNDop79u3T2X16tVzxn7XcVRO7dq1U9mQIUOcsdU93iqi3L59u8oqwk0lrGJOf/1TpkxRc5o3b66ygQMHqsz//nTq1EnNObvo3irAr+z87skHDx5Uc66//nqV+V2YReyi7kikpqYW+7l27txZqs+N81fan6vPeszyn9N8+eWXEX19q1t9JI+5VlF3yBsb4F94RQMAAABAcBw0AAAAAATHQQMAAABAcJW+RsN6L57/3vMjR46oOaV9r6HVHM1qIFSrVi2VNWrUyBlb9Rj+HBGRF154QWUbN250xhXhfdQoe9Z+t/a39R7Y+vXrO+M6deqEWxiipkuXLipr3LixM/abYYmIrFmzRmUVtRmVte/9moJ33nlHzencubPKfvCDH6isZ8+ezti6fi9duvTMf1sNxyo7/zHlq6++UnO+853vqOz//b//pzL/MctqqFe3bl2VtW3btth17tmzp9g5qHz85zDHjh0r069X1rWT+Bde0QAAAAAQHAcNAAAAAMFx0AAAAAAQHAcNAAAAAMFV+mJwi19UFLJQumbNmiq75JJLVOY3zBLRTaDat2+v5nz44Ycqmz59usqsBlao+qwCthMnTqjMKpjcsWOHM7aauKFk/Gad1s0iQjW5Otfn37Bhg8r8JmqZmZlqztnFzd+wml9VVP51fdu2bWrOe++9p7IePXqorFWrVs7Y+n6dfW2uitdf/0YAn3zyiZpz1VVXqezhhx9Wmd94749//KOac+WVV6qse/fuKvN/FgsXLlRzAFRcvKIBAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACCq5LF4GWpevXqKrM6895xxx3Ffq5Jkyap7LnnnlOZ1eUZ+IZVuHrfffepbN++fc64KnY3Lm9+cX7Iwm+LdWMLv6OziMjXX39d7MdZ3ZorM6tA27q5xt69e1XWtWtXZ5ydna3mLF68+Mx/h7zBSEX1wQcfqGzgwIEqu/3221XmP/5deOGFak6bNm1U1qBBA5X5Hd/nzp2r5gCouHhFAwAAAEBwHDQAAAAABMdBAwAAAEBwHDQAAAAABEcxeAlZBYfr1q1T2fz581W2e/duZzxjxoxi5wDFOXbsmMr8YmDElqrYubo0rBtpWB3R09PTnbFV1H/299S/CUBVdOLECZW99tprKrMKvUeMGOGMrS7gliVLlqjMumkKgMqDVzQAAAAABMdBAwAAAEBwHDQAAAAABEeNRgnFx8errFmzZipr165dsfPWrl2r5mzYsEFlR48eLckSEWOsJpJ16tRRWU5OjjM+depUma0J0ZWQ4F7arZqCsm4uWBFYvxstW7ZUWVpamjO2rrlbt249899FRUXq9ykW9O3bV2UtWrRQmf/927Fjh5rTsGFDlTVp0kRl/fr1c8ZnN04EUPHxigYAAACA4DhoAAAAAAiOgwYAAACA4DhoAAAAAAiOYvASqlZNn83y8/NVlpmZqTK/aO573/teRF/z1VdfVVlhYWFEH4uqLzU1VWX333+/yvwCzcmTJ6s527dvV1ksNCcrrbi4uG8di4T9XbWuP1YBbffu3Z3x/v371ZyNGzeqzGpwV1n4BfAiIn369FHZ+PHjVdahQwdnbH2/3nrrrTP/nZ+fL1OmTCnNMiuNgQMHquyee+5RmXX9mT17tjN+6aWX1JxLL71UZbfddpvKxo4d64w//vhjNce6iQqAioFXNAAAAAAEx0EDAAAAQHAcNAAAAAAEF1GNBu/R/hfre2HVaBw7dkxleXl53zoWsZuoVeTvf3msrSL//SsCqwbgxIkTKjt58mSxH1fZvtfltd5zfZ3y/n5ZX8/6OZ4+fdoZW835KtvPujjW38f/PojYdSj+tdi6fp99nf/mv6O9/8qS9b2zHrOs5ob+98/6XNY1ymqC6H/NWGg0WRI8BiOaItkbcUURzNq5c6fZTRXIzMw0O8OGxP7DuZTH/hNhD8LG/kO08RiMaIpk/0V00CgsLJSsrCxJSUkx76qC2FNUVCQ5OTmSlpZm3gknJPYffOW5/0TYg3Cx/xBtPAYjmkqy/yI6aAAAAABASVAMDgAAACA4DhoAAAAAguOgAQAAACA4DhoAAAAAguOgEYHHH39c4uLinP916dIl2stCDMnJyZEJEyZI69atJSkpSQYOHChLly6N9rIQI9q0aaOugXFxcTJ+/PhoLw0x4Pnnn5cePXpInTp1pE6dOjJgwAD56KOPor0sxKjf/e53EhcXJxMmTIj2UiqFiBr2QaRbt24yZ86cM+OEBL51KD/33HOPrFmzRl577TVJS0uTyZMny4gRI2TdunXSvHnzaC8PVdzSpUudRmlr1qyRK664QsaOHRvFVSFWtGjRQn73u99Jx44dpaioSF599VUZM2aMrFy5Urp16xbt5SGGLF26VF588UXp0aNHtJdSafCKRoQSEhKkWbNmZ/7XqFGjaC8JMeL48ePyzjvvyH/913/JpZdeKh06dJDHH39cOnToIM8//3y0l4cY0LhxY+f69/7770v79u1l6NCh0V4aYsDo0aNl5MiR0rFjR+nUqZM89dRTUrt2bVm8eHG0l4YYkpubK+PGjZOXX35Z6tevH+3lVBocNCK0efNmSUtLk3bt2sm4ceNkx44d0V4SYsTp06eloKBAEhMTnTwpKUkWLFgQpVUhVp06dUomT54sd911F827UO4KCgrkrbfekry8PBkwYEC0l4MYMn78eBk1apSMGDEi2kupVHj/TwT69+8vkyZNks6dO8vu3bvl17/+tQwZMkTWrFkjKSkp0V4eqriUlBQZMGCAPPHEE3LBBRdI06ZN5c0335RFixZJhw4dor08xJhp06bJ4cOH5Y477oj2UhBDVq9eLQMGDJATJ05I7dq1ZerUqdK1a9doLwsx4q233pIVK1ZQG1kKdAYvhcOHD0vr1q3l6aeflrvvvjvay0EM2LJli9x1110yf/58iY+Pl969e0unTp1k+fLlsn79+mgvDzHkqquukho1asiMGTOivRTEkFOnTsmOHTvkyJEj8s9//lP+93//V+bNm8dhA2UuMzNT+vbtK7Nnzz5Tm3HZZZfJRRddJM8880x0F1cJcNAopYsvvlhGjBghv/3tb6O9FMSQvLw8OXr0qKSmpsp3v/tdyc3NlQ8++CDay0KM2L59u7Rr107effddGTNmTLSXgxg2YsQIad++vbz44ovRXgqquGnTpsn1118v8fHxZ7KCggKJi4uTatWqycmTJ50/g4sajVLIzc2VLVu2SGpqarSXghiTnJwsqampcujQIZk1axZP9lCuJk6cKE2aNJFRo0ZFeymIcYWFhXLy5MloLwMxYPjw4bJ69WpJT08/87++ffvKuHHjJD09nUNGMajRiMDPfvYzGT16tLRu3VqysrLksccek/j4eLn11lujvTTEiFmzZklRUZF07txZMjIy5Oc//7l06dJF7rzzzmgvDTGisLBQJk6cKLfffju390a5euSRR+Saa66RVq1aSU5Ojrzxxhsyd+5cmTVrVrSXhhiQkpIi3bt3d7Lk5GRp2LChyqHxaBGBnTt3yq233ioHDhyQxo0by+DBg2Xx4sXSuHHjaC8NMeLIkSPyyCOPyM6dO6VBgwZy4403ylNPPSXVq1eP9tIQI+bMmSM7duyQu+66K9pLQYzJzs6W2267TXbv3i1169aVHj16yKxZs+SKK66I9tIAFIMaDQAAAADBUaMBAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAIDgOGgAAAACCi6gzeGFhoWRlZUlKSorExcWV9ZpQCRQVFUlOTo6kpaVJtWple15l/8FXnvtPhD0IF/sP0cZjMKKpJPsvooNGVlaWtGzZMsjiULVkZmZKixYtyvRrsP9wLuWx/0TYg7Cx/xBtPAYjmiLZfxEdNFJSUoIsCFVPeewN9h/Opbz2xjdfZ+TIkVK9evUz+a9+9StnXsOGDdXHbtmyRWV33XWXynbs2HG+yzzj7DWKiLRp00bNufzyy1XWpUsXlWVnZzvj2bNnqzkrVqxQWWFhYXHLrPTKe/8Bvqr6GNy5c2eVWdentWvXqiwjI6NM1gQtkr0R0UGDl8pwLuWxN9h/OJfy2hvffJ3q1as7T+Jr167tzKtTp4762OTkZJWV9Vsd/O9LfHy8mlOzZk2VJSUlqSwxMdEZJyToh41Y/R0t7/0H+KrqY7B1zfL/AeVc81B+ItkbFIMDAAAACC6iVzQAACLbt293/gVt8uTJzp9brxIcOXJEZceOHQu/uLOcOnXKGW/evFnN2b17t8qsl8FzcnKc8fHjx9WcgoKCki4RAM5p3bp1EWWo+HhFAwAAAEBwHDQAAAAABMdBAwAAAEBw1GgAQISys7OdO0Z9/PHHzp+fPn1afYx1JyerzqEsWTUUR48eVVlubm5EHwsAQCR4RQMAAABAcBw0AAAAAATHQQMAAABAcBw0AAAAAARHMTgARKhLly6SkPCvy+YDDzzg/HmjRo3Ux2RkZKjskUceUZnfGC+kGjVqqKxJkyYqs9a/f/9+Z3zgwAE1p7yL2wEAlQOvaAAAAAAIjoMGAAAAgOA4aAAAAAAIjoMGAAAAgOAoBg8gLi5OZUVFRVFYCYCy1KBBA6levfqZcbdu3Zw/b9iwofoYqzN4zZo1g63Juv6kpKQ44z59+qg5t9xyi8p69OihMr8Y/PXXX1dz3nvvPZWdOHFCZVwXAURi8ODBKhs6dKjK0tPTVfbhhx86Y6470cUrGgAAAACC46ABAAAAIDgOGgAAAACC46ABAAAAILiYKAa3CjSbN2+ustTUVJUlJiY641q1aqk5zZo1U5lVCHn48GFnvHnzZjVn2bJlKgO+jVVsfN1116ns5ptvdsb+3hYR+etf/6qyDz74oPSLq2IaNmzodNnOzs52/nzr1q3qY6wO3NY1w//YSAsYra7fgwYNcsYPP/ywmtO5c2eVbdq0SWV+wfsvf/lLNSc/P19lc+bMUdmRI0dUBqBy8q891arpf7suKChQmXW98O3YsUNleXl5KvvhD3+osiuvvNIZv/zyy2rOmjVril0DwuAVDQAAAADBcdAAAAAAEBwHDQAAAADBVfoajXr16qnsmmuuccb9+vVTczp06KCyRo0aqcyvybAabVmZ9V7FY8eOOePFixerOb///e9VtmHDBpUhNlkN1SZMmKCy/v37q8xv7Hb8+HE1Z9y4cSr7/PPPVXb06NFvW2aV1b17d6cmxq9zsequrJ9F9+7dVfbll18649OnT0e0JqtGo3fv3s740ksvVXMWLFigsscee0xlXbp0ccaPPvqomvPjH/9YZV9//bXKVq5c6YwLCwvVnGjwr9dWfQxNvxDrLrzwQomPjz8ztq4rPuu50KuvvqqyQ4cOOWOrRmPSpEkqs2pA/OuR9Xi1e/dulR04cEBlZzdoFbGfc+7bt09l+Bde0QAAAAAQHAcNAAAAAMFx0AAAAAAQHAcNAAAAAMFV+mLw4cOHq+yhhx5yxq1bt1ZzTp48qTKreHH79u3O2CpetIqDevbsqTKrSaDPKhzdtWuXynJycor9XKj8Bg4c6IytYt2uXbuqbMaMGSp79913nbG13+vUqaOyWC38tvTs2VNq1659Zuw35ty2bZv6mLPnf2Pw4MEqmzJlijP2iyPPxS/yF7FvUOFLT09X2apVq1TmXwMvu+wyNcfag1ajQgCV1/e//33nZhiNGzd2/ty6pviNYkXshsYvvPBCsV/fb3osoq+bIiJ9+/Z1xiNHjlRzDh48qLJPPvlEZX369HHGCQn6afPkyZNVZt1sJVbxigYAAACA4DhoAAAAAAiOgwYAAACA4DhoAAAAAAiu0heDW8XZKSkpzrhhw4Zqzv79+1VmdX71C3+sj7M68+bm5qrML7Rt0aKFmnPPPfeo7Oziq2+8+eabzvjIkSNqDiqXm266SWU//elPnXFycrKa84c//EFlf/7zn8MtDGfUrl3bub6sWLHC+XOrGHznzp0qs25Q0bJlS2dsFT5a1yjrGnjs2DFn7Bd0i4h89dVXKrOuW/6NJ2bPnq3mdO7cWWV169ZVmX89PXXqlJoTDf41PD8/X82xOhCjcjm7q7U1FrGLfa3u1lbms4qeS7vn/XUVFRVFZU+efQ1au3at82eLFi1S8y+55BKVWc9pSmvv3r0q+/Wvf+2M77jjDjXn2muvVdm///u/qywrK8sZ/+IXv1BzKPz+dryiAQAAACA4DhoAAAAAguOgAQAAACA4DhoAAAAAgqv0xeBW8dEzzzzjjIcOHarmdO/eXWVWJ1u/QNMqvmrUqJHKrGInv3jMmmMVVVqZ/7EUg1cuo0aNUtkvf/lLlbVr184ZT5gwQc2ZNGlSqGWhGGlpac5NHT766CPnz/fs2aM+xsp69eqlsosuusgZW53brS7tVoH46dOnnbFV9GoVs1qfy+8y7t9sw/p65/pcVuF6ReCvy1o7KgZrL1evXl1l1k1gOnXq5Iy7dOmi5vg3bRGx961/AwFrXXPnzlXZ4sWLVeYXiFufq0OHDs64oKBANm/erOaVpWPHjjnfi4ULFzp/vmrVKvUxs2bNUlmbNm1U5v8sNmzYUMpVimzdutUZ//a3v1VzDh06pLLLLrtMZf7esm4WgG/HKxoAAAAAguOgAQAAACA4DhoAAAAAgqv0bzaz3v/86quvOuOZM2eqOW3btlVZ8+bNVeY31ho8eLCa07RpU5VZ7+Pz6yg2bdqk5nz++ecq+8c//qEy6++NiqlZs2Yqe/DBB1Vm7Zlf/epXzph6jOjaunWr1K5d+8x4zpw5zp+np6erj3n33XdV9vDDD6vsxhtvdMbW+51Xr16tMqs+wq/lsPZWx44dVdagQQOV1apVyxkPHDhQzfHrOEREsrOzVVZRazT82jtqNKIjMTFRZf6etGoWe/bsqbJu3bqpzN/z1n73G7SJiOzYsUNl9erVc8Z+jZWI3fjRapTp12hYNSf+3yc/P7/cazTy8vKc641/vbOajFp1Kg899JDKrr76amdsNRktbWM8v9ZWRNe8iIgsXbpUZX49yb333qvmWNc6v5lrLOMVDQAAAADBcdAAAAAAEBwHDQAAAADBcdAAAAAAEFylLwa3+AVDVuOrvLw8lVkFWL1793bGaWlpas7JkydV5jeMERFZsmSJM/7www/VHKsYaefOnSpD5XH77berzCocXL58ucq+/PLLslgSSmn+/PlOwapf8GcVBfpN/URErrjiCpVdfPHFzvjaa69Vcw4ePKiyAwcOFJtZBeN9+vRRWd++fVXmF03269dPzZk3b57KMjIyVFZRi6xp2Ff+rMfbSy+9VGXf+973nLHVZM9qfms1ZPN/X62Gv9ZNWvbv368y/4YyV111lZqzcuVKlUVS0Gz9vvqF31bz4LK2evVq5+dmfY99VuM9q4jdf0xs3769mrNmzZoIVqlv4vPd735XzbGu1f/xH/+hMv85n3X9swrEraL/BQsWOGPre2P97EPym1ZamfW98b/3RUVFERfn84oGAAAAgOA4aAAAAAAIjoMGAAAAgOA4aAAAAAAIrkoWg/tdav0iSxGRYcOGqeySSy5RmV8kYxWRW51/P/nkE5UtW7bMGW/btk3NqaidcxE5v5OyVfjbsGFDlVndbX/5y18647Vr16o5Vud4q0M1zt/UqVOdLtt+0ZxVoGkVPr7yyisq8wsRf/rTn6o5jRo1UtmsWbNU5ncttq4r1jXQKtD1O+MeO3ZMzbFubLFv3z6VVdQi64q6rqrM2muDBw9WmV8M7hfUiog8++yzKrOKcXfv3u2MrWJmqxg3Li5OZf5zAeumLdbvgN8F3GKtYf369c44Gnt23bp1Uq3a+f/7tHWTE/9GAEOGDFFzrO9njx49VOZ3GbduTDFjxgyVRXLjHWvt/tcTEbnuuutU5hel//3vf1dzJk6cWOwaInXzzTer7L777lNZSkqKMz5x4oSaM3PmTGd88uRJ+cMf/hDROnhFAwAAAEBwHDQAAAAABMdBAwAAAEBwHDQAAAAABFfpi8GtLqGjRo1yxlYxbteuXVVmFcD4nbqtwlu6eeNsfnflOnXqqDlWx9gdO3aorEGDBs747rvvVnNuu+02lVn79Fe/+pUztm5sgG+3cuVKpzA0ksJO6/tsFSL6BaA///nP1ZwHHnhAZXfeeafK/GuZVURusYpxff/85z9VZt3coHHjxirzr4sVpQjbL3C11lVR1lpVWEXFVtG133142rRpas706dNVduTIkdIvzmP97P3Pb329kHsmPz8/2OcqraysLPNnVFJW9/UDBw4443vuuUfNGTBggMqsmwosXLjQGU+ePFnNycnJKXadFqubt1Vsbt20wC9wt24UEtLWrVtVZt2oyO/6nZqaqubs2bPHGZdkP/KKBgAAAIDgOGgAAAAACI6DBgAAAIDgKkyNhv9+zXbt2qk5gwYNUtmVV15Z7DzrvWRWMx+r6dRnn33mjK335wFnu+yyy5yx30BSROTJJ59UmVVX4X9sr1691JwJEyao7JZbblGZXyvg12ygeJHUZETCej/31KlTnfHBgwfVHL95mYjIBRdcoDJ/31ifq1WrVipLTEzUi/VYdXF+M1IRkfj4eJX57++m7iE2WO/rT0tLU1nv3r1VtnfvXmdsvff96NGj57G60onFvWs1JC0N//3+IiLz5s1zxlYjvqSkJJVNmjRJZX4TU6sBYkjW57euiVZWlirCGkR4RQMAAABAGeCgAQAAACA4DhoAAAAAguOgAQAAACC4EhWD16hRwynqOnnyZKm+aJMmTVTmN9mzirytQrH69eurbOPGjc7YKrKdP3++yqxCb6uJH/Bt/AZCWVlZao7VsM/i/44tXrxYzXn44YdV9vLLL6vMb3ZkNVnzmyah/Pg/67lz56o5y5cvV1m9evVU5hetW02tOnbsqLLrr79eZX6xudWg9KOPPlKZte8LCwtVVhFU1HVVZS1btlRZ27ZtVeY3E8vOzlZzYrEwu6p59dVXnfHHH3+s5lhF/6VtvIfywysaAAAAAILjoAEAAAAgOA4aAAAAAILjoAEAAAAguBIVg9euXdvp4F3aYvBGjRqprF+/fs7Y6j5rdV9ctGiRyqZMmeKMrUJFq1MuEMK+ffucsXVDgbN/j87X9u3bVbZ7926VderUyRmnpqaqORSDVxxWF3Lr51Pan9nOnTtVZt2koEGDBs7Y39/nswbELutmFHXr1lWZXwxuPe+wOtpbBf7+cwhuAlBx+D+LXbt2RWklCI1XNAAAAAAEx0EDAAAAQHAcNAAAAAAEx0EDAAAAQHAlKgYPVUC9bds2lb3++uvO2OqKW1BQoLKvv/5aZevXr3fGeXl5JVsgcB5Wr17tjEePHq3mDBs2TGWbNm0q1de76qqrVJaWlqYy//fOKhhH7LCKza2uy1YGlER8fLzKmjVrpjKrqNsvEL/yyivVnLi4OJUdP35cZRkZGc7Yei6Sm5urMorGgdLjFQ0AAAAAwXHQAAAAABAcBw0AAAAAwZWoRiMU672TCxYsiMJKgPCWLl3qjA8fPqzm3HnnnSpr3Lixyo4ePeqMhwwZouZcfPHFKrPef+/XQdFkDUB5SEpKUlmdOnVUZtVa3HLLLc74hhtuUHNq1aqlMqsp6ooVK5zx22+/reZMnz5dZVadEnUbQGR4RQMAAABAcBw0AAAAAATHQQMAAABAcBw0AAAAAAR3XsXgTZs2dcY1atRQc6xmeaEa/wEVkd/w6d1331VzHnzwQZX96Ec/Ull+fv63jkVE9u/frzKr4eWUKVNUBgBl7cSJEyqbP3++yk6ePKky/3pqPado2LChyrp06aKygQMHOuNf//rXao5VRP7WW2+pzLrJBwCNVzQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwJSoGv/rqq6V69epnxsOHD3f+3CpUTUxMVNmzzz6rsg0bNpRkKUCl8eabb6rsww8/VNkFF1ygsvj4eGe8d+9eNcfvHi5id7IFgGiwnhssXLhQZYsWLVKZ34Hb6shtdRRPS0tT2fjx453x/fffr+Z069ZNZVbn8SNHjjjjoqIiNQcAr2gAAAAAKAMcNAAAAAAEx0EDAAAAQHAcNAAAAAAEV6Ji8N69ezvF3f369XP+PCcnR31Ms2bNVDZv3jyVUQyOWOIXEoqILF68OAorAYDyV1BQEFHmszp3t2jRQmVXX321yoYNG+aMd+/ereZ88cUXKrNuuEHxNxAZXtEAAAAAEBwHDQAAAADBcdAAAAAAEFyJajQOHTokNWvWPDP2azKOHTumPsZ6L/qhQ4dK8mUBAEAVcvZziW/UrVtXZX6zPKvu8+abb1bZNddco7KTJ08647/97W9qjlVDaj23ARAZXtEAAAAAEBwHDQAAAADBcdAAAAAAEBwHDQAAAADBlagYfPr06U6znIyMDPeTJehP5xdfidgNcQAAQOXnN9Vr1aqVmtOrVy+V9e7dW2WdOnVyxn369FFzGjVqpDKrAerLL7/sjD/99FM15/DhwyqjOR9QeryiAQAAACA4DhoAAAAAguOgAQAAACA4DhoAAAAAgitRMfiuXbuccWZmZtDFAACAyq1Dhw7OeMKECWrO9ddfrzKrqNu/ycymTZvUnBdeeEFlkydPVtnGjRudcX5+vpoDICxe0QAAAAAQHAcNAAAAAMFx0AAAAAAQHAcNAAAAAMGVqBgcAADg23Tr1s0Z9+vXT82pXbu2yrZv366ydevWOeMpU6aoOTNnzlTZgQMHVEaHb6D88YoGAAAAgOA4aAAAAAAIjoMGAAAAgOCo0QAAAMHs3bvXGe/YsUPNadeuncoaNGigMr/e44orrlBzTpw4obKFCxeqLDs72xkXFBSoOQDC4hUNAAAAAMFx0AAAAAAQHAcNAAAAAMFx0AAAAAAQXImKwZOTkyUuLu7MuE2bNu4nS9CfzirS2rBhQ0m+LAAAqCRWrVrljJ999lk1Z+3atSq78MILVda6dWtnfPXVV6s5AwYMUNn06dNV9uabbzrj1atXqzmnTp1SGYDS4xUNAAAAAMFx0AAAAAAQHAcNAAAAAMFFVKNRVFTk/P83/GY3Z9dvnGsOqhZ/T1TWr4HKqbz2BnsQFvafzV/v6dOn1RyrfvPYsWMqy83NdcY5OTnFzjnX5/efj1S276uFx2BEUyR7I6KDxje/2P5FYP369aVYFqqSnJwcqVu3bpl/DcBSHvvvm68D+Nh/try8PGc8b948NcfKUHI8BiOaItl/cUURHEcKCwslKytLUlJSzFctEHuKiookJydH0tLSpFq1sn0HHvsPvvLcfyLsQbjYf4g2HoMRTSXZfxEdNAAAAACgJCgGBwAAABAcBw0AAAAAwXHQAAAAABAcBw0AAAAAwXHQAAAAABAcB40I5eTkyIQJE6R169aSlJQkAwcOlKVLl0Z7WYgRu3btku9///vSsGFDSUpKkgsvvFCWLVsW7WUhhrAHES2PP/64xMXFOf/r0qVLtJeFGPW73/1O4uLiZMKECdFeSqUQUcM+iNxzzz2yZs0aee211yQtLU0mT54sI0aMkHXr1knz5s2jvTxUYYcOHZJBgwbJsGHD5KOPPpLGjRvL5s2bpX79+tFeGmIEexDR1q1bN5kzZ86ZcUICT19Q/pYuXSovvvii9OjRI9pLqTT4TY3A8ePH5Z133pH33ntPLr30UhH5v39hmTFjhjz//PPy5JNPRnmFqMp+//vfS8uWLWXixIlnsrZt20ZxRYg17EFEW0JCgjRr1izay0AMy83NlXHjxsnLL7/M874S4K1TETh9+rQUFBRIYmKikyclJcmCBQuitCrEiunTp0vfvn1l7Nix0qRJE+nVq5e8/PLL0V4WYgh7ENG2efNmSUtLk3bt2sm4ceNkx44d0V4SYsz48eNl1KhRMmLEiGgvpVLhoBGBlJQUGTBggDzxxBOSlZUlBQUFMnnyZFm0aJHs3r072stDFbd161Z5/vnnpWPHjjJr1iz58Y9/LD/5yU/k1VdfjfbSECPYg4im/v37y6RJk2TmzJny/PPPy7Zt22TIkCGSk5MT7aUhRrz11luyYsUK+e1vfxvtpVQ6cUVFRUXRXkRlsGXLFrnrrrtk/vz5Eh8fL71795ZOnTrJ8uXLZf369dFeHqqwGjVqSN++feWLL744k/3kJz+RpUuXyqJFi6K4MsQK9iAqksOHD0vr1q3l6aeflrvvvjvay0EVl5mZKX379pXZs2efqc247LLL5KKLLpJnnnkmuourBHhFI0Lt27eXefPmSW5urmRmZsqSJUskPz9f2rVrF+2loYpLTU2Vrl27OtkFF1zAWwdQbtiDqEjq1asnnTp1koyMjGgvBTFg+fLlkp2dLb1795aEhARJSEiQefPmyV/+8hdJSEiQgoKCaC+xQuOgUULJycmSmpoqhw4dklmzZsmYMWOivSRUcYMGDZKNGzc62aZNm6R169ZRWhFiDXsQFUlubq5s2bJFUlNTo70UxIDhw4fL6tWrJT09/cz/+vbtK+PGjZP09HSJj4+P9hIrNO46FaFZs2ZJUVGRdO7cWTIyMuTnP/+5dOnSRe68885oLw1V3IMPPigDBw6U3/zmN3LzzTfLkiVL5KWXXpKXXnop2ktDjGAPIpp+9rOfyejRo6V169aSlZUljz32mMTHx8utt94a7aUhBqSkpEj37t2dLDk5WRo2bKhyaLyiEaEjR47I+PHjpUuXLnLbbbfJ4MGDZdasWVK9evVoLw1V3MUXXyxTp06VN998U7p37y5PPPGEPPPMMzJu3LhoLw0xgj2IaNq5c6fceuut0rlzZ7n55pulYcOGsnjxYmncuHG0lwagGBSDAwAAAAiOVzQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwHDQAAAAABMdBAwAAAEBwHDQAAAAABPf/ATmaTQUuIEUlAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_test[i], cmap=plt.cm.gray)\n",
        "    plt.xlabel(y_test[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "911e1e99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "911e1e99",
        "outputId": "df91bc89-791e-4545-b6ed-60f8d2a49d1b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "unique_classes_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "unique_classes_test, counts_test = np.unique(y_test, return_counts=True)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(unique_classes_train, counts_train, color='skyblue')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Distribution of Classes in y_train')\n",
        "plt.xticks(unique_classes_train)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(unique_classes_test, counts_test, color='skyblue')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Distribution of Classes in y_test')\n",
        "plt.xticks(unique_classes_test)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "667497e6",
      "metadata": {
        "id": "667497e6"
      },
      "source": [
        "## 3 - CNN Modele"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41313d6c",
      "metadata": {
        "id": "41313d6c"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "38b41552",
      "metadata": {
        "id": "38b41552"
      },
      "outputs": [],
      "source": [
        "outer_k_folds = 5\n",
        "inner_k_folds = 5\n",
        "epochs_cnn = 15\n",
        "monitor_callback_cnn = \"val_accuracy\"\n",
        "patience_callback_cnn = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a07bf8",
      "metadata": {
        "id": "53a07bf8"
      },
      "source": [
        "### Modele"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "942c8af6",
      "metadata": {
        "id": "942c8af6"
      },
      "outputs": [],
      "source": [
        "# Function to create CNN model\n",
        "def create_cnn_model(dropout_rate=0.3, learning_rate=0.001):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(dropout_rate),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(dropout_rate),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=RMSprop(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "99349f44",
      "metadata": {
        "id": "99349f44"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid for inner CV\n",
        "param_grid = {\n",
        "    'dropout_rate': [0.2, 0.3],\n",
        "    'learning_rate': [0.0001, 0.001],\n",
        "    'batch_size': [64, 128]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cbcf05e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cbcf05e",
        "outputId": "95701267-3fad-48e1-c414-647dcaf7e410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Outer Fold 1/5 ===\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2208 - loss: 2.3151 - val_accuracy: 0.3775 - val_loss: 1.8508\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4317 - loss: 1.6089 - val_accuracy: 0.6689 - val_loss: 1.0458\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5736 - loss: 1.2408 - val_accuracy: 0.7555 - val_loss: 0.7760\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6756 - loss: 0.9746 - val_accuracy: 0.8128 - val_loss: 0.5883\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.8064 - val_accuracy: 0.8496 - val_loss: 0.4826\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.6669 - val_accuracy: 0.8746 - val_loss: 0.4124\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.5896 - val_accuracy: 0.8847 - val_loss: 0.3664\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8320 - loss: 0.5219 - val_accuracy: 0.8998 - val_loss: 0.3287\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 0.4589 - val_accuracy: 0.9068 - val_loss: 0.3042\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8725 - loss: 0.4083 - val_accuracy: 0.9173 - val_loss: 0.2761\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8823 - loss: 0.3755 - val_accuracy: 0.9225 - val_loss: 0.2635\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.3548 - val_accuracy: 0.9226 - val_loss: 0.2554\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8984 - loss: 0.3272 - val_accuracy: 0.9236 - val_loss: 0.2522\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9012 - loss: 0.3016 - val_accuracy: 0.9302 - val_loss: 0.2394\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9099 - loss: 0.2834 - val_accuracy: 0.9329 - val_loss: 0.2311\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2101 - loss: 2.3218 - val_accuracy: 0.4422 - val_loss: 1.6525\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4333 - loss: 1.6094 - val_accuracy: 0.6925 - val_loss: 0.9943\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5853 - loss: 1.2169 - val_accuracy: 0.7811 - val_loss: 0.7098\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6785 - loss: 0.9558 - val_accuracy: 0.8307 - val_loss: 0.5485\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7428 - loss: 0.7730 - val_accuracy: 0.8558 - val_loss: 0.4588\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7863 - loss: 0.6519 - val_accuracy: 0.8833 - val_loss: 0.3727\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8129 - loss: 0.5727 - val_accuracy: 0.8994 - val_loss: 0.3215\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 0.4979 - val_accuracy: 0.9123 - val_loss: 0.2892\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8563 - loss: 0.4523 - val_accuracy: 0.9196 - val_loss: 0.2714\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.4105 - val_accuracy: 0.9253 - val_loss: 0.2439\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8780 - loss: 0.3776 - val_accuracy: 0.9278 - val_loss: 0.2357\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 0.3420 - val_accuracy: 0.9312 - val_loss: 0.2250\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8945 - loss: 0.3322 - val_accuracy: 0.9358 - val_loss: 0.2142\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9005 - loss: 0.3059 - val_accuracy: 0.9379 - val_loss: 0.2056\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9095 - loss: 0.2831 - val_accuracy: 0.9375 - val_loss: 0.2047\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.2129 - loss: 2.3320 - val_accuracy: 0.4576 - val_loss: 1.5979\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4459 - loss: 1.5785 - val_accuracy: 0.6942 - val_loss: 0.9684\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5949 - loss: 1.1854 - val_accuracy: 0.7893 - val_loss: 0.6816\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6852 - loss: 0.9358 - val_accuracy: 0.8392 - val_loss: 0.5134\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7575 - loss: 0.7423 - val_accuracy: 0.8699 - val_loss: 0.4193\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7956 - loss: 0.6369 - val_accuracy: 0.8892 - val_loss: 0.3545\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.5600 - val_accuracy: 0.8898 - val_loss: 0.3382\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.4941 - val_accuracy: 0.9078 - val_loss: 0.2977\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8604 - loss: 0.4365 - val_accuracy: 0.9132 - val_loss: 0.2795\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.4001 - val_accuracy: 0.9191 - val_loss: 0.2562\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 0.3741 - val_accuracy: 0.9240 - val_loss: 0.2494\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.3370 - val_accuracy: 0.9252 - val_loss: 0.2410\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9007 - loss: 0.3135 - val_accuracy: 0.9303 - val_loss: 0.2286\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9087 - loss: 0.2895 - val_accuracy: 0.9344 - val_loss: 0.2150\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.2766 - val_accuracy: 0.9345 - val_loss: 0.2145\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2173 - loss: 2.3152 - val_accuracy: 0.4319 - val_loss: 1.6996\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4540 - loss: 1.5605 - val_accuracy: 0.7014 - val_loss: 0.9608\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5985 - loss: 1.1699 - val_accuracy: 0.7892 - val_loss: 0.6926\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6997 - loss: 0.9079 - val_accuracy: 0.8303 - val_loss: 0.5355\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 0.7391 - val_accuracy: 0.8592 - val_loss: 0.4420\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7941 - loss: 0.6254 - val_accuracy: 0.8819 - val_loss: 0.3836\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.5445 - val_accuracy: 0.8942 - val_loss: 0.3403\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.4823 - val_accuracy: 0.9076 - val_loss: 0.3069\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8609 - loss: 0.4372 - val_accuracy: 0.9120 - val_loss: 0.2843\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8783 - loss: 0.3905 - val_accuracy: 0.9191 - val_loss: 0.2650\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.3688 - val_accuracy: 0.9184 - val_loss: 0.2716\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8963 - loss: 0.3328 - val_accuracy: 0.9225 - val_loss: 0.2522\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.3164 - val_accuracy: 0.9296 - val_loss: 0.2387\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9057 - loss: 0.2942 - val_accuracy: 0.9307 - val_loss: 0.2340\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9129 - loss: 0.2720 - val_accuracy: 0.9304 - val_loss: 0.2310\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2109 - loss: 2.3117 - val_accuracy: 0.4325 - val_loss: 1.6867\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4302 - loss: 1.6296 - val_accuracy: 0.6595 - val_loss: 1.0666\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5700 - loss: 1.2551 - val_accuracy: 0.7582 - val_loss: 0.7791\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6537 - loss: 1.0259 - val_accuracy: 0.8104 - val_loss: 0.6118\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7176 - loss: 0.8525 - val_accuracy: 0.8285 - val_loss: 0.5362\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7617 - loss: 0.7239 - val_accuracy: 0.8647 - val_loss: 0.4349\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.6243 - val_accuracy: 0.8810 - val_loss: 0.3807\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8233 - loss: 0.5564 - val_accuracy: 0.8938 - val_loss: 0.3399\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8429 - loss: 0.4971 - val_accuracy: 0.9061 - val_loss: 0.3062\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.4529 - val_accuracy: 0.9158 - val_loss: 0.2769\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8674 - loss: 0.4148 - val_accuracy: 0.9204 - val_loss: 0.2657\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8767 - loss: 0.3868 - val_accuracy: 0.9222 - val_loss: 0.2522\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8877 - loss: 0.3515 - val_accuracy: 0.9289 - val_loss: 0.2406\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8956 - loss: 0.3224 - val_accuracy: 0.9285 - val_loss: 0.2388\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9043 - loss: 0.3037 - val_accuracy: 0.9341 - val_loss: 0.2223\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9340\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3631 - loss: 1.9300 - val_accuracy: 0.6661 - val_loss: 0.9821\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7795 - loss: 0.6963 - val_accuracy: 0.8969 - val_loss: 0.3421\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 0.4777 - val_accuracy: 0.9091 - val_loss: 0.3013\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8855 - loss: 0.3808 - val_accuracy: 0.9172 - val_loss: 0.2820\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8946 - loss: 0.3550 - val_accuracy: 0.9197 - val_loss: 0.2690\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9089 - loss: 0.3131 - val_accuracy: 0.9282 - val_loss: 0.2476\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2940 - val_accuracy: 0.9295 - val_loss: 0.2649\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2771 - val_accuracy: 0.9297 - val_loss: 0.2503\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9223 - loss: 0.2670 - val_accuracy: 0.9346 - val_loss: 0.2488\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9295 - loss: 0.2465 - val_accuracy: 0.9377 - val_loss: 0.2264\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.2425 - val_accuracy: 0.9165 - val_loss: 0.2908\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.2249 - val_accuracy: 0.9362 - val_loss: 0.2313\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9361 - loss: 0.2265 - val_accuracy: 0.9357 - val_loss: 0.2314\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3657 - loss: 1.9127 - val_accuracy: 0.7004 - val_loss: 0.8576\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.6614 - val_accuracy: 0.9081 - val_loss: 0.2992\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8641 - loss: 0.4528 - val_accuracy: 0.9148 - val_loss: 0.2822\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8878 - loss: 0.3703 - val_accuracy: 0.9223 - val_loss: 0.2614\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 0.3351 - val_accuracy: 0.9303 - val_loss: 0.2422\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.3061 - val_accuracy: 0.9320 - val_loss: 0.2415\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.2808 - val_accuracy: 0.9393 - val_loss: 0.2073\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.2672 - val_accuracy: 0.9366 - val_loss: 0.2289\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9263 - loss: 0.2567 - val_accuracy: 0.9357 - val_loss: 0.2160\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9328 - loss: 0.2357 - val_accuracy: 0.9342 - val_loss: 0.2351\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3753 - loss: 1.9963 - val_accuracy: 0.7469 - val_loss: 0.7855\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7882 - loss: 0.6649 - val_accuracy: 0.8896 - val_loss: 0.3513\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 0.4629 - val_accuracy: 0.9173 - val_loss: 0.2704\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8848 - loss: 0.3834 - val_accuracy: 0.9320 - val_loss: 0.2313\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9017 - loss: 0.3325 - val_accuracy: 0.9098 - val_loss: 0.3685\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9088 - loss: 0.3065 - val_accuracy: 0.9314 - val_loss: 0.2358\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.2851 - val_accuracy: 0.9336 - val_loss: 0.2289\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.2558 - val_accuracy: 0.9389 - val_loss: 0.2174\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9283 - loss: 0.2527 - val_accuracy: 0.9372 - val_loss: 0.2462\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.2301 - val_accuracy: 0.9334 - val_loss: 0.2427\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.2154 - val_accuracy: 0.9385 - val_loss: 0.2093\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3761 - loss: 1.8987 - val_accuracy: 0.6303 - val_loss: 1.0748\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 0.6748 - val_accuracy: 0.8947 - val_loss: 0.3472\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8587 - loss: 0.4614 - val_accuracy: 0.9109 - val_loss: 0.3065\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8888 - loss: 0.3702 - val_accuracy: 0.9192 - val_loss: 0.2995\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.3263 - val_accuracy: 0.9225 - val_loss: 0.2934\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2860 - val_accuracy: 0.9247 - val_loss: 0.2684\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.2605 - val_accuracy: 0.9327 - val_loss: 0.3101\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9312 - loss: 0.2422 - val_accuracy: 0.9258 - val_loss: 0.2826\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9295 - loss: 0.2427 - val_accuracy: 0.9344 - val_loss: 0.2516\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.2191 - val_accuracy: 0.9367 - val_loss: 0.2388\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9354 - loss: 0.2289 - val_accuracy: 0.9364 - val_loss: 0.2362\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9390 - loss: 0.2178 - val_accuracy: 0.9364 - val_loss: 0.2267\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.2061 - val_accuracy: 0.9309 - val_loss: 0.2858\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3800 - loss: 1.9226 - val_accuracy: 0.7536 - val_loss: 0.7305\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.6513 - val_accuracy: 0.8907 - val_loss: 0.3654\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.4442 - val_accuracy: 0.9186 - val_loss: 0.2772\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.3628 - val_accuracy: 0.9080 - val_loss: 0.3386\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.3124 - val_accuracy: 0.9259 - val_loss: 0.2607\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 0.2910 - val_accuracy: 0.9266 - val_loss: 0.2645\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9228 - loss: 0.2613 - val_accuracy: 0.9304 - val_loss: 0.2530\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9299 - loss: 0.2505 - val_accuracy: 0.9351 - val_loss: 0.2270\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.2389 - val_accuracy: 0.9255 - val_loss: 0.2715\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9353 - loss: 0.2201 - val_accuracy: 0.9315 - val_loss: 0.2620\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.2151 - val_accuracy: 0.9379 - val_loss: 0.2556\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.2084 - val_accuracy: 0.9292 - val_loss: 0.2682\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9416 - loss: 0.2062 - val_accuracy: 0.9378 - val_loss: 0.2476\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.1918 - val_accuracy: 0.9328 - val_loss: 0.2370\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}: 0.9381\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1566 - loss: 2.6027 - val_accuracy: 0.2977 - val_loss: 2.0207\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2902 - loss: 1.9856 - val_accuracy: 0.4922 - val_loss: 1.5351\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3885 - loss: 1.7212 - val_accuracy: 0.5900 - val_loss: 1.2462\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4761 - loss: 1.4948 - val_accuracy: 0.6681 - val_loss: 1.0264\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5499 - loss: 1.2956 - val_accuracy: 0.7354 - val_loss: 0.8349\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6135 - loss: 1.1314 - val_accuracy: 0.7892 - val_loss: 0.6834\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6734 - loss: 0.9798 - val_accuracy: 0.8106 - val_loss: 0.5911\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7067 - loss: 0.8821 - val_accuracy: 0.8388 - val_loss: 0.5198\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7365 - loss: 0.8057 - val_accuracy: 0.8579 - val_loss: 0.4577\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7640 - loss: 0.7333 - val_accuracy: 0.8703 - val_loss: 0.4200\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7882 - loss: 0.6642 - val_accuracy: 0.8804 - val_loss: 0.3855\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8022 - loss: 0.6156 - val_accuracy: 0.8920 - val_loss: 0.3525\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.5822 - val_accuracy: 0.8974 - val_loss: 0.3308\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.5488 - val_accuracy: 0.9015 - val_loss: 0.3165\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.5196 - val_accuracy: 0.9054 - val_loss: 0.3075\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1559 - loss: 2.6035 - val_accuracy: 0.2857 - val_loss: 2.0150\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3016 - loss: 1.9603 - val_accuracy: 0.4699 - val_loss: 1.5645\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3830 - loss: 1.7388 - val_accuracy: 0.5559 - val_loss: 1.3254\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4562 - loss: 1.5347 - val_accuracy: 0.6372 - val_loss: 1.1117\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 1.3526 - val_accuracy: 0.7100 - val_loss: 0.9219\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5861 - loss: 1.1973 - val_accuracy: 0.7568 - val_loss: 0.7754\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6462 - loss: 1.0467 - val_accuracy: 0.8027 - val_loss: 0.6563\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6840 - loss: 0.9479 - val_accuracy: 0.8203 - val_loss: 0.5797\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7232 - loss: 0.8501 - val_accuracy: 0.8447 - val_loss: 0.5014\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7508 - loss: 0.7682 - val_accuracy: 0.8625 - val_loss: 0.4488\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.7022 - val_accuracy: 0.8791 - val_loss: 0.4003\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.6621 - val_accuracy: 0.8810 - val_loss: 0.3799\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.6160 - val_accuracy: 0.8920 - val_loss: 0.3526\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8143 - loss: 0.5783 - val_accuracy: 0.9010 - val_loss: 0.3257\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.5451 - val_accuracy: 0.9032 - val_loss: 0.3217\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.1579 - loss: 2.5662 - val_accuracy: 0.2755 - val_loss: 2.0472\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2980 - loss: 1.9668 - val_accuracy: 0.4951 - val_loss: 1.5344\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3833 - loss: 1.7255 - val_accuracy: 0.5855 - val_loss: 1.2694\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4774 - loss: 1.4891 - val_accuracy: 0.6831 - val_loss: 1.0292\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5517 - loss: 1.2965 - val_accuracy: 0.7281 - val_loss: 0.8679\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6096 - loss: 1.1457 - val_accuracy: 0.7841 - val_loss: 0.7044\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6635 - loss: 1.0025 - val_accuracy: 0.8118 - val_loss: 0.6006\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7115 - loss: 0.8787 - val_accuracy: 0.8366 - val_loss: 0.5342\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7394 - loss: 0.8000 - val_accuracy: 0.8564 - val_loss: 0.4610\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7629 - loss: 0.7296 - val_accuracy: 0.8755 - val_loss: 0.4086\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 0.6763 - val_accuracy: 0.8848 - val_loss: 0.3804\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.6189 - val_accuracy: 0.8914 - val_loss: 0.3536\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.5761 - val_accuracy: 0.9007 - val_loss: 0.3258\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.5527 - val_accuracy: 0.9049 - val_loss: 0.3070\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.5208 - val_accuracy: 0.9085 - val_loss: 0.2941\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.1583 - loss: 2.5930 - val_accuracy: 0.2848 - val_loss: 2.0768\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2991 - loss: 1.9593 - val_accuracy: 0.5096 - val_loss: 1.4945\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4060 - loss: 1.6822 - val_accuracy: 0.6071 - val_loss: 1.2180\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4836 - loss: 1.4876 - val_accuracy: 0.6829 - val_loss: 0.9940\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5551 - loss: 1.2834 - val_accuracy: 0.7532 - val_loss: 0.8012\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6191 - loss: 1.1191 - val_accuracy: 0.7922 - val_loss: 0.6646\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6744 - loss: 0.9790 - val_accuracy: 0.8264 - val_loss: 0.5714\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7124 - loss: 0.8743 - val_accuracy: 0.8480 - val_loss: 0.4937\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.7965 - val_accuracy: 0.8614 - val_loss: 0.4470\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7657 - loss: 0.7147 - val_accuracy: 0.8789 - val_loss: 0.4107\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.6620 - val_accuracy: 0.8878 - val_loss: 0.3768\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.6052 - val_accuracy: 0.8973 - val_loss: 0.3433\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8180 - loss: 0.5721 - val_accuracy: 0.9018 - val_loss: 0.3300\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8304 - loss: 0.5374 - val_accuracy: 0.9093 - val_loss: 0.3153\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8402 - loss: 0.5076 - val_accuracy: 0.9106 - val_loss: 0.3027\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.1549 - loss: 2.6048 - val_accuracy: 0.2545 - val_loss: 2.0949\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2951 - loss: 1.9785 - val_accuracy: 0.4800 - val_loss: 1.5685\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3803 - loss: 1.7468 - val_accuracy: 0.5705 - val_loss: 1.2932\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4654 - loss: 1.5198 - val_accuracy: 0.6747 - val_loss: 1.0409\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5429 - loss: 1.3180 - val_accuracy: 0.7301 - val_loss: 0.8477\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6054 - loss: 1.1531 - val_accuracy: 0.7804 - val_loss: 0.7081\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6623 - loss: 1.0105 - val_accuracy: 0.8250 - val_loss: 0.5815\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6994 - loss: 0.8989 - val_accuracy: 0.8426 - val_loss: 0.5068\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7394 - loss: 0.7986 - val_accuracy: 0.8645 - val_loss: 0.4377\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7629 - loss: 0.7304 - val_accuracy: 0.8803 - val_loss: 0.3894\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7894 - loss: 0.6543 - val_accuracy: 0.8913 - val_loss: 0.3495\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.6118 - val_accuracy: 0.8983 - val_loss: 0.3281\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8175 - loss: 0.5773 - val_accuracy: 0.9041 - val_loss: 0.3083\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.5446 - val_accuracy: 0.9069 - val_loss: 0.2986\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8425 - loss: 0.5041 - val_accuracy: 0.9153 - val_loss: 0.2742\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}: 0.9086\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2757 - loss: 2.1663 - val_accuracy: 0.6677 - val_loss: 1.0511\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 1.0594 - val_accuracy: 0.8401 - val_loss: 0.5195\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.7020 - val_accuracy: 0.8968 - val_loss: 0.3489\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8265 - loss: 0.5726 - val_accuracy: 0.8724 - val_loss: 0.3984\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.5056 - val_accuracy: 0.8915 - val_loss: 0.3445\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8618 - loss: 0.4570 - val_accuracy: 0.9062 - val_loss: 0.3467\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8741 - loss: 0.4202 - val_accuracy: 0.9185 - val_loss: 0.2813\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8773 - loss: 0.4089 - val_accuracy: 0.9195 - val_loss: 0.2733\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8883 - loss: 0.3772 - val_accuracy: 0.9215 - val_loss: 0.2613\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8876 - loss: 0.3791 - val_accuracy: 0.9167 - val_loss: 0.2835\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.3668 - val_accuracy: 0.9260 - val_loss: 0.2594\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8956 - loss: 0.3564 - val_accuracy: 0.9052 - val_loss: 0.3259\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8978 - loss: 0.3422 - val_accuracy: 0.9292 - val_loss: 0.2484\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8992 - loss: 0.3374 - val_accuracy: 0.9211 - val_loss: 0.3067\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.3276 - val_accuracy: 0.9328 - val_loss: 0.2393\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2622 - loss: 2.2375 - val_accuracy: 0.6205 - val_loss: 1.0998\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6386 - loss: 1.0855 - val_accuracy: 0.8469 - val_loss: 0.5107\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7634 - loss: 0.7495 - val_accuracy: 0.8715 - val_loss: 0.4161\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.6091 - val_accuracy: 0.9084 - val_loss: 0.3138\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8443 - loss: 0.5176 - val_accuracy: 0.9085 - val_loss: 0.3064\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8589 - loss: 0.4705 - val_accuracy: 0.9105 - val_loss: 0.2937\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.4280 - val_accuracy: 0.9231 - val_loss: 0.2662\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8780 - loss: 0.4052 - val_accuracy: 0.9272 - val_loss: 0.2572\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8868 - loss: 0.3842 - val_accuracy: 0.9272 - val_loss: 0.2492\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8917 - loss: 0.3842 - val_accuracy: 0.9306 - val_loss: 0.2437\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8960 - loss: 0.3645 - val_accuracy: 0.9247 - val_loss: 0.2664\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8930 - loss: 0.3657 - val_accuracy: 0.9347 - val_loss: 0.2328\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8968 - loss: 0.3489 - val_accuracy: 0.9300 - val_loss: 0.2338\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9017 - loss: 0.3282 - val_accuracy: 0.9317 - val_loss: 0.2471\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.3302 - val_accuracy: 0.9364 - val_loss: 0.2228\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.2832 - loss: 2.1812 - val_accuracy: 0.5894 - val_loss: 1.1827\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6691 - loss: 1.0153 - val_accuracy: 0.8365 - val_loss: 0.5633\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.6992 - val_accuracy: 0.8976 - val_loss: 0.3367\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8260 - loss: 0.5746 - val_accuracy: 0.9127 - val_loss: 0.3002\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8509 - loss: 0.4993 - val_accuracy: 0.8980 - val_loss: 0.3451\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.4623 - val_accuracy: 0.9125 - val_loss: 0.2955\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8738 - loss: 0.4296 - val_accuracy: 0.9193 - val_loss: 0.2821\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8799 - loss: 0.4154 - val_accuracy: 0.8864 - val_loss: 0.3674\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.3978 - val_accuracy: 0.9232 - val_loss: 0.2688\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.3845 - val_accuracy: 0.9266 - val_loss: 0.2694\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8923 - loss: 0.3636 - val_accuracy: 0.9280 - val_loss: 0.2592\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.3452 - val_accuracy: 0.9314 - val_loss: 0.2524\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8974 - loss: 0.3465 - val_accuracy: 0.9377 - val_loss: 0.2253\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.3286 - val_accuracy: 0.9335 - val_loss: 0.2374\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9023 - loss: 0.3304 - val_accuracy: 0.9286 - val_loss: 0.2460\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2780 - loss: 2.1870 - val_accuracy: 0.6094 - val_loss: 1.1997\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6563 - loss: 1.0370 - val_accuracy: 0.8405 - val_loss: 0.5274\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.6911 - val_accuracy: 0.8843 - val_loss: 0.3904\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8326 - loss: 0.5629 - val_accuracy: 0.9081 - val_loss: 0.3026\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 0.4928 - val_accuracy: 0.9153 - val_loss: 0.2861\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8642 - loss: 0.4552 - val_accuracy: 0.9124 - val_loss: 0.2937\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.4155 - val_accuracy: 0.9218 - val_loss: 0.2696\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.4000 - val_accuracy: 0.9248 - val_loss: 0.2600\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.3687 - val_accuracy: 0.9337 - val_loss: 0.2358\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8956 - loss: 0.3615 - val_accuracy: 0.9283 - val_loss: 0.2518\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8979 - loss: 0.3517 - val_accuracy: 0.9282 - val_loss: 0.2548\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9034 - loss: 0.3428 - val_accuracy: 0.9310 - val_loss: 0.2442\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2779 - loss: 2.1954 - val_accuracy: 0.6150 - val_loss: 1.1272\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6507 - loss: 1.0532 - val_accuracy: 0.8421 - val_loss: 0.5322\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7726 - loss: 0.7242 - val_accuracy: 0.8952 - val_loss: 0.3674\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8195 - loss: 0.5825 - val_accuracy: 0.9072 - val_loss: 0.3155\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8435 - loss: 0.5118 - val_accuracy: 0.9190 - val_loss: 0.2803\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 0.4726 - val_accuracy: 0.8991 - val_loss: 0.3313\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.4400 - val_accuracy: 0.9255 - val_loss: 0.2590\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8773 - loss: 0.4098 - val_accuracy: 0.9235 - val_loss: 0.2642\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.4025 - val_accuracy: 0.9268 - val_loss: 0.2589\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8846 - loss: 0.3852 - val_accuracy: 0.9345 - val_loss: 0.2391\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.3679 - val_accuracy: 0.9222 - val_loss: 0.2824\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.3612 - val_accuracy: 0.9333 - val_loss: 0.2292\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8986 - loss: 0.3428 - val_accuracy: 0.9311 - val_loss: 0.2481\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}: 0.9350\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.1915 - loss: 2.3747 - val_accuracy: 0.1124 - val_loss: 4.7043\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3587 - loss: 1.8130 - val_accuracy: 0.4734 - val_loss: 1.5853\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4675 - loss: 1.5119 - val_accuracy: 0.6696 - val_loss: 1.0508\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5613 - loss: 1.2778 - val_accuracy: 0.7485 - val_loss: 0.8244\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6414 - loss: 1.0650 - val_accuracy: 0.7894 - val_loss: 0.6843\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6939 - loss: 0.9165 - val_accuracy: 0.8234 - val_loss: 0.5715\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7350 - loss: 0.7999 - val_accuracy: 0.8511 - val_loss: 0.4861\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7703 - loss: 0.6948 - val_accuracy: 0.8616 - val_loss: 0.4380\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 0.6287 - val_accuracy: 0.8848 - val_loss: 0.3794\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8174 - loss: 0.5654 - val_accuracy: 0.8865 - val_loss: 0.3560\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8324 - loss: 0.5185 - val_accuracy: 0.8955 - val_loss: 0.3299\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8446 - loss: 0.4867 - val_accuracy: 0.9025 - val_loss: 0.3109\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8584 - loss: 0.4391 - val_accuracy: 0.9073 - val_loss: 0.2903\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8696 - loss: 0.4093 - val_accuracy: 0.9162 - val_loss: 0.2662\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8764 - loss: 0.3828 - val_accuracy: 0.9183 - val_loss: 0.2615\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1818 - loss: 2.4490 - val_accuracy: 0.1126 - val_loss: 3.6262\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3656 - loss: 1.7865 - val_accuracy: 0.5149 - val_loss: 1.4747\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4943 - loss: 1.4530 - val_accuracy: 0.6783 - val_loss: 1.0019\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5912 - loss: 1.2025 - val_accuracy: 0.7625 - val_loss: 0.7612\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6664 - loss: 0.9880 - val_accuracy: 0.7962 - val_loss: 0.6544\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7234 - loss: 0.8387 - val_accuracy: 0.8357 - val_loss: 0.5281\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7628 - loss: 0.7102 - val_accuracy: 0.8551 - val_loss: 0.4545\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7861 - loss: 0.6559 - val_accuracy: 0.8735 - val_loss: 0.4076\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8159 - loss: 0.5664 - val_accuracy: 0.8877 - val_loss: 0.3646\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8340 - loss: 0.5205 - val_accuracy: 0.8983 - val_loss: 0.3287\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8464 - loss: 0.4715 - val_accuracy: 0.9054 - val_loss: 0.3064\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8581 - loss: 0.4441 - val_accuracy: 0.9122 - val_loss: 0.2850\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8706 - loss: 0.4017 - val_accuracy: 0.9189 - val_loss: 0.2661\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8759 - loss: 0.3798 - val_accuracy: 0.9247 - val_loss: 0.2482\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8858 - loss: 0.3572 - val_accuracy: 0.9242 - val_loss: 0.2497\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.1874 - loss: 2.4191 - val_accuracy: 0.1125 - val_loss: 4.0313\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3785 - loss: 1.7571 - val_accuracy: 0.5096 - val_loss: 1.4590\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5051 - loss: 1.4275 - val_accuracy: 0.7018 - val_loss: 0.9489\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5945 - loss: 1.1830 - val_accuracy: 0.7615 - val_loss: 0.7566\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6649 - loss: 1.0048 - val_accuracy: 0.8022 - val_loss: 0.6239\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7147 - loss: 0.8540 - val_accuracy: 0.8372 - val_loss: 0.5197\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7537 - loss: 0.7440 - val_accuracy: 0.8577 - val_loss: 0.4519\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7879 - loss: 0.6537 - val_accuracy: 0.8704 - val_loss: 0.4075\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8129 - loss: 0.5825 - val_accuracy: 0.8821 - val_loss: 0.3717\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8300 - loss: 0.5337 - val_accuracy: 0.8903 - val_loss: 0.3370\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8418 - loss: 0.4952 - val_accuracy: 0.9009 - val_loss: 0.3141\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8486 - loss: 0.4643 - val_accuracy: 0.9084 - val_loss: 0.2932\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8658 - loss: 0.4181 - val_accuracy: 0.9173 - val_loss: 0.2712\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8771 - loss: 0.3778 - val_accuracy: 0.9147 - val_loss: 0.2738\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8826 - loss: 0.3693 - val_accuracy: 0.9241 - val_loss: 0.2466\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1924 - loss: 2.4637 - val_accuracy: 0.1124 - val_loss: 4.8093\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3822 - loss: 1.7596 - val_accuracy: 0.4985 - val_loss: 1.4978\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5075 - loss: 1.4264 - val_accuracy: 0.7038 - val_loss: 0.9506\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6044 - loss: 1.1626 - val_accuracy: 0.7685 - val_loss: 0.7416\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6677 - loss: 0.9794 - val_accuracy: 0.8118 - val_loss: 0.6114\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7276 - loss: 0.8225 - val_accuracy: 0.8413 - val_loss: 0.5107\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7643 - loss: 0.7177 - val_accuracy: 0.8596 - val_loss: 0.4521\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7951 - loss: 0.6290 - val_accuracy: 0.8761 - val_loss: 0.3944\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.5598 - val_accuracy: 0.8843 - val_loss: 0.3641\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8373 - loss: 0.5032 - val_accuracy: 0.8966 - val_loss: 0.3280\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8451 - loss: 0.4720 - val_accuracy: 0.9024 - val_loss: 0.3111\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8589 - loss: 0.4289 - val_accuracy: 0.9069 - val_loss: 0.2939\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8693 - loss: 0.4018 - val_accuracy: 0.9144 - val_loss: 0.2763\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8823 - loss: 0.3640 - val_accuracy: 0.9167 - val_loss: 0.2689\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8901 - loss: 0.3494 - val_accuracy: 0.9197 - val_loss: 0.2573\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.1859 - loss: 2.4202 - val_accuracy: 0.1167 - val_loss: 2.7875\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3799 - loss: 1.7573 - val_accuracy: 0.5386 - val_loss: 1.4287\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5060 - loss: 1.4229 - val_accuracy: 0.7046 - val_loss: 0.9501\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6013 - loss: 1.1706 - val_accuracy: 0.7693 - val_loss: 0.7380\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6761 - loss: 0.9616 - val_accuracy: 0.8159 - val_loss: 0.5867\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7294 - loss: 0.8108 - val_accuracy: 0.8452 - val_loss: 0.5006\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7696 - loss: 0.6953 - val_accuracy: 0.8649 - val_loss: 0.4268\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7979 - loss: 0.6156 - val_accuracy: 0.8864 - val_loss: 0.3689\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8259 - loss: 0.5363 - val_accuracy: 0.8956 - val_loss: 0.3371\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8410 - loss: 0.4952 - val_accuracy: 0.8972 - val_loss: 0.3233\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8537 - loss: 0.4540 - val_accuracy: 0.9058 - val_loss: 0.2984\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.4083 - val_accuracy: 0.9100 - val_loss: 0.2794\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8740 - loss: 0.3842 - val_accuracy: 0.9155 - val_loss: 0.2671\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8864 - loss: 0.3519 - val_accuracy: 0.9205 - val_loss: 0.2506\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.3295 - val_accuracy: 0.9257 - val_loss: 0.2420\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9225\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3347 - loss: 2.0917 - val_accuracy: 0.2614 - val_loss: 3.7691\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7594 - loss: 0.7397 - val_accuracy: 0.6779 - val_loss: 0.9554\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8507 - loss: 0.4671 - val_accuracy: 0.9103 - val_loss: 0.2970\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8880 - loss: 0.3596 - val_accuracy: 0.9077 - val_loss: 0.3051\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9088 - loss: 0.2925 - val_accuracy: 0.9254 - val_loss: 0.2584\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9196 - loss: 0.2553 - val_accuracy: 0.9362 - val_loss: 0.2094\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9277 - loss: 0.2309 - val_accuracy: 0.9248 - val_loss: 0.2789\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9338 - loss: 0.2124 - val_accuracy: 0.9399 - val_loss: 0.2095\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.1900 - val_accuracy: 0.9400 - val_loss: 0.2143\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.1810 - val_accuracy: 0.9400 - val_loss: 0.2242\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.1715 - val_accuracy: 0.9476 - val_loss: 0.1856\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9508 - loss: 0.1609 - val_accuracy: 0.9499 - val_loss: 0.1969\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9533 - loss: 0.1534 - val_accuracy: 0.9511 - val_loss: 0.1926\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.1450 - val_accuracy: 0.9525 - val_loss: 0.1912\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9581 - loss: 0.1376 - val_accuracy: 0.9521 - val_loss: 0.1952\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.3379 - loss: 2.1862 - val_accuracy: 0.1127 - val_loss: 7.6943\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7617 - loss: 0.7335 - val_accuracy: 0.7934 - val_loss: 0.6253\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8533 - loss: 0.4620 - val_accuracy: 0.9123 - val_loss: 0.2948\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8888 - loss: 0.3592 - val_accuracy: 0.9142 - val_loss: 0.2857\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9100 - loss: 0.2981 - val_accuracy: 0.9318 - val_loss: 0.2306\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9176 - loss: 0.2668 - val_accuracy: 0.9347 - val_loss: 0.2260\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9265 - loss: 0.2313 - val_accuracy: 0.9399 - val_loss: 0.2155\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9352 - loss: 0.2113 - val_accuracy: 0.9439 - val_loss: 0.1946\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9378 - loss: 0.1974 - val_accuracy: 0.9454 - val_loss: 0.1877\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9423 - loss: 0.1796 - val_accuracy: 0.9450 - val_loss: 0.1958\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9493 - loss: 0.1593 - val_accuracy: 0.9484 - val_loss: 0.1820\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9515 - loss: 0.1545 - val_accuracy: 0.9452 - val_loss: 0.2002\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9560 - loss: 0.1473 - val_accuracy: 0.9429 - val_loss: 0.2261\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9547 - loss: 0.1448 - val_accuracy: 0.9472 - val_loss: 0.2237\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.3178 - loss: 2.1561 - val_accuracy: 0.2791 - val_loss: 3.0691\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7418 - loss: 0.7898 - val_accuracy: 0.8390 - val_loss: 0.5055\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8474 - loss: 0.4941 - val_accuracy: 0.9062 - val_loss: 0.2970\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8865 - loss: 0.3628 - val_accuracy: 0.9227 - val_loss: 0.2532\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9067 - loss: 0.3081 - val_accuracy: 0.9321 - val_loss: 0.2325\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.2569 - val_accuracy: 0.9348 - val_loss: 0.2161\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9305 - loss: 0.2219 - val_accuracy: 0.9406 - val_loss: 0.2015\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9306 - loss: 0.2197 - val_accuracy: 0.9382 - val_loss: 0.2102\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9365 - loss: 0.1977 - val_accuracy: 0.9459 - val_loss: 0.1966\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9458 - loss: 0.1751 - val_accuracy: 0.9448 - val_loss: 0.2032\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.1742 - val_accuracy: 0.9435 - val_loss: 0.1924\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9493 - loss: 0.1563 - val_accuracy: 0.9383 - val_loss: 0.2110\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3156 - loss: 2.2279 - val_accuracy: 0.1985 - val_loss: 4.7814\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7450 - loss: 0.7921 - val_accuracy: 0.7970 - val_loss: 0.6371\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 0.5063 - val_accuracy: 0.9151 - val_loss: 0.2836\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8840 - loss: 0.3697 - val_accuracy: 0.9193 - val_loss: 0.2722\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9007 - loss: 0.3118 - val_accuracy: 0.9276 - val_loss: 0.2328\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2686 - val_accuracy: 0.9440 - val_loss: 0.1971\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9273 - loss: 0.2346 - val_accuracy: 0.9463 - val_loss: 0.1963\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9333 - loss: 0.2127 - val_accuracy: 0.9448 - val_loss: 0.1985\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9396 - loss: 0.1972 - val_accuracy: 0.9457 - val_loss: 0.2055\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9466 - loss: 0.1736 - val_accuracy: 0.9455 - val_loss: 0.2021\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3341 - loss: 2.1119 - val_accuracy: 0.1129 - val_loss: 9.3067\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7535 - loss: 0.7619 - val_accuracy: 0.6691 - val_loss: 0.9696\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8464 - loss: 0.4795 - val_accuracy: 0.9123 - val_loss: 0.2754\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8863 - loss: 0.3669 - val_accuracy: 0.9282 - val_loss: 0.2348\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9020 - loss: 0.3104 - val_accuracy: 0.9154 - val_loss: 0.2836\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9172 - loss: 0.2690 - val_accuracy: 0.9328 - val_loss: 0.2241\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9273 - loss: 0.2327 - val_accuracy: 0.9377 - val_loss: 0.2234\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9333 - loss: 0.2123 - val_accuracy: 0.9355 - val_loss: 0.2220\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9374 - loss: 0.2004 - val_accuracy: 0.9465 - val_loss: 0.1867\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9429 - loss: 0.1848 - val_accuracy: 0.9447 - val_loss: 0.1940\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.1711 - val_accuracy: 0.9463 - val_loss: 0.2003\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9495 - loss: 0.1618 - val_accuracy: 0.9471 - val_loss: 0.1845\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1491 - val_accuracy: 0.9440 - val_loss: 0.1955\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9552 - loss: 0.1438 - val_accuracy: 0.9469 - val_loss: 0.1870\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9594 - loss: 0.1334 - val_accuracy: 0.9435 - val_loss: 0.2232\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}: 0.9480\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1511 - loss: 2.6942 - val_accuracy: 0.1124 - val_loss: 4.7113\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2634 - loss: 2.0402 - val_accuracy: 0.3359 - val_loss: 1.9360\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3435 - loss: 1.8405 - val_accuracy: 0.5340 - val_loss: 1.4565\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4138 - loss: 1.6597 - val_accuracy: 0.6226 - val_loss: 1.2269\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4721 - loss: 1.5057 - val_accuracy: 0.6594 - val_loss: 1.0770\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5350 - loss: 1.3360 - val_accuracy: 0.7146 - val_loss: 0.9363\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5791 - loss: 1.2184 - val_accuracy: 0.7592 - val_loss: 0.8004\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6237 - loss: 1.0975 - val_accuracy: 0.7831 - val_loss: 0.7075\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6602 - loss: 1.0113 - val_accuracy: 0.8053 - val_loss: 0.6389\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6909 - loss: 0.9224 - val_accuracy: 0.8263 - val_loss: 0.5679\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7147 - loss: 0.8639 - val_accuracy: 0.8375 - val_loss: 0.5205\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7394 - loss: 0.7859 - val_accuracy: 0.8527 - val_loss: 0.4713\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7599 - loss: 0.7307 - val_accuracy: 0.8658 - val_loss: 0.4321\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7750 - loss: 0.6932 - val_accuracy: 0.8769 - val_loss: 0.3959\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 0.6516 - val_accuracy: 0.8804 - val_loss: 0.3756\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1447 - loss: 2.6729 - val_accuracy: 0.1124 - val_loss: 5.3476\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2527 - loss: 2.0635 - val_accuracy: 0.3505 - val_loss: 1.9008\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3331 - loss: 1.8633 - val_accuracy: 0.5276 - val_loss: 1.4660\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4083 - loss: 1.6689 - val_accuracy: 0.5916 - val_loss: 1.2528\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4754 - loss: 1.4882 - val_accuracy: 0.6791 - val_loss: 1.0441\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5378 - loss: 1.3346 - val_accuracy: 0.7252 - val_loss: 0.8981\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5859 - loss: 1.2043 - val_accuracy: 0.7652 - val_loss: 0.7698\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6303 - loss: 1.0901 - val_accuracy: 0.7972 - val_loss: 0.6583\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6724 - loss: 0.9757 - val_accuracy: 0.8223 - val_loss: 0.5860\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6978 - loss: 0.9075 - val_accuracy: 0.8377 - val_loss: 0.5286\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7296 - loss: 0.8271 - val_accuracy: 0.8532 - val_loss: 0.4740\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7451 - loss: 0.7735 - val_accuracy: 0.8640 - val_loss: 0.4403\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7656 - loss: 0.7275 - val_accuracy: 0.8765 - val_loss: 0.3994\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7841 - loss: 0.6632 - val_accuracy: 0.8779 - val_loss: 0.3955\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7943 - loss: 0.6284 - val_accuracy: 0.8895 - val_loss: 0.3561\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.1416 - loss: 2.6927 - val_accuracy: 0.1124 - val_loss: 5.8394\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2588 - loss: 2.0707 - val_accuracy: 0.3085 - val_loss: 2.0597\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3326 - loss: 1.8867 - val_accuracy: 0.5085 - val_loss: 1.4940\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3950 - loss: 1.7039 - val_accuracy: 0.5847 - val_loss: 1.2827\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4621 - loss: 1.5393 - val_accuracy: 0.6465 - val_loss: 1.1045\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5182 - loss: 1.3810 - val_accuracy: 0.6963 - val_loss: 0.9627\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5760 - loss: 1.2422 - val_accuracy: 0.7385 - val_loss: 0.8376\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6095 - loss: 1.1405 - val_accuracy: 0.7770 - val_loss: 0.7211\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6508 - loss: 1.0379 - val_accuracy: 0.7983 - val_loss: 0.6439\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6861 - loss: 0.9473 - val_accuracy: 0.8192 - val_loss: 0.5781\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7110 - loss: 0.8714 - val_accuracy: 0.8433 - val_loss: 0.5112\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7319 - loss: 0.8023 - val_accuracy: 0.8565 - val_loss: 0.4584\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7628 - loss: 0.7292 - val_accuracy: 0.8668 - val_loss: 0.4204\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7651 - loss: 0.7100 - val_accuracy: 0.8754 - val_loss: 0.3983\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7872 - loss: 0.6597 - val_accuracy: 0.8851 - val_loss: 0.3658\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.1460 - loss: 2.7081 - val_accuracy: 0.1136 - val_loss: 3.2215\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2614 - loss: 2.0622 - val_accuracy: 0.3923 - val_loss: 1.7998\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3444 - loss: 1.8496 - val_accuracy: 0.5152 - val_loss: 1.4732\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4120 - loss: 1.6691 - val_accuracy: 0.5997 - val_loss: 1.2608\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4692 - loss: 1.5094 - val_accuracy: 0.6465 - val_loss: 1.1058\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5248 - loss: 1.3701 - val_accuracy: 0.7070 - val_loss: 0.9340\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5804 - loss: 1.2189 - val_accuracy: 0.7481 - val_loss: 0.8124\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6252 - loss: 1.1129 - val_accuracy: 0.7769 - val_loss: 0.7151\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6605 - loss: 1.0038 - val_accuracy: 0.8055 - val_loss: 0.6233\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6989 - loss: 0.9070 - val_accuracy: 0.8291 - val_loss: 0.5555\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7218 - loss: 0.8464 - val_accuracy: 0.8512 - val_loss: 0.4954\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7443 - loss: 0.7839 - val_accuracy: 0.8604 - val_loss: 0.4539\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7685 - loss: 0.7246 - val_accuracy: 0.8735 - val_loss: 0.4184\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7861 - loss: 0.6666 - val_accuracy: 0.8810 - val_loss: 0.3911\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7951 - loss: 0.6292 - val_accuracy: 0.8919 - val_loss: 0.3609\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.1564 - loss: 2.6638 - val_accuracy: 0.1123 - val_loss: 4.8899\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2730 - loss: 2.0217 - val_accuracy: 0.3789 - val_loss: 1.8080\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3440 - loss: 1.8358 - val_accuracy: 0.5425 - val_loss: 1.4226\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4123 - loss: 1.6633 - val_accuracy: 0.6258 - val_loss: 1.2040\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4800 - loss: 1.4877 - val_accuracy: 0.6931 - val_loss: 1.0317\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5363 - loss: 1.3388 - val_accuracy: 0.7366 - val_loss: 0.8778\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5876 - loss: 1.2085 - val_accuracy: 0.7732 - val_loss: 0.7587\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6282 - loss: 1.0913 - val_accuracy: 0.7972 - val_loss: 0.6690\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6734 - loss: 0.9833 - val_accuracy: 0.8191 - val_loss: 0.5836\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7023 - loss: 0.9016 - val_accuracy: 0.8420 - val_loss: 0.5206\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7308 - loss: 0.8179 - val_accuracy: 0.8620 - val_loss: 0.4663\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7492 - loss: 0.7644 - val_accuracy: 0.8656 - val_loss: 0.4360\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7712 - loss: 0.7141 - val_accuracy: 0.8759 - val_loss: 0.3963\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7861 - loss: 0.6532 - val_accuracy: 0.8838 - val_loss: 0.3757\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8000 - loss: 0.6217 - val_accuracy: 0.8907 - val_loss: 0.3549\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0001}: 0.8875\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.2539 - loss: 2.2769 - val_accuracy: 0.1231 - val_loss: 6.9201\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6160 - loss: 1.1373 - val_accuracy: 0.7546 - val_loss: 0.7610\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7554 - loss: 0.7589 - val_accuracy: 0.8776 - val_loss: 0.4190\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8157 - loss: 0.5821 - val_accuracy: 0.8897 - val_loss: 0.3544\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.5024 - val_accuracy: 0.9162 - val_loss: 0.2866\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8638 - loss: 0.4333 - val_accuracy: 0.9176 - val_loss: 0.2889\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8777 - loss: 0.3947 - val_accuracy: 0.9314 - val_loss: 0.2370\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8899 - loss: 0.3647 - val_accuracy: 0.9336 - val_loss: 0.2450\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8954 - loss: 0.3299 - val_accuracy: 0.9324 - val_loss: 0.2411\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9074 - loss: 0.3053 - val_accuracy: 0.9433 - val_loss: 0.2041\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9122 - loss: 0.2884 - val_accuracy: 0.9405 - val_loss: 0.2104\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9144 - loss: 0.2806 - val_accuracy: 0.9411 - val_loss: 0.2134\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9187 - loss: 0.2715 - val_accuracy: 0.9422 - val_loss: 0.1990\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2517 - loss: 2.3070 - val_accuracy: 0.1138 - val_loss: 6.8280\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6182 - loss: 1.1267 - val_accuracy: 0.7684 - val_loss: 0.7218\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7598 - loss: 0.7464 - val_accuracy: 0.8767 - val_loss: 0.4078\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8160 - loss: 0.5816 - val_accuracy: 0.9020 - val_loss: 0.3125\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8549 - loss: 0.4708 - val_accuracy: 0.9126 - val_loss: 0.2893\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8728 - loss: 0.4143 - val_accuracy: 0.9166 - val_loss: 0.2829\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8839 - loss: 0.3726 - val_accuracy: 0.9196 - val_loss: 0.2713\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8929 - loss: 0.3492 - val_accuracy: 0.9290 - val_loss: 0.2247\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8991 - loss: 0.3290 - val_accuracy: 0.9297 - val_loss: 0.2328\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9023 - loss: 0.3156 - val_accuracy: 0.9350 - val_loss: 0.2267\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2928 - val_accuracy: 0.9373 - val_loss: 0.2103\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9147 - loss: 0.2747 - val_accuracy: 0.9429 - val_loss: 0.1878\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9171 - loss: 0.2740 - val_accuracy: 0.9409 - val_loss: 0.2128\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9215 - loss: 0.2562 - val_accuracy: 0.9444 - val_loss: 0.1927\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9221 - loss: 0.2534 - val_accuracy: 0.9390 - val_loss: 0.2112\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2501 - loss: 2.2708 - val_accuracy: 0.1735 - val_loss: 3.9720\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5882 - loss: 1.2078 - val_accuracy: 0.7604 - val_loss: 0.7513\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7345 - loss: 0.8203 - val_accuracy: 0.8748 - val_loss: 0.4004\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8054 - loss: 0.6226 - val_accuracy: 0.8959 - val_loss: 0.3322\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8415 - loss: 0.5101 - val_accuracy: 0.9256 - val_loss: 0.2486\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8666 - loss: 0.4402 - val_accuracy: 0.9215 - val_loss: 0.2574\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8758 - loss: 0.4016 - val_accuracy: 0.9311 - val_loss: 0.2355\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8870 - loss: 0.3747 - val_accuracy: 0.9373 - val_loss: 0.2062\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8968 - loss: 0.3305 - val_accuracy: 0.9394 - val_loss: 0.2035\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9080 - loss: 0.3142 - val_accuracy: 0.9436 - val_loss: 0.1834\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9031 - loss: 0.3102 - val_accuracy: 0.9367 - val_loss: 0.2094\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9131 - loss: 0.2895 - val_accuracy: 0.9477 - val_loss: 0.1751\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9151 - loss: 0.2799 - val_accuracy: 0.9409 - val_loss: 0.1946\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.2714 - val_accuracy: 0.9479 - val_loss: 0.1774\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.2533 - val_accuracy: 0.9466 - val_loss: 0.1734\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2530 - loss: 2.3399 - val_accuracy: 0.1533 - val_loss: 4.7761\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6032 - loss: 1.1661 - val_accuracy: 0.7241 - val_loss: 0.8644\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7534 - loss: 0.7768 - val_accuracy: 0.8865 - val_loss: 0.3716\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8112 - loss: 0.5932 - val_accuracy: 0.8599 - val_loss: 0.4521\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8509 - loss: 0.4746 - val_accuracy: 0.9001 - val_loss: 0.3540\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8652 - loss: 0.4324 - val_accuracy: 0.9010 - val_loss: 0.3216\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8806 - loss: 0.3886 - val_accuracy: 0.9290 - val_loss: 0.2338\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8955 - loss: 0.3421 - val_accuracy: 0.9323 - val_loss: 0.2275\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8975 - loss: 0.3338 - val_accuracy: 0.9341 - val_loss: 0.2260\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.3101 - val_accuracy: 0.9335 - val_loss: 0.2259\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9087 - loss: 0.3020 - val_accuracy: 0.9354 - val_loss: 0.2208\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9101 - loss: 0.2891 - val_accuracy: 0.9311 - val_loss: 0.2522\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9171 - loss: 0.2690 - val_accuracy: 0.9405 - val_loss: 0.2171\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9185 - loss: 0.2785 - val_accuracy: 0.9428 - val_loss: 0.2116\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9224 - loss: 0.2618 - val_accuracy: 0.9411 - val_loss: 0.2014\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2580 - loss: 2.2752 - val_accuracy: 0.1210 - val_loss: 6.1847\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6255 - loss: 1.1063 - val_accuracy: 0.6881 - val_loss: 0.9129\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7626 - loss: 0.7381 - val_accuracy: 0.8776 - val_loss: 0.3970\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8245 - loss: 0.5698 - val_accuracy: 0.9074 - val_loss: 0.3092\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8507 - loss: 0.4797 - val_accuracy: 0.9081 - val_loss: 0.2934\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8705 - loss: 0.4193 - val_accuracy: 0.9200 - val_loss: 0.2578\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8832 - loss: 0.3836 - val_accuracy: 0.9185 - val_loss: 0.2625\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8934 - loss: 0.3514 - val_accuracy: 0.9300 - val_loss: 0.2318\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8953 - loss: 0.3351 - val_accuracy: 0.9322 - val_loss: 0.2237\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.3162 - val_accuracy: 0.9378 - val_loss: 0.2046\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9106 - loss: 0.2887 - val_accuracy: 0.9418 - val_loss: 0.1991\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9121 - loss: 0.2835 - val_accuracy: 0.9419 - val_loss: 0.1951\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9181 - loss: 0.2664 - val_accuracy: 0.9410 - val_loss: 0.1998\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9217 - loss: 0.2608 - val_accuracy: 0.9356 - val_loss: 0.2113\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9214 - loss: 0.2617 - val_accuracy: 0.9376 - val_loss: 0.2131\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.001}: 0.9441\n",
            "Best parameters for outer fold 1: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "Best inner validation accuracy: 0.9480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outer Fold 1 - Test Accuracy: 0.9523\n",
            "\n",
            "=== Outer Fold 2/5 ===\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2116 - loss: 2.3079 - val_accuracy: 0.4363 - val_loss: 1.6801\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4395 - loss: 1.6081 - val_accuracy: 0.6768 - val_loss: 1.0211\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5883 - loss: 1.2049 - val_accuracy: 0.7776 - val_loss: 0.7246\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6796 - loss: 0.9592 - val_accuracy: 0.8261 - val_loss: 0.5579\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.7878 - val_accuracy: 0.8650 - val_loss: 0.4489\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.6567 - val_accuracy: 0.8750 - val_loss: 0.3976\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8225 - loss: 0.5643 - val_accuracy: 0.8948 - val_loss: 0.3419\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.5056 - val_accuracy: 0.9056 - val_loss: 0.3099\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8562 - loss: 0.4469 - val_accuracy: 0.9134 - val_loss: 0.2847\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8690 - loss: 0.4069 - val_accuracy: 0.9204 - val_loss: 0.2623\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8826 - loss: 0.3659 - val_accuracy: 0.9236 - val_loss: 0.2552\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.3376 - val_accuracy: 0.9260 - val_loss: 0.2458\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8984 - loss: 0.3230 - val_accuracy: 0.9328 - val_loss: 0.2326\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.2989 - val_accuracy: 0.9332 - val_loss: 0.2269\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2856 - val_accuracy: 0.9352 - val_loss: 0.2188\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2098 - loss: 2.3125 - val_accuracy: 0.4005 - val_loss: 1.7776\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4336 - loss: 1.6153 - val_accuracy: 0.6945 - val_loss: 0.9959\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5845 - loss: 1.2246 - val_accuracy: 0.7707 - val_loss: 0.7575\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6803 - loss: 0.9506 - val_accuracy: 0.8235 - val_loss: 0.5763\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.7770 - val_accuracy: 0.8557 - val_loss: 0.4686\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7808 - loss: 0.6685 - val_accuracy: 0.8792 - val_loss: 0.3964\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8146 - loss: 0.5775 - val_accuracy: 0.8960 - val_loss: 0.3439\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8388 - loss: 0.5048 - val_accuracy: 0.9065 - val_loss: 0.3086\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8523 - loss: 0.4543 - val_accuracy: 0.9099 - val_loss: 0.2954\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8698 - loss: 0.4011 - val_accuracy: 0.9192 - val_loss: 0.2677\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.3739 - val_accuracy: 0.9232 - val_loss: 0.2603\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.3520 - val_accuracy: 0.9291 - val_loss: 0.2436\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8974 - loss: 0.3223 - val_accuracy: 0.9281 - val_loss: 0.2434\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.3056 - val_accuracy: 0.9292 - val_loss: 0.2394\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.2795 - val_accuracy: 0.9357 - val_loss: 0.2193\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2147 - loss: 2.3079 - val_accuracy: 0.4461 - val_loss: 1.6316\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4477 - loss: 1.5749 - val_accuracy: 0.7028 - val_loss: 0.9612\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5954 - loss: 1.1900 - val_accuracy: 0.7879 - val_loss: 0.6829\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6969 - loss: 0.9190 - val_accuracy: 0.8351 - val_loss: 0.5242\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.7398 - val_accuracy: 0.8693 - val_loss: 0.4189\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.6260 - val_accuracy: 0.8770 - val_loss: 0.3777\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.5529 - val_accuracy: 0.8979 - val_loss: 0.3170\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8452 - loss: 0.4758 - val_accuracy: 0.9055 - val_loss: 0.2967\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.4266 - val_accuracy: 0.9148 - val_loss: 0.2671\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.3989 - val_accuracy: 0.9167 - val_loss: 0.2571\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.3647 - val_accuracy: 0.9261 - val_loss: 0.2390\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.3456 - val_accuracy: 0.9246 - val_loss: 0.2423\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8991 - loss: 0.3169 - val_accuracy: 0.9280 - val_loss: 0.2240\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9061 - loss: 0.2960 - val_accuracy: 0.9297 - val_loss: 0.2208\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9104 - loss: 0.2780 - val_accuracy: 0.9356 - val_loss: 0.2062\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.2169 - loss: 2.3066 - val_accuracy: 0.4168 - val_loss: 1.7071\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4402 - loss: 1.5972 - val_accuracy: 0.6658 - val_loss: 1.0301\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5832 - loss: 1.2194 - val_accuracy: 0.7731 - val_loss: 0.7293\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6754 - loss: 0.9655 - val_accuracy: 0.8207 - val_loss: 0.5784\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.7794 - val_accuracy: 0.8553 - val_loss: 0.4675\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.6461 - val_accuracy: 0.8733 - val_loss: 0.4064\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8175 - loss: 0.5694 - val_accuracy: 0.8881 - val_loss: 0.3598\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8386 - loss: 0.5023 - val_accuracy: 0.9004 - val_loss: 0.3207\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.4599 - val_accuracy: 0.9082 - val_loss: 0.2941\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8689 - loss: 0.4149 - val_accuracy: 0.9135 - val_loss: 0.2751\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8811 - loss: 0.3804 - val_accuracy: 0.9195 - val_loss: 0.2575\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8889 - loss: 0.3528 - val_accuracy: 0.9221 - val_loss: 0.2506\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9002 - loss: 0.3153 - val_accuracy: 0.9268 - val_loss: 0.2376\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.3036 - val_accuracy: 0.9277 - val_loss: 0.2357\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.2753 - val_accuracy: 0.9333 - val_loss: 0.2219\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2180 - loss: 2.3009 - val_accuracy: 0.4046 - val_loss: 1.7324\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4468 - loss: 1.5861 - val_accuracy: 0.6808 - val_loss: 0.9997\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5954 - loss: 1.1951 - val_accuracy: 0.7678 - val_loss: 0.7330\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6890 - loss: 0.9344 - val_accuracy: 0.8254 - val_loss: 0.5562\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7537 - loss: 0.7557 - val_accuracy: 0.8506 - val_loss: 0.4660\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.6381 - val_accuracy: 0.8746 - val_loss: 0.3982\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 0.5664 - val_accuracy: 0.8855 - val_loss: 0.3610\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.4871 - val_accuracy: 0.8991 - val_loss: 0.3199\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 0.4506 - val_accuracy: 0.9123 - val_loss: 0.2884\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.4051 - val_accuracy: 0.9162 - val_loss: 0.2719\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.3808 - val_accuracy: 0.9186 - val_loss: 0.2638\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.3506 - val_accuracy: 0.9216 - val_loss: 0.2553\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.3281 - val_accuracy: 0.9272 - val_loss: 0.2404\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2921 - val_accuracy: 0.9316 - val_loss: 0.2314\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9086 - loss: 0.2850 - val_accuracy: 0.9308 - val_loss: 0.2220\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9343\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3575 - loss: 1.9573 - val_accuracy: 0.7508 - val_loss: 0.7546\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7755 - loss: 0.7036 - val_accuracy: 0.8775 - val_loss: 0.4031\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 0.4727 - val_accuracy: 0.9211 - val_loss: 0.2838\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8836 - loss: 0.3930 - val_accuracy: 0.9254 - val_loss: 0.2575\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.3305 - val_accuracy: 0.9235 - val_loss: 0.2729\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2946 - val_accuracy: 0.9321 - val_loss: 0.2364\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2629 - val_accuracy: 0.9335 - val_loss: 0.2406\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9259 - loss: 0.2542 - val_accuracy: 0.9444 - val_loss: 0.2054\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9288 - loss: 0.2475 - val_accuracy: 0.9303 - val_loss: 0.2596\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.2302 - val_accuracy: 0.9433 - val_loss: 0.2018\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9380 - loss: 0.2070 - val_accuracy: 0.9427 - val_loss: 0.2129\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3532 - loss: 1.9864 - val_accuracy: 0.6772 - val_loss: 0.9545\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.6996 - val_accuracy: 0.8683 - val_loss: 0.4215\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 0.4663 - val_accuracy: 0.9123 - val_loss: 0.2910\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8905 - loss: 0.3615 - val_accuracy: 0.9250 - val_loss: 0.2709\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9021 - loss: 0.3270 - val_accuracy: 0.9244 - val_loss: 0.2542\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.2996 - val_accuracy: 0.9383 - val_loss: 0.2296\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.2816 - val_accuracy: 0.9348 - val_loss: 0.2324\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9223 - loss: 0.2710 - val_accuracy: 0.9386 - val_loss: 0.2122\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9260 - loss: 0.2615 - val_accuracy: 0.9353 - val_loss: 0.2639\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.2395 - val_accuracy: 0.9401 - val_loss: 0.2102\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9331 - loss: 0.2333 - val_accuracy: 0.9389 - val_loss: 0.2249\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9355 - loss: 0.2322 - val_accuracy: 0.9406 - val_loss: 0.2265\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.2193 - val_accuracy: 0.9472 - val_loss: 0.2188\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9418 - loss: 0.2109 - val_accuracy: 0.9488 - val_loss: 0.2069\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.2026 - val_accuracy: 0.9361 - val_loss: 0.2369\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3581 - loss: 1.9605 - val_accuracy: 0.6979 - val_loss: 0.9139\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7787 - loss: 0.6943 - val_accuracy: 0.8871 - val_loss: 0.3659\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.4608 - val_accuracy: 0.9032 - val_loss: 0.3169\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8864 - loss: 0.3748 - val_accuracy: 0.9150 - val_loss: 0.2762\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9041 - loss: 0.3240 - val_accuracy: 0.9167 - val_loss: 0.3041\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2899 - val_accuracy: 0.9337 - val_loss: 0.2353\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.2743 - val_accuracy: 0.9323 - val_loss: 0.2726\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9289 - loss: 0.2516 - val_accuracy: 0.9245 - val_loss: 0.2583\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.2465 - val_accuracy: 0.9374 - val_loss: 0.2205\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9348 - loss: 0.2274 - val_accuracy: 0.9324 - val_loss: 0.2452\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9364 - loss: 0.2255 - val_accuracy: 0.9324 - val_loss: 0.2429\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.2254 - val_accuracy: 0.9342 - val_loss: 0.2341\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3715 - loss: 1.8768 - val_accuracy: 0.7523 - val_loss: 0.7542\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7901 - loss: 0.6616 - val_accuracy: 0.9004 - val_loss: 0.3261\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8620 - loss: 0.4502 - val_accuracy: 0.8894 - val_loss: 0.3833\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8915 - loss: 0.3628 - val_accuracy: 0.9312 - val_loss: 0.2399\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9068 - loss: 0.3106 - val_accuracy: 0.9384 - val_loss: 0.2231\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.2988 - val_accuracy: 0.9250 - val_loss: 0.2633\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.2793 - val_accuracy: 0.9378 - val_loss: 0.2380\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9257 - loss: 0.2600 - val_accuracy: 0.9273 - val_loss: 0.2547\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3943 - loss: 1.8731 - val_accuracy: 0.7173 - val_loss: 0.8353\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7996 - loss: 0.6330 - val_accuracy: 0.8942 - val_loss: 0.3584\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.4311 - val_accuracy: 0.9147 - val_loss: 0.2903\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.3522 - val_accuracy: 0.9156 - val_loss: 0.3042\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9086 - loss: 0.3095 - val_accuracy: 0.9269 - val_loss: 0.2715\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2874 - val_accuracy: 0.9326 - val_loss: 0.2620\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.2551 - val_accuracy: 0.9330 - val_loss: 0.2360\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9299 - loss: 0.2480 - val_accuracy: 0.9323 - val_loss: 0.2401\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9310 - loss: 0.2329 - val_accuracy: 0.9323 - val_loss: 0.2604\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9348 - loss: 0.2198 - val_accuracy: 0.9357 - val_loss: 0.2291\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9399 - loss: 0.2040 - val_accuracy: 0.9364 - val_loss: 0.2238\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.2035 - val_accuracy: 0.9369 - val_loss: 0.2247\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9449 - loss: 0.1970 - val_accuracy: 0.9305 - val_loss: 0.2604\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9436 - loss: 0.1952 - val_accuracy: 0.9398 - val_loss: 0.2188\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9477 - loss: 0.1863 - val_accuracy: 0.9337 - val_loss: 0.2359\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}: 0.9418\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1568 - loss: 2.6026 - val_accuracy: 0.2782 - val_loss: 2.0658\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2947 - loss: 1.9652 - val_accuracy: 0.4997 - val_loss: 1.5233\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3852 - loss: 1.7227 - val_accuracy: 0.5899 - val_loss: 1.2612\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4761 - loss: 1.4911 - val_accuracy: 0.6683 - val_loss: 1.0273\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5467 - loss: 1.3023 - val_accuracy: 0.7306 - val_loss: 0.8547\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6126 - loss: 1.1381 - val_accuracy: 0.7907 - val_loss: 0.6988\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6610 - loss: 1.0138 - val_accuracy: 0.8128 - val_loss: 0.6023\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6996 - loss: 0.9034 - val_accuracy: 0.8398 - val_loss: 0.5167\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7371 - loss: 0.8064 - val_accuracy: 0.8558 - val_loss: 0.4633\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7563 - loss: 0.7456 - val_accuracy: 0.8759 - val_loss: 0.4076\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.6825 - val_accuracy: 0.8774 - val_loss: 0.3897\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.6322 - val_accuracy: 0.8944 - val_loss: 0.3487\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8148 - loss: 0.5801 - val_accuracy: 0.9016 - val_loss: 0.3281\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.5594 - val_accuracy: 0.9031 - val_loss: 0.3150\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8363 - loss: 0.5210 - val_accuracy: 0.9061 - val_loss: 0.3082\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1625 - loss: 2.5782 - val_accuracy: 0.2607 - val_loss: 2.1106\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3063 - loss: 1.9452 - val_accuracy: 0.4944 - val_loss: 1.5060\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4149 - loss: 1.6737 - val_accuracy: 0.5983 - val_loss: 1.2387\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4881 - loss: 1.4582 - val_accuracy: 0.6820 - val_loss: 0.9927\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5695 - loss: 1.2521 - val_accuracy: 0.7417 - val_loss: 0.8334\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6295 - loss: 1.0916 - val_accuracy: 0.7859 - val_loss: 0.6946\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6842 - loss: 0.9597 - val_accuracy: 0.8191 - val_loss: 0.6037\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7190 - loss: 0.8509 - val_accuracy: 0.8379 - val_loss: 0.5330\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7480 - loss: 0.7754 - val_accuracy: 0.8542 - val_loss: 0.4805\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7687 - loss: 0.7084 - val_accuracy: 0.8670 - val_loss: 0.4343\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7958 - loss: 0.6383 - val_accuracy: 0.8768 - val_loss: 0.4047\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.6080 - val_accuracy: 0.8848 - val_loss: 0.3781\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8225 - loss: 0.5669 - val_accuracy: 0.8930 - val_loss: 0.3680\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8278 - loss: 0.5364 - val_accuracy: 0.9015 - val_loss: 0.3408\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8418 - loss: 0.5024 - val_accuracy: 0.9041 - val_loss: 0.3328\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.1613 - loss: 2.5602 - val_accuracy: 0.2738 - val_loss: 2.0924\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3113 - loss: 1.9274 - val_accuracy: 0.5123 - val_loss: 1.4889\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4082 - loss: 1.6738 - val_accuracy: 0.6141 - val_loss: 1.1938\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4998 - loss: 1.4274 - val_accuracy: 0.6948 - val_loss: 0.9652\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5702 - loss: 1.2534 - val_accuracy: 0.7643 - val_loss: 0.7849\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6337 - loss: 1.0779 - val_accuracy: 0.7969 - val_loss: 0.6518\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6791 - loss: 0.9566 - val_accuracy: 0.8233 - val_loss: 0.5622\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7139 - loss: 0.8579 - val_accuracy: 0.8514 - val_loss: 0.4828\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7495 - loss: 0.7718 - val_accuracy: 0.8668 - val_loss: 0.4395\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7729 - loss: 0.7106 - val_accuracy: 0.8820 - val_loss: 0.3847\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.6467 - val_accuracy: 0.8909 - val_loss: 0.3575\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.6064 - val_accuracy: 0.8984 - val_loss: 0.3328\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8234 - loss: 0.5500 - val_accuracy: 0.9064 - val_loss: 0.3046\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8317 - loss: 0.5344 - val_accuracy: 0.9087 - val_loss: 0.2935\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.4970 - val_accuracy: 0.9187 - val_loss: 0.2776\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1533 - loss: 2.6268 - val_accuracy: 0.2450 - val_loss: 2.0962\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2927 - loss: 1.9802 - val_accuracy: 0.4944 - val_loss: 1.5071\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3963 - loss: 1.7052 - val_accuracy: 0.6052 - val_loss: 1.2244\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4874 - loss: 1.4782 - val_accuracy: 0.6675 - val_loss: 1.0028\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5611 - loss: 1.2825 - val_accuracy: 0.7387 - val_loss: 0.8172\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6186 - loss: 1.1146 - val_accuracy: 0.7871 - val_loss: 0.6784\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.9960 - val_accuracy: 0.8232 - val_loss: 0.5670\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 0.8830 - val_accuracy: 0.8417 - val_loss: 0.5043\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7427 - loss: 0.7890 - val_accuracy: 0.8578 - val_loss: 0.4552\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7664 - loss: 0.7236 - val_accuracy: 0.8714 - val_loss: 0.4052\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.6628 - val_accuracy: 0.8766 - val_loss: 0.3900\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.6045 - val_accuracy: 0.8925 - val_loss: 0.3403\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8143 - loss: 0.5759 - val_accuracy: 0.9005 - val_loss: 0.3219\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.5480 - val_accuracy: 0.9041 - val_loss: 0.3138\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8391 - loss: 0.5098 - val_accuracy: 0.9132 - val_loss: 0.2875\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.1633 - loss: 2.5907 - val_accuracy: 0.2704 - val_loss: 2.0976\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3030 - loss: 1.9409 - val_accuracy: 0.5132 - val_loss: 1.4980\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4068 - loss: 1.6779 - val_accuracy: 0.6125 - val_loss: 1.2093\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4968 - loss: 1.4458 - val_accuracy: 0.6889 - val_loss: 0.9935\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5664 - loss: 1.2677 - val_accuracy: 0.7436 - val_loss: 0.8061\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6267 - loss: 1.1037 - val_accuracy: 0.7997 - val_loss: 0.6655\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6749 - loss: 0.9748 - val_accuracy: 0.8295 - val_loss: 0.5704\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.8781 - val_accuracy: 0.8458 - val_loss: 0.5044\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7392 - loss: 0.7947 - val_accuracy: 0.8660 - val_loss: 0.4486\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7636 - loss: 0.7309 - val_accuracy: 0.8793 - val_loss: 0.4076\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7837 - loss: 0.6674 - val_accuracy: 0.8846 - val_loss: 0.3771\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.6163 - val_accuracy: 0.8943 - val_loss: 0.3472\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.5868 - val_accuracy: 0.8975 - val_loss: 0.3407\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.5617 - val_accuracy: 0.9068 - val_loss: 0.3130\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.5086 - val_accuracy: 0.9124 - val_loss: 0.2951\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}: 0.9109\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2775 - loss: 2.1977 - val_accuracy: 0.6735 - val_loss: 1.0461\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6504 - loss: 1.0602 - val_accuracy: 0.8295 - val_loss: 0.5493\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.7159 - val_accuracy: 0.8790 - val_loss: 0.3929\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.5833 - val_accuracy: 0.8989 - val_loss: 0.3325\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8448 - loss: 0.5182 - val_accuracy: 0.9130 - val_loss: 0.2831\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8602 - loss: 0.4643 - val_accuracy: 0.9011 - val_loss: 0.3249\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8717 - loss: 0.4265 - val_accuracy: 0.9193 - val_loss: 0.2675\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.4171 - val_accuracy: 0.9224 - val_loss: 0.2482\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8837 - loss: 0.3928 - val_accuracy: 0.9268 - val_loss: 0.2513\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.3775 - val_accuracy: 0.9233 - val_loss: 0.2599\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8922 - loss: 0.3731 - val_accuracy: 0.9196 - val_loss: 0.2676\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8957 - loss: 0.3665 - val_accuracy: 0.9302 - val_loss: 0.2408\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.3413 - val_accuracy: 0.9272 - val_loss: 0.2498\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9023 - loss: 0.3343 - val_accuracy: 0.9282 - val_loss: 0.2414\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9053 - loss: 0.3280 - val_accuracy: 0.9272 - val_loss: 0.2620\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2764 - loss: 2.1709 - val_accuracy: 0.6270 - val_loss: 1.2032\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6619 - loss: 1.0302 - val_accuracy: 0.8442 - val_loss: 0.4884\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7864 - loss: 0.6889 - val_accuracy: 0.8988 - val_loss: 0.3565\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8317 - loss: 0.5472 - val_accuracy: 0.9118 - val_loss: 0.2992\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8558 - loss: 0.4822 - val_accuracy: 0.9125 - val_loss: 0.3082\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8662 - loss: 0.4418 - val_accuracy: 0.9264 - val_loss: 0.2781\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8776 - loss: 0.4157 - val_accuracy: 0.9159 - val_loss: 0.2879\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 0.3900 - val_accuracy: 0.9334 - val_loss: 0.2470\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.3643 - val_accuracy: 0.9302 - val_loss: 0.2420\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8973 - loss: 0.3562 - val_accuracy: 0.9280 - val_loss: 0.2613\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.3642 - val_accuracy: 0.9236 - val_loss: 0.2874\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2732 - loss: 2.1913 - val_accuracy: 0.6810 - val_loss: 1.0107\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6433 - loss: 1.0701 - val_accuracy: 0.8541 - val_loss: 0.4682\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7636 - loss: 0.7470 - val_accuracy: 0.8891 - val_loss: 0.3684\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.6161 - val_accuracy: 0.9086 - val_loss: 0.3022\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.5313 - val_accuracy: 0.9130 - val_loss: 0.2934\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8540 - loss: 0.4843 - val_accuracy: 0.9126 - val_loss: 0.2873\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8686 - loss: 0.4525 - val_accuracy: 0.9145 - val_loss: 0.2911\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8727 - loss: 0.4193 - val_accuracy: 0.8944 - val_loss: 0.3407\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8814 - loss: 0.4157 - val_accuracy: 0.9306 - val_loss: 0.2376\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8887 - loss: 0.3874 - val_accuracy: 0.9322 - val_loss: 0.2355\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8916 - loss: 0.3786 - val_accuracy: 0.9325 - val_loss: 0.2313\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 0.3638 - val_accuracy: 0.9341 - val_loss: 0.2212\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 0.3419 - val_accuracy: 0.9278 - val_loss: 0.2492\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8966 - loss: 0.3431 - val_accuracy: 0.9367 - val_loss: 0.2133\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9004 - loss: 0.3360 - val_accuracy: 0.9309 - val_loss: 0.2591\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2817 - loss: 2.1558 - val_accuracy: 0.6776 - val_loss: 1.0182\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6436 - loss: 1.0708 - val_accuracy: 0.8665 - val_loss: 0.4607\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.7143 - val_accuracy: 0.8880 - val_loss: 0.3831\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8204 - loss: 0.5852 - val_accuracy: 0.9096 - val_loss: 0.3044\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8447 - loss: 0.5210 - val_accuracy: 0.9111 - val_loss: 0.2818\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8599 - loss: 0.4599 - val_accuracy: 0.9192 - val_loss: 0.2813\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.4160 - val_accuracy: 0.9195 - val_loss: 0.2632\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8864 - loss: 0.3897 - val_accuracy: 0.9317 - val_loss: 0.2355\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8822 - loss: 0.3900 - val_accuracy: 0.9217 - val_loss: 0.2856\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8870 - loss: 0.3749 - val_accuracy: 0.9311 - val_loss: 0.2311\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8974 - loss: 0.3559 - val_accuracy: 0.9296 - val_loss: 0.2589\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2691 - loss: 2.1980 - val_accuracy: 0.5985 - val_loss: 1.1447\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6656 - loss: 1.0209 - val_accuracy: 0.8352 - val_loss: 0.5281\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7823 - loss: 0.6899 - val_accuracy: 0.8938 - val_loss: 0.3613\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.5674 - val_accuracy: 0.8960 - val_loss: 0.3366\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8538 - loss: 0.4865 - val_accuracy: 0.9162 - val_loss: 0.2882\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.4515 - val_accuracy: 0.9189 - val_loss: 0.2856\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8741 - loss: 0.4151 - val_accuracy: 0.9275 - val_loss: 0.2594\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8810 - loss: 0.4100 - val_accuracy: 0.9274 - val_loss: 0.2483\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8877 - loss: 0.3721 - val_accuracy: 0.9085 - val_loss: 0.2948\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8953 - loss: 0.3616 - val_accuracy: 0.9254 - val_loss: 0.2652\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}: 0.9319\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.1963 - loss: 2.3864 - val_accuracy: 0.1124 - val_loss: 4.4363\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3852 - loss: 1.7429 - val_accuracy: 0.5165 - val_loss: 1.4366\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4979 - loss: 1.4257 - val_accuracy: 0.7018 - val_loss: 0.9536\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5992 - loss: 1.1653 - val_accuracy: 0.7625 - val_loss: 0.7553\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6718 - loss: 0.9750 - val_accuracy: 0.8095 - val_loss: 0.6102\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7216 - loss: 0.8269 - val_accuracy: 0.8465 - val_loss: 0.4994\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7671 - loss: 0.7158 - val_accuracy: 0.8611 - val_loss: 0.4422\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7893 - loss: 0.6452 - val_accuracy: 0.8750 - val_loss: 0.3996\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8127 - loss: 0.5663 - val_accuracy: 0.8916 - val_loss: 0.3481\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8342 - loss: 0.5048 - val_accuracy: 0.9019 - val_loss: 0.3153\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8486 - loss: 0.4612 - val_accuracy: 0.9084 - val_loss: 0.2970\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8601 - loss: 0.4219 - val_accuracy: 0.9141 - val_loss: 0.2773\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8736 - loss: 0.3957 - val_accuracy: 0.9204 - val_loss: 0.2636\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8819 - loss: 0.3692 - val_accuracy: 0.9230 - val_loss: 0.2482\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.3416 - val_accuracy: 0.9255 - val_loss: 0.2449\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1958 - loss: 2.4013 - val_accuracy: 0.1131 - val_loss: 3.8682\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4005 - loss: 1.7025 - val_accuracy: 0.5306 - val_loss: 1.4010\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5271 - loss: 1.3752 - val_accuracy: 0.7191 - val_loss: 0.9121\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6125 - loss: 1.1448 - val_accuracy: 0.7811 - val_loss: 0.7159\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6835 - loss: 0.9440 - val_accuracy: 0.8223 - val_loss: 0.5858\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7292 - loss: 0.8212 - val_accuracy: 0.8494 - val_loss: 0.4984\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7631 - loss: 0.7160 - val_accuracy: 0.8670 - val_loss: 0.4370\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.6275 - val_accuracy: 0.8803 - val_loss: 0.3958\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8184 - loss: 0.5600 - val_accuracy: 0.8863 - val_loss: 0.3640\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8396 - loss: 0.4999 - val_accuracy: 0.9007 - val_loss: 0.3221\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8490 - loss: 0.4736 - val_accuracy: 0.9073 - val_loss: 0.2984\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8625 - loss: 0.4295 - val_accuracy: 0.9104 - val_loss: 0.2910\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8731 - loss: 0.3948 - val_accuracy: 0.9186 - val_loss: 0.2736\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8837 - loss: 0.3633 - val_accuracy: 0.9225 - val_loss: 0.2619\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8921 - loss: 0.3416 - val_accuracy: 0.9269 - val_loss: 0.2526\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1948 - loss: 2.4306 - val_accuracy: 0.1123 - val_loss: 4.9601\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3849 - loss: 1.7492 - val_accuracy: 0.5128 - val_loss: 1.4507\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5138 - loss: 1.4129 - val_accuracy: 0.7093 - val_loss: 0.9325\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6028 - loss: 1.1597 - val_accuracy: 0.7720 - val_loss: 0.7294\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6769 - loss: 0.9720 - val_accuracy: 0.8120 - val_loss: 0.5975\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7310 - loss: 0.8330 - val_accuracy: 0.8445 - val_loss: 0.5005\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7613 - loss: 0.7183 - val_accuracy: 0.8617 - val_loss: 0.4398\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7907 - loss: 0.6449 - val_accuracy: 0.8753 - val_loss: 0.3938\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8073 - loss: 0.5772 - val_accuracy: 0.8820 - val_loss: 0.3622\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8298 - loss: 0.5236 - val_accuracy: 0.8990 - val_loss: 0.3221\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8450 - loss: 0.4840 - val_accuracy: 0.8978 - val_loss: 0.3137\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8544 - loss: 0.4567 - val_accuracy: 0.9102 - val_loss: 0.2890\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8645 - loss: 0.4185 - val_accuracy: 0.9175 - val_loss: 0.2689\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8754 - loss: 0.3915 - val_accuracy: 0.9169 - val_loss: 0.2643\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8842 - loss: 0.3606 - val_accuracy: 0.9219 - val_loss: 0.2468\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.1917 - loss: 2.3832 - val_accuracy: 0.1129 - val_loss: 3.5147\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3856 - loss: 1.7405 - val_accuracy: 0.5231 - val_loss: 1.4399\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5073 - loss: 1.4179 - val_accuracy: 0.6974 - val_loss: 0.9514\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5983 - loss: 1.1695 - val_accuracy: 0.7773 - val_loss: 0.7314\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6694 - loss: 0.9826 - val_accuracy: 0.8192 - val_loss: 0.5949\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7202 - loss: 0.8447 - val_accuracy: 0.8438 - val_loss: 0.5048\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7678 - loss: 0.7178 - val_accuracy: 0.8639 - val_loss: 0.4347\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7929 - loss: 0.6396 - val_accuracy: 0.8767 - val_loss: 0.3896\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8137 - loss: 0.5741 - val_accuracy: 0.8946 - val_loss: 0.3402\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8354 - loss: 0.5178 - val_accuracy: 0.8992 - val_loss: 0.3213\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8443 - loss: 0.4818 - val_accuracy: 0.9105 - val_loss: 0.2851\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.4285 - val_accuracy: 0.9142 - val_loss: 0.2709\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8727 - loss: 0.4066 - val_accuracy: 0.9177 - val_loss: 0.2540\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8822 - loss: 0.3706 - val_accuracy: 0.9224 - val_loss: 0.2441\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8902 - loss: 0.3468 - val_accuracy: 0.9283 - val_loss: 0.2281\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.1962 - loss: 2.3897 - val_accuracy: 0.1136 - val_loss: 3.3972\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4038 - loss: 1.6948 - val_accuracy: 0.5276 - val_loss: 1.3711\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5298 - loss: 1.3655 - val_accuracy: 0.7104 - val_loss: 0.9076\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6189 - loss: 1.1194 - val_accuracy: 0.7657 - val_loss: 0.7393\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6936 - loss: 0.9258 - val_accuracy: 0.8189 - val_loss: 0.5874\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7314 - loss: 0.8015 - val_accuracy: 0.8442 - val_loss: 0.5032\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7710 - loss: 0.6913 - val_accuracy: 0.8644 - val_loss: 0.4379\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8005 - loss: 0.6104 - val_accuracy: 0.8823 - val_loss: 0.3846\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8222 - loss: 0.5496 - val_accuracy: 0.8914 - val_loss: 0.3547\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8398 - loss: 0.4943 - val_accuracy: 0.8940 - val_loss: 0.3411\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8521 - loss: 0.4595 - val_accuracy: 0.9009 - val_loss: 0.3151\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8642 - loss: 0.4172 - val_accuracy: 0.9093 - val_loss: 0.2981\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8747 - loss: 0.3877 - val_accuracy: 0.9116 - val_loss: 0.2859\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8842 - loss: 0.3595 - val_accuracy: 0.9175 - val_loss: 0.2674\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8903 - loss: 0.3386 - val_accuracy: 0.9168 - val_loss: 0.2636\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9240\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.3225 - loss: 2.1303 - val_accuracy: 0.2128 - val_loss: 4.3365\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7443 - loss: 0.7704 - val_accuracy: 0.7908 - val_loss: 0.6429\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8445 - loss: 0.4902 - val_accuracy: 0.9122 - val_loss: 0.2864\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.3825 - val_accuracy: 0.9151 - val_loss: 0.2872\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.3185 - val_accuracy: 0.9297 - val_loss: 0.2386\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2644 - val_accuracy: 0.9335 - val_loss: 0.2469\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.2373 - val_accuracy: 0.9395 - val_loss: 0.2185\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9335 - loss: 0.2209 - val_accuracy: 0.9432 - val_loss: 0.2042\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.2045 - val_accuracy: 0.9426 - val_loss: 0.2086\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9408 - loss: 0.1949 - val_accuracy: 0.9489 - val_loss: 0.2028\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.1684 - val_accuracy: 0.9452 - val_loss: 0.2118\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9514 - loss: 0.1546 - val_accuracy: 0.9450 - val_loss: 0.2083\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.1552 - val_accuracy: 0.9439 - val_loss: 0.2192\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3296 - loss: 2.1063 - val_accuracy: 0.1281 - val_loss: 5.4728\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7504 - loss: 0.7587 - val_accuracy: 0.7395 - val_loss: 0.7981\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8491 - loss: 0.4750 - val_accuracy: 0.9104 - val_loss: 0.3016\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8856 - loss: 0.3623 - val_accuracy: 0.9142 - val_loss: 0.2918\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.3089 - val_accuracy: 0.9143 - val_loss: 0.2897\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9166 - loss: 0.2658 - val_accuracy: 0.9353 - val_loss: 0.2348\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9243 - loss: 0.2398 - val_accuracy: 0.9221 - val_loss: 0.2624\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.2090 - val_accuracy: 0.9364 - val_loss: 0.2151\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 0.1947 - val_accuracy: 0.9421 - val_loss: 0.2053\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9449 - loss: 0.1797 - val_accuracy: 0.9439 - val_loss: 0.2242\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.1682 - val_accuracy: 0.9457 - val_loss: 0.1909\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9509 - loss: 0.1568 - val_accuracy: 0.9427 - val_loss: 0.2403\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9526 - loss: 0.1540 - val_accuracy: 0.9447 - val_loss: 0.1988\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9573 - loss: 0.1445 - val_accuracy: 0.9509 - val_loss: 0.1803\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.1382 - val_accuracy: 0.9447 - val_loss: 0.2130\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3228 - loss: 2.1708 - val_accuracy: 0.1123 - val_loss: 10.3207\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7593 - loss: 0.7431 - val_accuracy: 0.7098 - val_loss: 0.9017\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.4735 - val_accuracy: 0.9200 - val_loss: 0.2555\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8904 - loss: 0.3578 - val_accuracy: 0.9242 - val_loss: 0.2463\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9076 - loss: 0.3009 - val_accuracy: 0.9356 - val_loss: 0.2095\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.2560 - val_accuracy: 0.9416 - val_loss: 0.1937\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9283 - loss: 0.2314 - val_accuracy: 0.9390 - val_loss: 0.2028\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 0.2016 - val_accuracy: 0.9448 - val_loss: 0.1869\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.1910 - val_accuracy: 0.9400 - val_loss: 0.2033\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.1797 - val_accuracy: 0.9454 - val_loss: 0.1957\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9494 - loss: 0.1654 - val_accuracy: 0.9450 - val_loss: 0.1873\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9525 - loss: 0.1539 - val_accuracy: 0.9446 - val_loss: 0.1979\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9545 - loss: 0.1504 - val_accuracy: 0.9446 - val_loss: 0.1926\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.3218 - loss: 2.1636 - val_accuracy: 0.1859 - val_loss: 4.5139\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7376 - loss: 0.8071 - val_accuracy: 0.7728 - val_loss: 0.6651\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8435 - loss: 0.4921 - val_accuracy: 0.9183 - val_loss: 0.2679\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8815 - loss: 0.3793 - val_accuracy: 0.9097 - val_loss: 0.3107\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9026 - loss: 0.3172 - val_accuracy: 0.9316 - val_loss: 0.2244\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2705 - val_accuracy: 0.9350 - val_loss: 0.2211\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9270 - loss: 0.2351 - val_accuracy: 0.9377 - val_loss: 0.2153\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9337 - loss: 0.2095 - val_accuracy: 0.9428 - val_loss: 0.2055\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9363 - loss: 0.2036 - val_accuracy: 0.9489 - val_loss: 0.1770\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9411 - loss: 0.1847 - val_accuracy: 0.9455 - val_loss: 0.1895\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9442 - loss: 0.1772 - val_accuracy: 0.9451 - val_loss: 0.2073\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9502 - loss: 0.1679 - val_accuracy: 0.9443 - val_loss: 0.2106\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3238 - loss: 2.1198 - val_accuracy: 0.2627 - val_loss: 4.3637\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7481 - loss: 0.7633 - val_accuracy: 0.7591 - val_loss: 0.7142\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8480 - loss: 0.4793 - val_accuracy: 0.8807 - val_loss: 0.3908\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8846 - loss: 0.3717 - val_accuracy: 0.9242 - val_loss: 0.2545\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9042 - loss: 0.3045 - val_accuracy: 0.9243 - val_loss: 0.2580\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9166 - loss: 0.2657 - val_accuracy: 0.9276 - val_loss: 0.2566\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9262 - loss: 0.2334 - val_accuracy: 0.9331 - val_loss: 0.2365\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9304 - loss: 0.2196 - val_accuracy: 0.9373 - val_loss: 0.2119\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9363 - loss: 0.2035 - val_accuracy: 0.9430 - val_loss: 0.2321\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.1808 - val_accuracy: 0.9406 - val_loss: 0.2108\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9431 - loss: 0.1792 - val_accuracy: 0.9476 - val_loss: 0.2228\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1533 - val_accuracy: 0.9384 - val_loss: 0.2268\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9516 - loss: 0.1611 - val_accuracy: 0.9398 - val_loss: 0.2102\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9547 - loss: 0.1516 - val_accuracy: 0.9469 - val_loss: 0.1972\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}: 0.9483\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.1398 - loss: 2.7516 - val_accuracy: 0.1124 - val_loss: 5.7362\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2689 - loss: 2.0376 - val_accuracy: 0.3151 - val_loss: 2.0221\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3451 - loss: 1.8335 - val_accuracy: 0.5213 - val_loss: 1.4509\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4101 - loss: 1.6643 - val_accuracy: 0.5893 - val_loss: 1.2415\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4774 - loss: 1.4905 - val_accuracy: 0.6612 - val_loss: 1.0601\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5332 - loss: 1.3429 - val_accuracy: 0.7140 - val_loss: 0.9169\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5860 - loss: 1.2108 - val_accuracy: 0.7524 - val_loss: 0.7991\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6343 - loss: 1.0727 - val_accuracy: 0.7901 - val_loss: 0.6888\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6682 - loss: 0.9824 - val_accuracy: 0.8147 - val_loss: 0.6120\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7026 - loss: 0.8955 - val_accuracy: 0.8346 - val_loss: 0.5527\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7268 - loss: 0.8236 - val_accuracy: 0.8510 - val_loss: 0.5005\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7495 - loss: 0.7624 - val_accuracy: 0.8651 - val_loss: 0.4514\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7655 - loss: 0.7120 - val_accuracy: 0.8700 - val_loss: 0.4311\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7778 - loss: 0.6790 - val_accuracy: 0.8807 - val_loss: 0.3945\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7968 - loss: 0.6231 - val_accuracy: 0.8869 - val_loss: 0.3686\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1423 - loss: 2.7272 - val_accuracy: 0.1132 - val_loss: 3.3437\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2661 - loss: 2.0453 - val_accuracy: 0.3889 - val_loss: 1.7980\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3466 - loss: 1.8482 - val_accuracy: 0.5185 - val_loss: 1.4544\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4171 - loss: 1.6569 - val_accuracy: 0.6024 - val_loss: 1.2155\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4819 - loss: 1.4829 - val_accuracy: 0.6615 - val_loss: 1.0461\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5357 - loss: 1.3404 - val_accuracy: 0.7058 - val_loss: 0.9163\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5871 - loss: 1.2008 - val_accuracy: 0.7487 - val_loss: 0.8067\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6279 - loss: 1.1055 - val_accuracy: 0.7820 - val_loss: 0.6938\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6681 - loss: 0.9911 - val_accuracy: 0.8047 - val_loss: 0.6164\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6942 - loss: 0.9170 - val_accuracy: 0.8238 - val_loss: 0.5552\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7177 - loss: 0.8400 - val_accuracy: 0.8401 - val_loss: 0.5037\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7444 - loss: 0.7776 - val_accuracy: 0.8604 - val_loss: 0.4504\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7594 - loss: 0.7343 - val_accuracy: 0.8645 - val_loss: 0.4268\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7755 - loss: 0.6825 - val_accuracy: 0.8799 - val_loss: 0.3842\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7893 - loss: 0.6462 - val_accuracy: 0.8847 - val_loss: 0.3760\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.1444 - loss: 2.7461 - val_accuracy: 0.1123 - val_loss: 4.8491\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2775 - loss: 2.0204 - val_accuracy: 0.3567 - val_loss: 1.8727\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3569 - loss: 1.8155 - val_accuracy: 0.5115 - val_loss: 1.4148\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4232 - loss: 1.6362 - val_accuracy: 0.5964 - val_loss: 1.2098\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4815 - loss: 1.4707 - val_accuracy: 0.6539 - val_loss: 1.0436\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5409 - loss: 1.3194 - val_accuracy: 0.7093 - val_loss: 0.9001\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5935 - loss: 1.1820 - val_accuracy: 0.7529 - val_loss: 0.7698\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6425 - loss: 1.0568 - val_accuracy: 0.7924 - val_loss: 0.6622\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6684 - loss: 0.9782 - val_accuracy: 0.8132 - val_loss: 0.5906\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7054 - loss: 0.8828 - val_accuracy: 0.8450 - val_loss: 0.5110\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.8044 - val_accuracy: 0.8561 - val_loss: 0.4660\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7576 - loss: 0.7425 - val_accuracy: 0.8668 - val_loss: 0.4319\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7725 - loss: 0.6964 - val_accuracy: 0.8759 - val_loss: 0.3997\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7861 - loss: 0.6536 - val_accuracy: 0.8805 - val_loss: 0.3760\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8029 - loss: 0.6121 - val_accuracy: 0.8882 - val_loss: 0.3562\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1509 - loss: 2.6398 - val_accuracy: 0.1125 - val_loss: 3.9457\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2767 - loss: 2.0252 - val_accuracy: 0.3744 - val_loss: 1.8294\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3551 - loss: 1.8228 - val_accuracy: 0.5326 - val_loss: 1.4182\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4206 - loss: 1.6459 - val_accuracy: 0.6040 - val_loss: 1.2156\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4839 - loss: 1.4713 - val_accuracy: 0.6766 - val_loss: 1.0323\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5450 - loss: 1.3257 - val_accuracy: 0.7240 - val_loss: 0.8929\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5931 - loss: 1.1875 - val_accuracy: 0.7555 - val_loss: 0.7775\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6384 - loss: 1.0764 - val_accuracy: 0.7893 - val_loss: 0.6864\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6710 - loss: 0.9869 - val_accuracy: 0.8123 - val_loss: 0.6152\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6917 - loss: 0.9132 - val_accuracy: 0.8321 - val_loss: 0.5450\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7235 - loss: 0.8308 - val_accuracy: 0.8492 - val_loss: 0.4990\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7447 - loss: 0.7731 - val_accuracy: 0.8576 - val_loss: 0.4640\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7647 - loss: 0.7140 - val_accuracy: 0.8689 - val_loss: 0.4254\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7774 - loss: 0.6848 - val_accuracy: 0.8796 - val_loss: 0.3988\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7970 - loss: 0.6367 - val_accuracy: 0.8825 - val_loss: 0.3873\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.1468 - loss: 2.6879 - val_accuracy: 0.1124 - val_loss: 4.1374\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2588 - loss: 2.0642 - val_accuracy: 0.3682 - val_loss: 1.8315\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3369 - loss: 1.8655 - val_accuracy: 0.4924 - val_loss: 1.4864\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4003 - loss: 1.6886 - val_accuracy: 0.5627 - val_loss: 1.2946\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4592 - loss: 1.5283 - val_accuracy: 0.6227 - val_loss: 1.1285\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5143 - loss: 1.3877 - val_accuracy: 0.6926 - val_loss: 0.9640\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5702 - loss: 1.2420 - val_accuracy: 0.7350 - val_loss: 0.8415\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6080 - loss: 1.1397 - val_accuracy: 0.7689 - val_loss: 0.7328\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6593 - loss: 1.0228 - val_accuracy: 0.7965 - val_loss: 0.6586\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6898 - loss: 0.9282 - val_accuracy: 0.8163 - val_loss: 0.5822\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7167 - loss: 0.8553 - val_accuracy: 0.8333 - val_loss: 0.5234\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7399 - loss: 0.7934 - val_accuracy: 0.8527 - val_loss: 0.4665\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7566 - loss: 0.7376 - val_accuracy: 0.8645 - val_loss: 0.4319\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7718 - loss: 0.6943 - val_accuracy: 0.8775 - val_loss: 0.3968\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7937 - loss: 0.6499 - val_accuracy: 0.8844 - val_loss: 0.3722\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0001}: 0.8853\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.2440 - loss: 2.3900 - val_accuracy: 0.1412 - val_loss: 4.3738\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5868 - loss: 1.2128 - val_accuracy: 0.7471 - val_loss: 0.7550\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7478 - loss: 0.7922 - val_accuracy: 0.8751 - val_loss: 0.4086\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8057 - loss: 0.6173 - val_accuracy: 0.8992 - val_loss: 0.3321\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8374 - loss: 0.5152 - val_accuracy: 0.9154 - val_loss: 0.2819\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8670 - loss: 0.4265 - val_accuracy: 0.9073 - val_loss: 0.3217\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.3937 - val_accuracy: 0.9190 - val_loss: 0.2737\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8858 - loss: 0.3679 - val_accuracy: 0.9269 - val_loss: 0.2407\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8987 - loss: 0.3280 - val_accuracy: 0.9276 - val_loss: 0.2510\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9026 - loss: 0.3188 - val_accuracy: 0.9323 - val_loss: 0.2360\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9073 - loss: 0.2986 - val_accuracy: 0.9319 - val_loss: 0.2479\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9112 - loss: 0.2912 - val_accuracy: 0.9312 - val_loss: 0.2591\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9144 - loss: 0.2761 - val_accuracy: 0.9398 - val_loss: 0.2039\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.2756 - val_accuracy: 0.9398 - val_loss: 0.2071\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9235 - loss: 0.2533 - val_accuracy: 0.9395 - val_loss: 0.2105\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2517 - loss: 2.3118 - val_accuracy: 0.1177 - val_loss: 6.8619\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6102 - loss: 1.1502 - val_accuracy: 0.7527 - val_loss: 0.7771\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7609 - loss: 0.7557 - val_accuracy: 0.8764 - val_loss: 0.3966\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8155 - loss: 0.5876 - val_accuracy: 0.8932 - val_loss: 0.3411\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.4951 - val_accuracy: 0.9076 - val_loss: 0.3034\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8690 - loss: 0.4229 - val_accuracy: 0.9092 - val_loss: 0.2978\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8773 - loss: 0.4016 - val_accuracy: 0.9255 - val_loss: 0.2502\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8926 - loss: 0.3546 - val_accuracy: 0.9362 - val_loss: 0.2188\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8968 - loss: 0.3358 - val_accuracy: 0.9255 - val_loss: 0.2554\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9027 - loss: 0.3201 - val_accuracy: 0.9351 - val_loss: 0.2186\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2905 - val_accuracy: 0.9359 - val_loss: 0.2166\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.2579 - loss: 2.3496 - val_accuracy: 0.1000 - val_loss: 3.4381\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6232 - loss: 1.1145 - val_accuracy: 0.6689 - val_loss: 0.9405\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7618 - loss: 0.7475 - val_accuracy: 0.8743 - val_loss: 0.4035\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8213 - loss: 0.5706 - val_accuracy: 0.9041 - val_loss: 0.3423\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8501 - loss: 0.4985 - val_accuracy: 0.9151 - val_loss: 0.2883\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8675 - loss: 0.4380 - val_accuracy: 0.9125 - val_loss: 0.3038\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8774 - loss: 0.3945 - val_accuracy: 0.9315 - val_loss: 0.2486\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8914 - loss: 0.3583 - val_accuracy: 0.9282 - val_loss: 0.2516\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8999 - loss: 0.3345 - val_accuracy: 0.9286 - val_loss: 0.2539\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9036 - loss: 0.3212 - val_accuracy: 0.9217 - val_loss: 0.3207\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.2464 - loss: 2.3358 - val_accuracy: 0.1165 - val_loss: 5.0397\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5963 - loss: 1.1826 - val_accuracy: 0.6977 - val_loss: 0.9923\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7446 - loss: 0.7892 - val_accuracy: 0.8766 - val_loss: 0.3960\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8141 - loss: 0.5895 - val_accuracy: 0.8917 - val_loss: 0.3513\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8399 - loss: 0.5151 - val_accuracy: 0.9198 - val_loss: 0.2667\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8638 - loss: 0.4406 - val_accuracy: 0.9236 - val_loss: 0.2585\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8727 - loss: 0.4070 - val_accuracy: 0.9252 - val_loss: 0.2551\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8888 - loss: 0.3674 - val_accuracy: 0.9307 - val_loss: 0.2270\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8970 - loss: 0.3440 - val_accuracy: 0.9380 - val_loss: 0.2049\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8999 - loss: 0.3205 - val_accuracy: 0.9380 - val_loss: 0.2048\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9035 - loss: 0.3093 - val_accuracy: 0.9448 - val_loss: 0.1847\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9136 - loss: 0.2887 - val_accuracy: 0.9450 - val_loss: 0.1884\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9143 - loss: 0.2723 - val_accuracy: 0.9427 - val_loss: 0.1933\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9200 - loss: 0.2717 - val_accuracy: 0.9397 - val_loss: 0.2033\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9212 - loss: 0.2600 - val_accuracy: 0.9448 - val_loss: 0.1943\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2544 - loss: 2.3457 - val_accuracy: 0.1126 - val_loss: 7.6339\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6170 - loss: 1.1289 - val_accuracy: 0.7526 - val_loss: 0.7539\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7575 - loss: 0.7559 - val_accuracy: 0.8894 - val_loss: 0.3588\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8153 - loss: 0.5967 - val_accuracy: 0.9123 - val_loss: 0.2967\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8508 - loss: 0.4849 - val_accuracy: 0.9050 - val_loss: 0.3127\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8708 - loss: 0.4233 - val_accuracy: 0.9243 - val_loss: 0.2502\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8806 - loss: 0.3815 - val_accuracy: 0.9292 - val_loss: 0.2302\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 0.3574 - val_accuracy: 0.9391 - val_loss: 0.2012\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8979 - loss: 0.3317 - val_accuracy: 0.9234 - val_loss: 0.2711\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.3121 - val_accuracy: 0.9336 - val_loss: 0.2149\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9102 - loss: 0.3022 - val_accuracy: 0.9420 - val_loss: 0.1949\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9124 - loss: 0.2814 - val_accuracy: 0.9439 - val_loss: 0.1850\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9131 - loss: 0.2914 - val_accuracy: 0.9419 - val_loss: 0.1815\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9229 - loss: 0.2621 - val_accuracy: 0.9414 - val_loss: 0.1915\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9215 - loss: 0.2663 - val_accuracy: 0.9418 - val_loss: 0.1944\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.001}: 0.9393\n",
            "Best parameters for outer fold 2: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "Best inner validation accuracy: 0.9483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outer Fold 2 - Test Accuracy: 0.9479\n",
            "\n",
            "=== Outer Fold 3/5 ===\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2193 - loss: 2.3216 - val_accuracy: 0.4355 - val_loss: 1.6797\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4412 - loss: 1.6042 - val_accuracy: 0.6770 - val_loss: 1.0080\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5776 - loss: 1.2362 - val_accuracy: 0.7807 - val_loss: 0.7291\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6792 - loss: 0.9691 - val_accuracy: 0.8316 - val_loss: 0.5560\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7402 - loss: 0.8015 - val_accuracy: 0.8577 - val_loss: 0.4597\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7773 - loss: 0.6793 - val_accuracy: 0.8809 - val_loss: 0.3916\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.5783 - val_accuracy: 0.8990 - val_loss: 0.3351\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.5156 - val_accuracy: 0.9009 - val_loss: 0.3178\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8489 - loss: 0.4715 - val_accuracy: 0.9136 - val_loss: 0.2852\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8656 - loss: 0.4212 - val_accuracy: 0.9197 - val_loss: 0.2624\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.3878 - val_accuracy: 0.9226 - val_loss: 0.2511\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.3557 - val_accuracy: 0.9259 - val_loss: 0.2398\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8928 - loss: 0.3354 - val_accuracy: 0.9206 - val_loss: 0.2563\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9009 - loss: 0.3089 - val_accuracy: 0.9324 - val_loss: 0.2180\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9065 - loss: 0.2984 - val_accuracy: 0.9346 - val_loss: 0.2206\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2105 - loss: 2.3396 - val_accuracy: 0.4342 - val_loss: 1.6794\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4490 - loss: 1.5727 - val_accuracy: 0.6977 - val_loss: 0.9727\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5894 - loss: 1.1939 - val_accuracy: 0.7640 - val_loss: 0.7446\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6850 - loss: 0.9354 - val_accuracy: 0.8265 - val_loss: 0.5547\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7495 - loss: 0.7571 - val_accuracy: 0.8614 - val_loss: 0.4461\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.6312 - val_accuracy: 0.8801 - val_loss: 0.3851\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.5538 - val_accuracy: 0.8936 - val_loss: 0.3434\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.4760 - val_accuracy: 0.9048 - val_loss: 0.3161\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8627 - loss: 0.4336 - val_accuracy: 0.9119 - val_loss: 0.2887\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8724 - loss: 0.3980 - val_accuracy: 0.9180 - val_loss: 0.2683\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.3610 - val_accuracy: 0.9224 - val_loss: 0.2550\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.3330 - val_accuracy: 0.9251 - val_loss: 0.2432\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9028 - loss: 0.3090 - val_accuracy: 0.9243 - val_loss: 0.2521\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9089 - loss: 0.2887 - val_accuracy: 0.9307 - val_loss: 0.2343\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9106 - loss: 0.2733 - val_accuracy: 0.9327 - val_loss: 0.2268\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2116 - loss: 2.3307 - val_accuracy: 0.4645 - val_loss: 1.6407\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4428 - loss: 1.5834 - val_accuracy: 0.6930 - val_loss: 1.0087\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5893 - loss: 1.2009 - val_accuracy: 0.7792 - val_loss: 0.7341\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6847 - loss: 0.9451 - val_accuracy: 0.8292 - val_loss: 0.5640\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7448 - loss: 0.7724 - val_accuracy: 0.8565 - val_loss: 0.4648\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.6542 - val_accuracy: 0.8743 - val_loss: 0.4064\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8159 - loss: 0.5753 - val_accuracy: 0.8889 - val_loss: 0.3498\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 0.5069 - val_accuracy: 0.8989 - val_loss: 0.3257\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 0.4579 - val_accuracy: 0.9085 - val_loss: 0.2906\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8692 - loss: 0.4132 - val_accuracy: 0.9122 - val_loss: 0.2821\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.3868 - val_accuracy: 0.9161 - val_loss: 0.2756\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.3475 - val_accuracy: 0.9246 - val_loss: 0.2428\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8947 - loss: 0.3323 - val_accuracy: 0.9236 - val_loss: 0.2459\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.3037 - val_accuracy: 0.9317 - val_loss: 0.2325\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9032 - loss: 0.3000 - val_accuracy: 0.9337 - val_loss: 0.2196\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2103 - loss: 2.3418 - val_accuracy: 0.3980 - val_loss: 1.7416\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4355 - loss: 1.6185 - val_accuracy: 0.6703 - val_loss: 1.0347\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5806 - loss: 1.2274 - val_accuracy: 0.7656 - val_loss: 0.7491\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6721 - loss: 0.9712 - val_accuracy: 0.8247 - val_loss: 0.5722\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7373 - loss: 0.7836 - val_accuracy: 0.8547 - val_loss: 0.4676\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7844 - loss: 0.6631 - val_accuracy: 0.8780 - val_loss: 0.3942\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.5679 - val_accuracy: 0.8951 - val_loss: 0.3397\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8367 - loss: 0.5043 - val_accuracy: 0.9092 - val_loss: 0.3016\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8619 - loss: 0.4436 - val_accuracy: 0.9148 - val_loss: 0.2719\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.4037 - val_accuracy: 0.9189 - val_loss: 0.2565\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.3726 - val_accuracy: 0.9211 - val_loss: 0.2504\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8921 - loss: 0.3401 - val_accuracy: 0.9268 - val_loss: 0.2336\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.3177 - val_accuracy: 0.9305 - val_loss: 0.2251\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9021 - loss: 0.3090 - val_accuracy: 0.9318 - val_loss: 0.2231\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9103 - loss: 0.2872 - val_accuracy: 0.9342 - val_loss: 0.2149\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2134 - loss: 2.3339 - val_accuracy: 0.4353 - val_loss: 1.6593\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4560 - loss: 1.5607 - val_accuracy: 0.7009 - val_loss: 0.9663\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5971 - loss: 1.1760 - val_accuracy: 0.7845 - val_loss: 0.6984\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6930 - loss: 0.9175 - val_accuracy: 0.8327 - val_loss: 0.5514\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7626 - loss: 0.7354 - val_accuracy: 0.8691 - val_loss: 0.4386\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.6192 - val_accuracy: 0.8818 - val_loss: 0.3937\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8282 - loss: 0.5330 - val_accuracy: 0.8942 - val_loss: 0.3487\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8448 - loss: 0.4794 - val_accuracy: 0.9058 - val_loss: 0.3105\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8611 - loss: 0.4303 - val_accuracy: 0.9087 - val_loss: 0.2962\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8720 - loss: 0.3957 - val_accuracy: 0.9162 - val_loss: 0.2780\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.3620 - val_accuracy: 0.9162 - val_loss: 0.2798\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.3395 - val_accuracy: 0.9204 - val_loss: 0.2623\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.3118 - val_accuracy: 0.9234 - val_loss: 0.2532\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9047 - loss: 0.2926 - val_accuracy: 0.9260 - val_loss: 0.2428\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2802 - val_accuracy: 0.9302 - val_loss: 0.2342\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9331\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3627 - loss: 1.9790 - val_accuracy: 0.7808 - val_loss: 0.6749\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7858 - loss: 0.6881 - val_accuracy: 0.9054 - val_loss: 0.3189\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 0.4609 - val_accuracy: 0.9077 - val_loss: 0.2992\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3829 - val_accuracy: 0.9291 - val_loss: 0.2572\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9018 - loss: 0.3300 - val_accuracy: 0.9043 - val_loss: 0.4283\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9088 - loss: 0.3067 - val_accuracy: 0.9239 - val_loss: 0.2789\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9186 - loss: 0.2803 - val_accuracy: 0.9393 - val_loss: 0.2075\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2691 - val_accuracy: 0.9174 - val_loss: 0.2723\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9270 - loss: 0.2592 - val_accuracy: 0.9413 - val_loss: 0.2032\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9297 - loss: 0.2369 - val_accuracy: 0.9451 - val_loss: 0.1988\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.2330 - val_accuracy: 0.9326 - val_loss: 0.2300\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.2263 - val_accuracy: 0.9402 - val_loss: 0.2234\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.2112 - val_accuracy: 0.9441 - val_loss: 0.2012\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3664 - loss: 1.9486 - val_accuracy: 0.7072 - val_loss: 0.8610\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7872 - loss: 0.6717 - val_accuracy: 0.9031 - val_loss: 0.3304\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8621 - loss: 0.4539 - val_accuracy: 0.8993 - val_loss: 0.3706\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8852 - loss: 0.3754 - val_accuracy: 0.9171 - val_loss: 0.3080\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9021 - loss: 0.3293 - val_accuracy: 0.9271 - val_loss: 0.2561\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.3007 - val_accuracy: 0.9228 - val_loss: 0.2552\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.2845 - val_accuracy: 0.9326 - val_loss: 0.2410\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 0.2612 - val_accuracy: 0.9293 - val_loss: 0.2507\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9288 - loss: 0.2499 - val_accuracy: 0.9417 - val_loss: 0.2125\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.2369 - val_accuracy: 0.9318 - val_loss: 0.2472\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.2361 - val_accuracy: 0.9317 - val_loss: 0.2494\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.2200 - val_accuracy: 0.9342 - val_loss: 0.2244\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3718 - loss: 1.9408 - val_accuracy: 0.7592 - val_loss: 0.7517\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.6964 - val_accuracy: 0.8967 - val_loss: 0.3381\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8531 - loss: 0.4756 - val_accuracy: 0.9122 - val_loss: 0.3095\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8834 - loss: 0.3849 - val_accuracy: 0.9216 - val_loss: 0.2713\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.3373 - val_accuracy: 0.9309 - val_loss: 0.2426\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.3068 - val_accuracy: 0.9341 - val_loss: 0.2400\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2821 - val_accuracy: 0.9407 - val_loss: 0.2117\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9213 - loss: 0.2692 - val_accuracy: 0.9304 - val_loss: 0.2828\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9299 - loss: 0.2474 - val_accuracy: 0.9389 - val_loss: 0.2117\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9316 - loss: 0.2415 - val_accuracy: 0.9425 - val_loss: 0.2076\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9326 - loss: 0.2307 - val_accuracy: 0.9358 - val_loss: 0.2280\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.2320 - val_accuracy: 0.9279 - val_loss: 0.2545\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9394 - loss: 0.2031 - val_accuracy: 0.9407 - val_loss: 0.2204\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3581 - loss: 1.9582 - val_accuracy: 0.7014 - val_loss: 0.8886\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7904 - loss: 0.6641 - val_accuracy: 0.8941 - val_loss: 0.3483\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.4496 - val_accuracy: 0.9130 - val_loss: 0.2830\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8956 - loss: 0.3517 - val_accuracy: 0.9180 - val_loss: 0.2790\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.3169 - val_accuracy: 0.9252 - val_loss: 0.3297\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9132 - loss: 0.2954 - val_accuracy: 0.9273 - val_loss: 0.2764\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9190 - loss: 0.2715 - val_accuracy: 0.9324 - val_loss: 0.2478\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.2567 - val_accuracy: 0.9323 - val_loss: 0.2320\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9290 - loss: 0.2350 - val_accuracy: 0.9324 - val_loss: 0.2358\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9340 - loss: 0.2331 - val_accuracy: 0.9306 - val_loss: 0.2474\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3654 - loss: 1.9584 - val_accuracy: 0.6717 - val_loss: 0.9721\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7872 - loss: 0.6641 - val_accuracy: 0.8920 - val_loss: 0.3521\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8609 - loss: 0.4519 - val_accuracy: 0.9181 - val_loss: 0.2840\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.3655 - val_accuracy: 0.9141 - val_loss: 0.2810\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.3071 - val_accuracy: 0.9309 - val_loss: 0.2452\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2857 - val_accuracy: 0.9336 - val_loss: 0.2542\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2577 - val_accuracy: 0.9379 - val_loss: 0.2224\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.2448 - val_accuracy: 0.9375 - val_loss: 0.2270\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.2394 - val_accuracy: 0.9293 - val_loss: 0.2469\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.2324 - val_accuracy: 0.9391 - val_loss: 0.2357\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9373 - loss: 0.2267 - val_accuracy: 0.9386 - val_loss: 0.2292\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.2207 - val_accuracy: 0.9331 - val_loss: 0.2364\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9387 - loss: 0.2116 - val_accuracy: 0.9385 - val_loss: 0.2186\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}: 0.9401\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1593 - loss: 2.5784 - val_accuracy: 0.2839 - val_loss: 2.0262\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3064 - loss: 1.9425 - val_accuracy: 0.4973 - val_loss: 1.5372\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3949 - loss: 1.7171 - val_accuracy: 0.6041 - val_loss: 1.2391\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4812 - loss: 1.4923 - val_accuracy: 0.7018 - val_loss: 1.0008\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5572 - loss: 1.2994 - val_accuracy: 0.7469 - val_loss: 0.8319\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6112 - loss: 1.1388 - val_accuracy: 0.7889 - val_loss: 0.7042\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6618 - loss: 1.0076 - val_accuracy: 0.8213 - val_loss: 0.5933\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.9013 - val_accuracy: 0.8455 - val_loss: 0.5162\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7335 - loss: 0.8146 - val_accuracy: 0.8631 - val_loss: 0.4546\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7602 - loss: 0.7402 - val_accuracy: 0.8752 - val_loss: 0.4165\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.6682 - val_accuracy: 0.8848 - val_loss: 0.3822\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 0.6144 - val_accuracy: 0.8988 - val_loss: 0.3423\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.5878 - val_accuracy: 0.9011 - val_loss: 0.3290\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8303 - loss: 0.5423 - val_accuracy: 0.9087 - val_loss: 0.3082\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8377 - loss: 0.5171 - val_accuracy: 0.9131 - val_loss: 0.2913\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.1605 - loss: 2.5634 - val_accuracy: 0.3267 - val_loss: 1.9138\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3039 - loss: 1.9426 - val_accuracy: 0.5007 - val_loss: 1.5039\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3940 - loss: 1.6910 - val_accuracy: 0.5952 - val_loss: 1.2288\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4826 - loss: 1.4685 - val_accuracy: 0.6725 - val_loss: 1.0200\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5494 - loss: 1.2943 - val_accuracy: 0.7257 - val_loss: 0.8585\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6138 - loss: 1.1349 - val_accuracy: 0.7823 - val_loss: 0.7073\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6637 - loss: 1.0071 - val_accuracy: 0.8261 - val_loss: 0.5833\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7059 - loss: 0.8923 - val_accuracy: 0.8447 - val_loss: 0.5166\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7358 - loss: 0.8108 - val_accuracy: 0.8673 - val_loss: 0.4466\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7615 - loss: 0.7412 - val_accuracy: 0.8814 - val_loss: 0.4024\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.6779 - val_accuracy: 0.8889 - val_loss: 0.3686\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.6195 - val_accuracy: 0.8958 - val_loss: 0.3394\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.5859 - val_accuracy: 0.9015 - val_loss: 0.3232\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.5566 - val_accuracy: 0.9112 - val_loss: 0.2964\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.5221 - val_accuracy: 0.9130 - val_loss: 0.2824\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1539 - loss: 2.6054 - val_accuracy: 0.3034 - val_loss: 2.0117\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2988 - loss: 1.9627 - val_accuracy: 0.5106 - val_loss: 1.5096\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3946 - loss: 1.7085 - val_accuracy: 0.5928 - val_loss: 1.2514\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4824 - loss: 1.4853 - val_accuracy: 0.6707 - val_loss: 1.0346\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5510 - loss: 1.3085 - val_accuracy: 0.7222 - val_loss: 0.8812\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6079 - loss: 1.1626 - val_accuracy: 0.7758 - val_loss: 0.7372\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6512 - loss: 1.0360 - val_accuracy: 0.8110 - val_loss: 0.6202\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.9122 - val_accuracy: 0.8336 - val_loss: 0.5477\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7320 - loss: 0.8245 - val_accuracy: 0.8507 - val_loss: 0.4847\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7581 - loss: 0.7452 - val_accuracy: 0.8634 - val_loss: 0.4440\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7808 - loss: 0.6845 - val_accuracy: 0.8768 - val_loss: 0.4068\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.6267 - val_accuracy: 0.8881 - val_loss: 0.3677\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8131 - loss: 0.5897 - val_accuracy: 0.8936 - val_loss: 0.3519\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.5490 - val_accuracy: 0.9030 - val_loss: 0.3290\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.5241 - val_accuracy: 0.9054 - val_loss: 0.3105\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1597 - loss: 2.6322 - val_accuracy: 0.3074 - val_loss: 1.9784\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3004 - loss: 1.9601 - val_accuracy: 0.4978 - val_loss: 1.5243\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3968 - loss: 1.7220 - val_accuracy: 0.6009 - val_loss: 1.2591\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4666 - loss: 1.5129 - val_accuracy: 0.6816 - val_loss: 1.0222\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5385 - loss: 1.3272 - val_accuracy: 0.7336 - val_loss: 0.8398\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6122 - loss: 1.1498 - val_accuracy: 0.7906 - val_loss: 0.6844\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6555 - loss: 1.0279 - val_accuracy: 0.8120 - val_loss: 0.5908\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7006 - loss: 0.9107 - val_accuracy: 0.8458 - val_loss: 0.4944\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7331 - loss: 0.8162 - val_accuracy: 0.8598 - val_loss: 0.4349\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7629 - loss: 0.7360 - val_accuracy: 0.8748 - val_loss: 0.3889\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 0.6849 - val_accuracy: 0.8868 - val_loss: 0.3590\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8007 - loss: 0.6224 - val_accuracy: 0.8944 - val_loss: 0.3340\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.5897 - val_accuracy: 0.9060 - val_loss: 0.2992\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.5563 - val_accuracy: 0.9125 - val_loss: 0.2840\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.5198 - val_accuracy: 0.9116 - val_loss: 0.2837\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1587 - loss: 2.5987 - val_accuracy: 0.3083 - val_loss: 1.9747\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3062 - loss: 1.9339 - val_accuracy: 0.5379 - val_loss: 1.4573\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4163 - loss: 1.6453 - val_accuracy: 0.6367 - val_loss: 1.1681\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5022 - loss: 1.4277 - val_accuracy: 0.7185 - val_loss: 0.9347\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5753 - loss: 1.2266 - val_accuracy: 0.7722 - val_loss: 0.7701\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6388 - loss: 1.0720 - val_accuracy: 0.8122 - val_loss: 0.6425\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6935 - loss: 0.9258 - val_accuracy: 0.8296 - val_loss: 0.5587\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7299 - loss: 0.8310 - val_accuracy: 0.8601 - val_loss: 0.4703\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7551 - loss: 0.7396 - val_accuracy: 0.8733 - val_loss: 0.4221\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7812 - loss: 0.6838 - val_accuracy: 0.8882 - val_loss: 0.3790\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8039 - loss: 0.6130 - val_accuracy: 0.8948 - val_loss: 0.3647\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.5815 - val_accuracy: 0.9054 - val_loss: 0.3234\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8218 - loss: 0.5566 - val_accuracy: 0.9093 - val_loss: 0.3048\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8394 - loss: 0.5099 - val_accuracy: 0.9127 - val_loss: 0.2966\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.4963 - val_accuracy: 0.9152 - val_loss: 0.2857\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}: 0.9119\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2767 - loss: 2.2244 - val_accuracy: 0.6155 - val_loss: 1.1256\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6588 - loss: 1.0352 - val_accuracy: 0.8587 - val_loss: 0.4774\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7783 - loss: 0.7172 - val_accuracy: 0.8918 - val_loss: 0.3658\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8250 - loss: 0.5812 - val_accuracy: 0.9048 - val_loss: 0.3315\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.5104 - val_accuracy: 0.9048 - val_loss: 0.3261\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.4661 - val_accuracy: 0.9229 - val_loss: 0.2738\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.4248 - val_accuracy: 0.9145 - val_loss: 0.2889\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.4112 - val_accuracy: 0.8952 - val_loss: 0.3367\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 0.3855 - val_accuracy: 0.9170 - val_loss: 0.2872\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2839 - loss: 2.1502 - val_accuracy: 0.6906 - val_loss: 0.9717\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6701 - loss: 1.0073 - val_accuracy: 0.8589 - val_loss: 0.4851\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7837 - loss: 0.6827 - val_accuracy: 0.8950 - val_loss: 0.3541\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.5515 - val_accuracy: 0.9077 - val_loss: 0.3053\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 0.4856 - val_accuracy: 0.9228 - val_loss: 0.2641\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8682 - loss: 0.4390 - val_accuracy: 0.9099 - val_loss: 0.3062\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8766 - loss: 0.4222 - val_accuracy: 0.9249 - val_loss: 0.2613\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.3889 - val_accuracy: 0.9254 - val_loss: 0.2441\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8868 - loss: 0.3788 - val_accuracy: 0.9317 - val_loss: 0.2487\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8967 - loss: 0.3525 - val_accuracy: 0.9309 - val_loss: 0.2397\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9010 - loss: 0.3457 - val_accuracy: 0.9287 - val_loss: 0.2567\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.3371 - val_accuracy: 0.9370 - val_loss: 0.2349\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9063 - loss: 0.3243 - val_accuracy: 0.9373 - val_loss: 0.2231\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.3220 - val_accuracy: 0.9290 - val_loss: 0.2493\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9067 - loss: 0.3197 - val_accuracy: 0.9371 - val_loss: 0.2345\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2853 - loss: 2.1477 - val_accuracy: 0.6701 - val_loss: 0.9875\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6589 - loss: 1.0392 - val_accuracy: 0.8571 - val_loss: 0.4675\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.6956 - val_accuracy: 0.7809 - val_loss: 0.6627\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8229 - loss: 0.5700 - val_accuracy: 0.9060 - val_loss: 0.3274\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8497 - loss: 0.5016 - val_accuracy: 0.8923 - val_loss: 0.3397\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.4552 - val_accuracy: 0.9151 - val_loss: 0.2857\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8682 - loss: 0.4383 - val_accuracy: 0.9011 - val_loss: 0.3196\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.4084 - val_accuracy: 0.8955 - val_loss: 0.3616\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.3989 - val_accuracy: 0.9177 - val_loss: 0.2863\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.3838 - val_accuracy: 0.9101 - val_loss: 0.2895\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8925 - loss: 0.3700 - val_accuracy: 0.9220 - val_loss: 0.2737\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8972 - loss: 0.3605 - val_accuracy: 0.8877 - val_loss: 0.3509\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.3515 - val_accuracy: 0.9258 - val_loss: 0.2611\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9010 - loss: 0.3334 - val_accuracy: 0.9246 - val_loss: 0.2540\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9004 - loss: 0.3366 - val_accuracy: 0.9021 - val_loss: 0.3176\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2784 - loss: 2.2031 - val_accuracy: 0.6890 - val_loss: 1.0268\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6545 - loss: 1.0560 - val_accuracy: 0.8457 - val_loss: 0.4947\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 0.7052 - val_accuracy: 0.8972 - val_loss: 0.3442\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8242 - loss: 0.5759 - val_accuracy: 0.9112 - val_loss: 0.3074\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.5008 - val_accuracy: 0.9128 - val_loss: 0.2890\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8669 - loss: 0.4500 - val_accuracy: 0.8955 - val_loss: 0.3389\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8766 - loss: 0.4155 - val_accuracy: 0.9240 - val_loss: 0.2650\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8862 - loss: 0.3911 - val_accuracy: 0.9268 - val_loss: 0.2631\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.3666 - val_accuracy: 0.9322 - val_loss: 0.2464\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8952 - loss: 0.3655 - val_accuracy: 0.9281 - val_loss: 0.2519\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.3550 - val_accuracy: 0.9229 - val_loss: 0.2782\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.3413 - val_accuracy: 0.9354 - val_loss: 0.2247\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9005 - loss: 0.3427 - val_accuracy: 0.9315 - val_loss: 0.2547\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.3261 - val_accuracy: 0.9235 - val_loss: 0.2787\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9060 - loss: 0.3216 - val_accuracy: 0.9332 - val_loss: 0.2532\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2766 - loss: 2.1818 - val_accuracy: 0.5945 - val_loss: 1.1908\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6652 - loss: 1.0212 - val_accuracy: 0.8518 - val_loss: 0.4917\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.6978 - val_accuracy: 0.7692 - val_loss: 0.6877\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8308 - loss: 0.5530 - val_accuracy: 0.9139 - val_loss: 0.2895\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8541 - loss: 0.4945 - val_accuracy: 0.9260 - val_loss: 0.2634\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 0.4494 - val_accuracy: 0.9090 - val_loss: 0.2964\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.4187 - val_accuracy: 0.9131 - val_loss: 0.2906\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8833 - loss: 0.4006 - val_accuracy: 0.9260 - val_loss: 0.2525\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}: 0.9295\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1932 - loss: 2.4183 - val_accuracy: 0.1126 - val_loss: 3.7241\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3977 - loss: 1.7065 - val_accuracy: 0.5459 - val_loss: 1.3556\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5209 - loss: 1.3799 - val_accuracy: 0.7120 - val_loss: 0.9164\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6158 - loss: 1.1253 - val_accuracy: 0.7796 - val_loss: 0.7119\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6814 - loss: 0.9411 - val_accuracy: 0.8159 - val_loss: 0.5905\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7287 - loss: 0.8133 - val_accuracy: 0.8369 - val_loss: 0.5178\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7669 - loss: 0.7010 - val_accuracy: 0.8619 - val_loss: 0.4465\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.6270 - val_accuracy: 0.8673 - val_loss: 0.4160\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8242 - loss: 0.5489 - val_accuracy: 0.8899 - val_loss: 0.3593\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8367 - loss: 0.4981 - val_accuracy: 0.9013 - val_loss: 0.3285\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8514 - loss: 0.4629 - val_accuracy: 0.9039 - val_loss: 0.3156\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.4210 - val_accuracy: 0.9081 - val_loss: 0.3013\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8725 - loss: 0.3922 - val_accuracy: 0.9145 - val_loss: 0.2795\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8820 - loss: 0.3628 - val_accuracy: 0.9209 - val_loss: 0.2669\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8921 - loss: 0.3349 - val_accuracy: 0.9239 - val_loss: 0.2526\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1905 - loss: 2.4567 - val_accuracy: 0.1123 - val_loss: 3.7760\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3779 - loss: 1.7623 - val_accuracy: 0.5286 - val_loss: 1.4194\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5061 - loss: 1.4301 - val_accuracy: 0.7097 - val_loss: 0.9448\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6006 - loss: 1.1745 - val_accuracy: 0.7765 - val_loss: 0.7295\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6677 - loss: 0.9878 - val_accuracy: 0.8132 - val_loss: 0.6070\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7234 - loss: 0.8332 - val_accuracy: 0.8493 - val_loss: 0.5010\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7652 - loss: 0.7248 - val_accuracy: 0.8655 - val_loss: 0.4390\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7913 - loss: 0.6439 - val_accuracy: 0.8755 - val_loss: 0.3985\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.5780 - val_accuracy: 0.8927 - val_loss: 0.3453\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8329 - loss: 0.5214 - val_accuracy: 0.8991 - val_loss: 0.3224\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8506 - loss: 0.4683 - val_accuracy: 0.9076 - val_loss: 0.2971\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8642 - loss: 0.4255 - val_accuracy: 0.9135 - val_loss: 0.2811\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8742 - loss: 0.3978 - val_accuracy: 0.9177 - val_loss: 0.2647\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8801 - loss: 0.3790 - val_accuracy: 0.9178 - val_loss: 0.2558\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8866 - loss: 0.3547 - val_accuracy: 0.9239 - val_loss: 0.2471\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1801 - loss: 2.4433 - val_accuracy: 0.1123 - val_loss: 4.3003\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3708 - loss: 1.7773 - val_accuracy: 0.5134 - val_loss: 1.4499\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4916 - loss: 1.4578 - val_accuracy: 0.6966 - val_loss: 0.9708\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5929 - loss: 1.1860 - val_accuracy: 0.7668 - val_loss: 0.7557\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6682 - loss: 0.9871 - val_accuracy: 0.8207 - val_loss: 0.5950\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7196 - loss: 0.8412 - val_accuracy: 0.8457 - val_loss: 0.5033\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7621 - loss: 0.7195 - val_accuracy: 0.8683 - val_loss: 0.4306\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7978 - loss: 0.6292 - val_accuracy: 0.8819 - val_loss: 0.3862\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8192 - loss: 0.5626 - val_accuracy: 0.8980 - val_loss: 0.3394\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8322 - loss: 0.5137 - val_accuracy: 0.9052 - val_loss: 0.3147\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8488 - loss: 0.4672 - val_accuracy: 0.9136 - val_loss: 0.2885\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8601 - loss: 0.4274 - val_accuracy: 0.9181 - val_loss: 0.2747\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.3970 - val_accuracy: 0.9217 - val_loss: 0.2612\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8822 - loss: 0.3691 - val_accuracy: 0.9255 - val_loss: 0.2494\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8900 - loss: 0.3439 - val_accuracy: 0.9282 - val_loss: 0.2362\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1913 - loss: 2.4026 - val_accuracy: 0.1124 - val_loss: 4.3588\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3776 - loss: 1.7527 - val_accuracy: 0.5358 - val_loss: 1.4487\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5021 - loss: 1.4263 - val_accuracy: 0.7150 - val_loss: 0.9425\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6028 - loss: 1.1654 - val_accuracy: 0.7783 - val_loss: 0.7242\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6771 - loss: 0.9638 - val_accuracy: 0.8200 - val_loss: 0.5901\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7300 - loss: 0.8149 - val_accuracy: 0.8553 - val_loss: 0.4771\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7724 - loss: 0.6978 - val_accuracy: 0.8726 - val_loss: 0.4141\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8012 - loss: 0.6208 - val_accuracy: 0.8866 - val_loss: 0.3704\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8192 - loss: 0.5515 - val_accuracy: 0.8985 - val_loss: 0.3333\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8413 - loss: 0.4884 - val_accuracy: 0.9057 - val_loss: 0.3076\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8514 - loss: 0.4634 - val_accuracy: 0.9089 - val_loss: 0.2914\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8655 - loss: 0.4150 - val_accuracy: 0.9158 - val_loss: 0.2738\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8724 - loss: 0.3944 - val_accuracy: 0.9169 - val_loss: 0.2646\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8821 - loss: 0.3643 - val_accuracy: 0.9249 - val_loss: 0.2444\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8909 - loss: 0.3412 - val_accuracy: 0.9261 - val_loss: 0.2372\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1851 - loss: 2.4841 - val_accuracy: 0.1124 - val_loss: 4.2553\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3807 - loss: 1.7687 - val_accuracy: 0.4925 - val_loss: 1.5064\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5076 - loss: 1.4216 - val_accuracy: 0.6968 - val_loss: 0.9635\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6020 - loss: 1.1657 - val_accuracy: 0.7686 - val_loss: 0.7455\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6793 - loss: 0.9703 - val_accuracy: 0.8139 - val_loss: 0.6008\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7302 - loss: 0.8091 - val_accuracy: 0.8396 - val_loss: 0.5110\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7686 - loss: 0.7063 - val_accuracy: 0.8645 - val_loss: 0.4425\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7927 - loss: 0.6308 - val_accuracy: 0.8773 - val_loss: 0.3963\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8206 - loss: 0.5642 - val_accuracy: 0.8866 - val_loss: 0.3660\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8342 - loss: 0.5073 - val_accuracy: 0.8994 - val_loss: 0.3277\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8542 - loss: 0.4656 - val_accuracy: 0.9028 - val_loss: 0.3153\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8616 - loss: 0.4365 - val_accuracy: 0.9073 - val_loss: 0.3020\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8713 - loss: 0.3977 - val_accuracy: 0.9142 - val_loss: 0.2773\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8784 - loss: 0.3737 - val_accuracy: 0.9189 - val_loss: 0.2683\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8863 - loss: 0.3496 - val_accuracy: 0.9239 - val_loss: 0.2525\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9252\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3254 - loss: 2.0933 - val_accuracy: 0.1281 - val_loss: 6.4264\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7509 - loss: 0.7684 - val_accuracy: 0.7485 - val_loss: 0.7078\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8529 - loss: 0.4692 - val_accuracy: 0.8971 - val_loss: 0.3305\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8846 - loss: 0.3722 - val_accuracy: 0.9194 - val_loss: 0.2653\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9033 - loss: 0.3041 - val_accuracy: 0.9229 - val_loss: 0.2715\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9155 - loss: 0.2649 - val_accuracy: 0.9126 - val_loss: 0.2872\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.2358 - val_accuracy: 0.9388 - val_loss: 0.2191\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9334 - loss: 0.2140 - val_accuracy: 0.9410 - val_loss: 0.2112\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9385 - loss: 0.1943 - val_accuracy: 0.9388 - val_loss: 0.2162\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9423 - loss: 0.1836 - val_accuracy: 0.9473 - val_loss: 0.1828\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9478 - loss: 0.1692 - val_accuracy: 0.9509 - val_loss: 0.1729\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.1661 - val_accuracy: 0.9491 - val_loss: 0.1984\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9517 - loss: 0.1580 - val_accuracy: 0.9451 - val_loss: 0.2016\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9538 - loss: 0.1517 - val_accuracy: 0.9478 - val_loss: 0.1916\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.3293 - loss: 2.0515 - val_accuracy: 0.1159 - val_loss: 6.5954\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7558 - loss: 0.7584 - val_accuracy: 0.8170 - val_loss: 0.5749\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8435 - loss: 0.4990 - val_accuracy: 0.8956 - val_loss: 0.3488\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8865 - loss: 0.3783 - val_accuracy: 0.9189 - val_loss: 0.2798\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9030 - loss: 0.3054 - val_accuracy: 0.9291 - val_loss: 0.2500\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9166 - loss: 0.2698 - val_accuracy: 0.9333 - val_loss: 0.2289\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9259 - loss: 0.2401 - val_accuracy: 0.9314 - val_loss: 0.2400\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9331 - loss: 0.2184 - val_accuracy: 0.9307 - val_loss: 0.2441\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9348 - loss: 0.2029 - val_accuracy: 0.9372 - val_loss: 0.2214\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9420 - loss: 0.1989 - val_accuracy: 0.9367 - val_loss: 0.2415\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.1812 - val_accuracy: 0.9372 - val_loss: 0.2290\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9508 - loss: 0.1558 - val_accuracy: 0.9420 - val_loss: 0.2233\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9519 - loss: 0.1564 - val_accuracy: 0.9381 - val_loss: 0.2252\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9566 - loss: 0.1428 - val_accuracy: 0.9380 - val_loss: 0.2271\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9575 - loss: 0.1389 - val_accuracy: 0.9411 - val_loss: 0.2459\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.3117 - loss: 2.1879 - val_accuracy: 0.1867 - val_loss: 3.7029\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7470 - loss: 0.7753 - val_accuracy: 0.7644 - val_loss: 0.6872\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8461 - loss: 0.4837 - val_accuracy: 0.9222 - val_loss: 0.2700\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.3573 - val_accuracy: 0.9222 - val_loss: 0.2728\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9044 - loss: 0.3086 - val_accuracy: 0.9295 - val_loss: 0.2367\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9187 - loss: 0.2616 - val_accuracy: 0.9367 - val_loss: 0.2261\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9262 - loss: 0.2308 - val_accuracy: 0.9442 - val_loss: 0.1988\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9349 - loss: 0.2046 - val_accuracy: 0.9458 - val_loss: 0.1966\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9386 - loss: 0.1910 - val_accuracy: 0.9463 - val_loss: 0.1970\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.1822 - val_accuracy: 0.9470 - val_loss: 0.2201\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.1614 - val_accuracy: 0.9499 - val_loss: 0.1911\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.1500 - val_accuracy: 0.9300 - val_loss: 0.2372\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9557 - loss: 0.1462 - val_accuracy: 0.9467 - val_loss: 0.2084\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9603 - loss: 0.1337 - val_accuracy: 0.9523 - val_loss: 0.2015\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9551 - loss: 0.1407 - val_accuracy: 0.9515 - val_loss: 0.2103\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.3230 - loss: 2.0759 - val_accuracy: 0.1573 - val_loss: 4.5503\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7474 - loss: 0.7720 - val_accuracy: 0.7841 - val_loss: 0.6476\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8435 - loss: 0.4867 - val_accuracy: 0.9035 - val_loss: 0.3111\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8845 - loss: 0.3704 - val_accuracy: 0.9222 - val_loss: 0.2596\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.3064 - val_accuracy: 0.9322 - val_loss: 0.2298\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2681 - val_accuracy: 0.9384 - val_loss: 0.2142\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9283 - loss: 0.2339 - val_accuracy: 0.9451 - val_loss: 0.1849\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9342 - loss: 0.2117 - val_accuracy: 0.9447 - val_loss: 0.1993\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9381 - loss: 0.1983 - val_accuracy: 0.9405 - val_loss: 0.2063\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9417 - loss: 0.1834 - val_accuracy: 0.9452 - val_loss: 0.1954\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9490 - loss: 0.1652 - val_accuracy: 0.9409 - val_loss: 0.2159\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9504 - loss: 0.1597 - val_accuracy: 0.9466 - val_loss: 0.2011\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9521 - loss: 0.1553 - val_accuracy: 0.9463 - val_loss: 0.2080\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9548 - loss: 0.1442 - val_accuracy: 0.9467 - val_loss: 0.1899\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.1366 - val_accuracy: 0.9480 - val_loss: 0.1759\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.3321 - loss: 2.0666 - val_accuracy: 0.1990 - val_loss: 3.3898\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7597 - loss: 0.7308 - val_accuracy: 0.7056 - val_loss: 0.8696\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 0.4776 - val_accuracy: 0.9042 - val_loss: 0.3105\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8862 - loss: 0.3612 - val_accuracy: 0.9259 - val_loss: 0.2346\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9092 - loss: 0.2967 - val_accuracy: 0.9355 - val_loss: 0.2097\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.2585 - val_accuracy: 0.9318 - val_loss: 0.2394\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9263 - loss: 0.2347 - val_accuracy: 0.9381 - val_loss: 0.2288\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9347 - loss: 0.2079 - val_accuracy: 0.9312 - val_loss: 0.2473\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9405 - loss: 0.1934 - val_accuracy: 0.9468 - val_loss: 0.1827\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.1764 - val_accuracy: 0.9443 - val_loss: 0.2228\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9487 - loss: 0.1715 - val_accuracy: 0.9432 - val_loss: 0.1999\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9487 - loss: 0.1635 - val_accuracy: 0.9435 - val_loss: 0.2128\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}: 0.9480\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.1470 - loss: 2.7040 - val_accuracy: 0.1124 - val_loss: 4.6957\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2632 - loss: 2.0446 - val_accuracy: 0.3741 - val_loss: 1.8229\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3430 - loss: 1.8402 - val_accuracy: 0.5420 - val_loss: 1.4357\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4090 - loss: 1.6556 - val_accuracy: 0.6223 - val_loss: 1.2158\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4806 - loss: 1.4746 - val_accuracy: 0.6651 - val_loss: 1.0659\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5309 - loss: 1.3405 - val_accuracy: 0.7167 - val_loss: 0.9140\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5843 - loss: 1.1959 - val_accuracy: 0.7575 - val_loss: 0.7896\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6327 - loss: 1.0730 - val_accuracy: 0.7882 - val_loss: 0.6902\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6730 - loss: 0.9771 - val_accuracy: 0.8139 - val_loss: 0.6077\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7011 - loss: 0.8879 - val_accuracy: 0.8345 - val_loss: 0.5405\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7239 - loss: 0.8337 - val_accuracy: 0.8509 - val_loss: 0.4936\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7490 - loss: 0.7671 - val_accuracy: 0.8628 - val_loss: 0.4561\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7694 - loss: 0.7093 - val_accuracy: 0.8709 - val_loss: 0.4240\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7822 - loss: 0.6680 - val_accuracy: 0.8798 - val_loss: 0.3958\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7989 - loss: 0.6290 - val_accuracy: 0.8830 - val_loss: 0.3799\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1489 - loss: 2.7115 - val_accuracy: 0.1123 - val_loss: 4.0377\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.2686 - loss: 2.0271 - val_accuracy: 0.3842 - val_loss: 1.8011\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3539 - loss: 1.8143 - val_accuracy: 0.5245 - val_loss: 1.4235\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4278 - loss: 1.6286 - val_accuracy: 0.6169 - val_loss: 1.1961\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4901 - loss: 1.4510 - val_accuracy: 0.6823 - val_loss: 1.0259\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5449 - loss: 1.3025 - val_accuracy: 0.7295 - val_loss: 0.8835\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6012 - loss: 1.1721 - val_accuracy: 0.7659 - val_loss: 0.7717\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6468 - loss: 1.0448 - val_accuracy: 0.8002 - val_loss: 0.6651\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6810 - loss: 0.9601 - val_accuracy: 0.8263 - val_loss: 0.5834\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7069 - loss: 0.8771 - val_accuracy: 0.8392 - val_loss: 0.5288\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7363 - loss: 0.8082 - val_accuracy: 0.8551 - val_loss: 0.4730\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7540 - loss: 0.7531 - val_accuracy: 0.8668 - val_loss: 0.4386\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7752 - loss: 0.6826 - val_accuracy: 0.8763 - val_loss: 0.4046\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7896 - loss: 0.6477 - val_accuracy: 0.8843 - val_loss: 0.3797\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7979 - loss: 0.6253 - val_accuracy: 0.8968 - val_loss: 0.3468\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.1520 - loss: 2.6757 - val_accuracy: 0.1123 - val_loss: 5.4278\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2605 - loss: 2.0462 - val_accuracy: 0.3565 - val_loss: 1.8910\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3431 - loss: 1.8439 - val_accuracy: 0.5267 - val_loss: 1.4497\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4122 - loss: 1.6664 - val_accuracy: 0.6062 - val_loss: 1.2321\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4731 - loss: 1.4911 - val_accuracy: 0.6662 - val_loss: 1.0465\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5322 - loss: 1.3426 - val_accuracy: 0.7168 - val_loss: 0.8981\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5812 - loss: 1.2186 - val_accuracy: 0.7583 - val_loss: 0.7661\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6305 - loss: 1.0893 - val_accuracy: 0.7831 - val_loss: 0.6806\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6596 - loss: 1.0087 - val_accuracy: 0.8138 - val_loss: 0.5918\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7012 - loss: 0.8960 - val_accuracy: 0.8352 - val_loss: 0.5342\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7260 - loss: 0.8378 - val_accuracy: 0.8560 - val_loss: 0.4674\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7487 - loss: 0.7632 - val_accuracy: 0.8641 - val_loss: 0.4328\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7682 - loss: 0.7054 - val_accuracy: 0.8845 - val_loss: 0.3824\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7767 - loss: 0.6861 - val_accuracy: 0.8907 - val_loss: 0.3649\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.6394 - val_accuracy: 0.8999 - val_loss: 0.3373\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.1434 - loss: 2.6963 - val_accuracy: 0.1124 - val_loss: 3.6364\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2520 - loss: 2.0672 - val_accuracy: 0.3897 - val_loss: 1.7917\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3280 - loss: 1.8829 - val_accuracy: 0.5177 - val_loss: 1.4935\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3920 - loss: 1.7183 - val_accuracy: 0.5829 - val_loss: 1.2985\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4515 - loss: 1.5573 - val_accuracy: 0.6543 - val_loss: 1.1023\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5098 - loss: 1.4028 - val_accuracy: 0.7104 - val_loss: 0.9527\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5544 - loss: 1.2848 - val_accuracy: 0.7502 - val_loss: 0.8170\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5988 - loss: 1.1659 - val_accuracy: 0.7789 - val_loss: 0.7293\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6400 - loss: 1.0628 - val_accuracy: 0.8077 - val_loss: 0.6380\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6766 - loss: 0.9662 - val_accuracy: 0.8292 - val_loss: 0.5584\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7039 - loss: 0.8929 - val_accuracy: 0.8367 - val_loss: 0.5192\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7255 - loss: 0.8298 - val_accuracy: 0.8548 - val_loss: 0.4703\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7471 - loss: 0.7732 - val_accuracy: 0.8683 - val_loss: 0.4314\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7700 - loss: 0.7139 - val_accuracy: 0.8709 - val_loss: 0.4151\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7827 - loss: 0.6682 - val_accuracy: 0.8777 - val_loss: 0.3955\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.1441 - loss: 2.7108 - val_accuracy: 0.1124 - val_loss: 4.8773\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2518 - loss: 2.0608 - val_accuracy: 0.3452 - val_loss: 1.9110\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3302 - loss: 1.8793 - val_accuracy: 0.5022 - val_loss: 1.5170\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3965 - loss: 1.6956 - val_accuracy: 0.5639 - val_loss: 1.3073\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4529 - loss: 1.5508 - val_accuracy: 0.6185 - val_loss: 1.1383\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5169 - loss: 1.3873 - val_accuracy: 0.6832 - val_loss: 0.9638\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5663 - loss: 1.2634 - val_accuracy: 0.7317 - val_loss: 0.8415\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6090 - loss: 1.1365 - val_accuracy: 0.7642 - val_loss: 0.7321\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6554 - loss: 1.0355 - val_accuracy: 0.7923 - val_loss: 0.6521\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6833 - loss: 0.9519 - val_accuracy: 0.8156 - val_loss: 0.5827\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7078 - loss: 0.8747 - val_accuracy: 0.8356 - val_loss: 0.5238\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7377 - loss: 0.8071 - val_accuracy: 0.8487 - val_loss: 0.4829\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7573 - loss: 0.7559 - val_accuracy: 0.8601 - val_loss: 0.4425\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7739 - loss: 0.7111 - val_accuracy: 0.8671 - val_loss: 0.4202\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7902 - loss: 0.6579 - val_accuracy: 0.8821 - val_loss: 0.3800\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0001}: 0.8879\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2481 - loss: 2.3014 - val_accuracy: 0.1294 - val_loss: 4.2636\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5926 - loss: 1.1956 - val_accuracy: 0.7583 - val_loss: 0.7872\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7424 - loss: 0.8014 - val_accuracy: 0.8754 - val_loss: 0.4087\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8065 - loss: 0.6186 - val_accuracy: 0.8873 - val_loss: 0.3669\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8398 - loss: 0.5174 - val_accuracy: 0.9110 - val_loss: 0.2995\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8659 - loss: 0.4418 - val_accuracy: 0.9171 - val_loss: 0.2764\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8726 - loss: 0.4151 - val_accuracy: 0.9237 - val_loss: 0.2670\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8905 - loss: 0.3626 - val_accuracy: 0.9323 - val_loss: 0.2253\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8926 - loss: 0.3512 - val_accuracy: 0.9382 - val_loss: 0.2089\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9003 - loss: 0.3238 - val_accuracy: 0.9436 - val_loss: 0.1854\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9079 - loss: 0.3103 - val_accuracy: 0.9349 - val_loss: 0.2241\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9127 - loss: 0.2890 - val_accuracy: 0.9445 - val_loss: 0.2013\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2879 - val_accuracy: 0.9453 - val_loss: 0.1969\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9196 - loss: 0.2672 - val_accuracy: 0.9439 - val_loss: 0.1888\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9225 - loss: 0.2641 - val_accuracy: 0.9432 - val_loss: 0.2033\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.2529 - loss: 2.3130 - val_accuracy: 0.1172 - val_loss: 5.6675\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6165 - loss: 1.1411 - val_accuracy: 0.7102 - val_loss: 0.8388\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7601 - loss: 0.7477 - val_accuracy: 0.8915 - val_loss: 0.3628\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8158 - loss: 0.5835 - val_accuracy: 0.9132 - val_loss: 0.2929\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8514 - loss: 0.4794 - val_accuracy: 0.9220 - val_loss: 0.2609\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8672 - loss: 0.4293 - val_accuracy: 0.9322 - val_loss: 0.2277\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8847 - loss: 0.3805 - val_accuracy: 0.9132 - val_loss: 0.3140\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8921 - loss: 0.3508 - val_accuracy: 0.9274 - val_loss: 0.2463\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8967 - loss: 0.3324 - val_accuracy: 0.9361 - val_loss: 0.2257\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9057 - loss: 0.3048 - val_accuracy: 0.9389 - val_loss: 0.2012\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9112 - loss: 0.2928 - val_accuracy: 0.9364 - val_loss: 0.2323\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9154 - loss: 0.2801 - val_accuracy: 0.9391 - val_loss: 0.2116\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.2696 - val_accuracy: 0.9400 - val_loss: 0.2100\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9222 - loss: 0.2579 - val_accuracy: 0.9463 - val_loss: 0.1853\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9258 - loss: 0.2483 - val_accuracy: 0.9444 - val_loss: 0.1935\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.2584 - loss: 2.2969 - val_accuracy: 0.1158 - val_loss: 6.5768\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6255 - loss: 1.1077 - val_accuracy: 0.7392 - val_loss: 0.8546\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7680 - loss: 0.7338 - val_accuracy: 0.8828 - val_loss: 0.3780\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8301 - loss: 0.5534 - val_accuracy: 0.9056 - val_loss: 0.3026\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.4700 - val_accuracy: 0.9246 - val_loss: 0.2416\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8730 - loss: 0.4159 - val_accuracy: 0.9342 - val_loss: 0.2248\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8854 - loss: 0.3778 - val_accuracy: 0.9312 - val_loss: 0.2286\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.3500 - val_accuracy: 0.9359 - val_loss: 0.2122\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.3211 - val_accuracy: 0.9341 - val_loss: 0.2228\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9073 - loss: 0.3026 - val_accuracy: 0.9418 - val_loss: 0.1980\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9089 - loss: 0.3084 - val_accuracy: 0.9443 - val_loss: 0.1965\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2745 - val_accuracy: 0.9429 - val_loss: 0.1979\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9168 - loss: 0.2712 - val_accuracy: 0.9382 - val_loss: 0.2232\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9205 - loss: 0.2649 - val_accuracy: 0.9461 - val_loss: 0.1860\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9275 - loss: 0.2451 - val_accuracy: 0.9481 - val_loss: 0.1843\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.2618 - loss: 2.3090 - val_accuracy: 0.1758 - val_loss: 3.8804\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6193 - loss: 1.1272 - val_accuracy: 0.7327 - val_loss: 0.8065\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7591 - loss: 0.7432 - val_accuracy: 0.8603 - val_loss: 0.4326\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8165 - loss: 0.5908 - val_accuracy: 0.9067 - val_loss: 0.3011\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8536 - loss: 0.4848 - val_accuracy: 0.9181 - val_loss: 0.2764\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8682 - loss: 0.4210 - val_accuracy: 0.9098 - val_loss: 0.3096\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8802 - loss: 0.3901 - val_accuracy: 0.9171 - val_loss: 0.2778\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8899 - loss: 0.3561 - val_accuracy: 0.9223 - val_loss: 0.2668\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8980 - loss: 0.3365 - val_accuracy: 0.9308 - val_loss: 0.2422\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9047 - loss: 0.3122 - val_accuracy: 0.9413 - val_loss: 0.1975\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9074 - loss: 0.3085 - val_accuracy: 0.9316 - val_loss: 0.2389\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9131 - loss: 0.2855 - val_accuracy: 0.9410 - val_loss: 0.2008\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9133 - loss: 0.2837 - val_accuracy: 0.9443 - val_loss: 0.1955\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.2586 - val_accuracy: 0.9430 - val_loss: 0.2089\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2550 - val_accuracy: 0.9477 - val_loss: 0.1827\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.2578 - loss: 2.2925 - val_accuracy: 0.1645 - val_loss: 4.2517\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6023 - loss: 1.1740 - val_accuracy: 0.6025 - val_loss: 1.1489\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7585 - loss: 0.7528 - val_accuracy: 0.8750 - val_loss: 0.4032\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8159 - loss: 0.5850 - val_accuracy: 0.9018 - val_loss: 0.3343\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8462 - loss: 0.4963 - val_accuracy: 0.9130 - val_loss: 0.2852\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8641 - loss: 0.4377 - val_accuracy: 0.9156 - val_loss: 0.2952\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8798 - loss: 0.3923 - val_accuracy: 0.9251 - val_loss: 0.2492\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8890 - loss: 0.3562 - val_accuracy: 0.9158 - val_loss: 0.2990\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8997 - loss: 0.3305 - val_accuracy: 0.9339 - val_loss: 0.2230\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9020 - loss: 0.3237 - val_accuracy: 0.9372 - val_loss: 0.2214\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9084 - loss: 0.2986 - val_accuracy: 0.9366 - val_loss: 0.2361\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9142 - loss: 0.2843 - val_accuracy: 0.9345 - val_loss: 0.2253\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.2734 - val_accuracy: 0.9357 - val_loss: 0.2145\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.001}: 0.9449\n",
            "Best parameters for outer fold 3: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "Best inner validation accuracy: 0.9480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outer Fold 3 - Test Accuracy: 0.9546\n",
            "\n",
            "=== Outer Fold 4/5 ===\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2226 - loss: 2.2969 - val_accuracy: 0.4242 - val_loss: 1.6927\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4469 - loss: 1.5843 - val_accuracy: 0.6927 - val_loss: 0.9934\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5857 - loss: 1.2067 - val_accuracy: 0.7859 - val_loss: 0.7063\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6767 - loss: 0.9579 - val_accuracy: 0.8470 - val_loss: 0.5193\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7505 - loss: 0.7641 - val_accuracy: 0.8668 - val_loss: 0.4337\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7885 - loss: 0.6539 - val_accuracy: 0.8784 - val_loss: 0.3930\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.5512 - val_accuracy: 0.8977 - val_loss: 0.3351\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8428 - loss: 0.4909 - val_accuracy: 0.9069 - val_loss: 0.2989\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.4487 - val_accuracy: 0.9137 - val_loss: 0.2769\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8705 - loss: 0.4067 - val_accuracy: 0.9210 - val_loss: 0.2544\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8859 - loss: 0.3629 - val_accuracy: 0.9242 - val_loss: 0.2457\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8935 - loss: 0.3368 - val_accuracy: 0.9296 - val_loss: 0.2247\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.3254 - val_accuracy: 0.9310 - val_loss: 0.2245\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9046 - loss: 0.3061 - val_accuracy: 0.9345 - val_loss: 0.2134\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9133 - loss: 0.2748 - val_accuracy: 0.9367 - val_loss: 0.2060\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.1996 - loss: 2.3419 - val_accuracy: 0.4191 - val_loss: 1.6990\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4275 - loss: 1.6316 - val_accuracy: 0.6724 - val_loss: 1.0492\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5772 - loss: 1.2441 - val_accuracy: 0.7598 - val_loss: 0.7687\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6750 - loss: 0.9663 - val_accuracy: 0.8149 - val_loss: 0.6019\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7371 - loss: 0.7866 - val_accuracy: 0.8447 - val_loss: 0.5000\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7860 - loss: 0.6562 - val_accuracy: 0.8699 - val_loss: 0.4161\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.5762 - val_accuracy: 0.8823 - val_loss: 0.3778\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.5027 - val_accuracy: 0.8939 - val_loss: 0.3392\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8569 - loss: 0.4522 - val_accuracy: 0.9070 - val_loss: 0.3123\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8704 - loss: 0.4104 - val_accuracy: 0.9129 - val_loss: 0.2943\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8784 - loss: 0.3791 - val_accuracy: 0.9136 - val_loss: 0.2798\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.3480 - val_accuracy: 0.9190 - val_loss: 0.2633\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8963 - loss: 0.3274 - val_accuracy: 0.9192 - val_loss: 0.2669\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.2934 - val_accuracy: 0.9259 - val_loss: 0.2430\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9074 - loss: 0.2891 - val_accuracy: 0.9300 - val_loss: 0.2387\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2167 - loss: 2.2946 - val_accuracy: 0.4332 - val_loss: 1.6519\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4339 - loss: 1.6029 - val_accuracy: 0.6669 - val_loss: 1.0456\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5775 - loss: 1.2343 - val_accuracy: 0.7678 - val_loss: 0.7503\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6710 - loss: 0.9867 - val_accuracy: 0.8123 - val_loss: 0.5919\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7432 - loss: 0.7806 - val_accuracy: 0.8551 - val_loss: 0.4591\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.6501 - val_accuracy: 0.8795 - val_loss: 0.3887\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.5683 - val_accuracy: 0.8874 - val_loss: 0.3543\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 0.5037 - val_accuracy: 0.9017 - val_loss: 0.3124\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 0.4577 - val_accuracy: 0.9134 - val_loss: 0.2860\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.4005 - val_accuracy: 0.9171 - val_loss: 0.2750\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.3848 - val_accuracy: 0.9231 - val_loss: 0.2593\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.3440 - val_accuracy: 0.9261 - val_loss: 0.2514\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8949 - loss: 0.3303 - val_accuracy: 0.9279 - val_loss: 0.2367\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2905 - val_accuracy: 0.9315 - val_loss: 0.2351\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2762 - val_accuracy: 0.9336 - val_loss: 0.2281\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2196 - loss: 2.2995 - val_accuracy: 0.4586 - val_loss: 1.6074\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4499 - loss: 1.5755 - val_accuracy: 0.6729 - val_loss: 1.0192\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5813 - loss: 1.2167 - val_accuracy: 0.7676 - val_loss: 0.7440\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6788 - loss: 0.9525 - val_accuracy: 0.8275 - val_loss: 0.5619\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7423 - loss: 0.7795 - val_accuracy: 0.8520 - val_loss: 0.4722\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7857 - loss: 0.6562 - val_accuracy: 0.8766 - val_loss: 0.3988\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8175 - loss: 0.5710 - val_accuracy: 0.8930 - val_loss: 0.3451\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.4907 - val_accuracy: 0.9006 - val_loss: 0.3159\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.4504 - val_accuracy: 0.9126 - val_loss: 0.2855\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8754 - loss: 0.4065 - val_accuracy: 0.9190 - val_loss: 0.2641\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.3763 - val_accuracy: 0.9206 - val_loss: 0.2509\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8890 - loss: 0.3478 - val_accuracy: 0.9283 - val_loss: 0.2360\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8935 - loss: 0.3294 - val_accuracy: 0.9329 - val_loss: 0.2239\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.3079 - val_accuracy: 0.9358 - val_loss: 0.2137\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9111 - loss: 0.2808 - val_accuracy: 0.9386 - val_loss: 0.2068\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2168 - loss: 2.2953 - val_accuracy: 0.4169 - val_loss: 1.6916\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4664 - loss: 1.5227 - val_accuracy: 0.7093 - val_loss: 0.9083\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6108 - loss: 1.1439 - val_accuracy: 0.7889 - val_loss: 0.6753\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6975 - loss: 0.9163 - val_accuracy: 0.8383 - val_loss: 0.5198\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7569 - loss: 0.7451 - val_accuracy: 0.8634 - val_loss: 0.4354\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.6247 - val_accuracy: 0.8878 - val_loss: 0.3612\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.5436 - val_accuracy: 0.9019 - val_loss: 0.3225\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.4815 - val_accuracy: 0.9091 - val_loss: 0.2928\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.4384 - val_accuracy: 0.9157 - val_loss: 0.2751\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.3987 - val_accuracy: 0.9196 - val_loss: 0.2625\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.3590 - val_accuracy: 0.9268 - val_loss: 0.2428\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8943 - loss: 0.3396 - val_accuracy: 0.9316 - val_loss: 0.2274\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.3146 - val_accuracy: 0.9357 - val_loss: 0.2185\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.2962 - val_accuracy: 0.9370 - val_loss: 0.2107\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2802 - val_accuracy: 0.9378 - val_loss: 0.2129\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9354\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3693 - loss: 1.9670 - val_accuracy: 0.7250 - val_loss: 0.8238\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.6684 - val_accuracy: 0.8829 - val_loss: 0.3848\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.4520 - val_accuracy: 0.9204 - val_loss: 0.2801\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.3640 - val_accuracy: 0.9192 - val_loss: 0.2907\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.3132 - val_accuracy: 0.9277 - val_loss: 0.2531\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2840 - val_accuracy: 0.9320 - val_loss: 0.2584\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9218 - loss: 0.2676 - val_accuracy: 0.9368 - val_loss: 0.2183\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.2435 - val_accuracy: 0.9411 - val_loss: 0.2128\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9321 - loss: 0.2330 - val_accuracy: 0.9347 - val_loss: 0.2235\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9365 - loss: 0.2174 - val_accuracy: 0.9321 - val_loss: 0.2340\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.2057 - val_accuracy: 0.9314 - val_loss: 0.2266\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3696 - loss: 1.9493 - val_accuracy: 0.6580 - val_loss: 0.9728\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.6535 - val_accuracy: 0.9035 - val_loss: 0.3370\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8642 - loss: 0.4456 - val_accuracy: 0.9084 - val_loss: 0.3015\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.3718 - val_accuracy: 0.9186 - val_loss: 0.2693\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9077 - loss: 0.3202 - val_accuracy: 0.9321 - val_loss: 0.2306\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9099 - loss: 0.3067 - val_accuracy: 0.9350 - val_loss: 0.2382\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.2815 - val_accuracy: 0.9371 - val_loss: 0.2194\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9225 - loss: 0.2723 - val_accuracy: 0.9380 - val_loss: 0.2736\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.2530 - val_accuracy: 0.9345 - val_loss: 0.2262\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9309 - loss: 0.2447 - val_accuracy: 0.9408 - val_loss: 0.2107\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9346 - loss: 0.2394 - val_accuracy: 0.9383 - val_loss: 0.2181\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.2203 - val_accuracy: 0.9391 - val_loss: 0.2272\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9353 - loss: 0.2249 - val_accuracy: 0.9317 - val_loss: 0.2508\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3657 - loss: 2.0032 - val_accuracy: 0.7564 - val_loss: 0.7313\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.6823 - val_accuracy: 0.8589 - val_loss: 0.4665\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 0.4639 - val_accuracy: 0.9059 - val_loss: 0.3093\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8858 - loss: 0.3726 - val_accuracy: 0.9240 - val_loss: 0.2688\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9039 - loss: 0.3207 - val_accuracy: 0.9388 - val_loss: 0.2101\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9150 - loss: 0.2878 - val_accuracy: 0.9388 - val_loss: 0.2286\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9217 - loss: 0.2692 - val_accuracy: 0.9365 - val_loss: 0.2303\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.2481 - val_accuracy: 0.9393 - val_loss: 0.2134\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9308 - loss: 0.2302 - val_accuracy: 0.9456 - val_loss: 0.2054\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9314 - loss: 0.2287 - val_accuracy: 0.9423 - val_loss: 0.2000\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9368 - loss: 0.2204 - val_accuracy: 0.9332 - val_loss: 0.2318\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9358 - loss: 0.2306 - val_accuracy: 0.9373 - val_loss: 0.2221\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3672 - loss: 2.0085 - val_accuracy: 0.7361 - val_loss: 0.8021\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.6576 - val_accuracy: 0.8961 - val_loss: 0.3468\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8643 - loss: 0.4407 - val_accuracy: 0.9233 - val_loss: 0.2593\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.3725 - val_accuracy: 0.9157 - val_loss: 0.2737\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9051 - loss: 0.3114 - val_accuracy: 0.9384 - val_loss: 0.2255\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 0.2910 - val_accuracy: 0.9296 - val_loss: 0.2742\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.2670 - val_accuracy: 0.9335 - val_loss: 0.2524\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9275 - loss: 0.2460 - val_accuracy: 0.9399 - val_loss: 0.2242\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.2264 - val_accuracy: 0.9400 - val_loss: 0.2393\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9355 - loss: 0.2172 - val_accuracy: 0.9375 - val_loss: 0.2181\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9380 - loss: 0.2146 - val_accuracy: 0.9407 - val_loss: 0.2383\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.2096 - val_accuracy: 0.9351 - val_loss: 0.2532\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.2019 - val_accuracy: 0.9413 - val_loss: 0.2499\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.2058 - val_accuracy: 0.9450 - val_loss: 0.2152\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1869 - val_accuracy: 0.9372 - val_loss: 0.2308\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3617 - loss: 1.9245 - val_accuracy: 0.6008 - val_loss: 1.1094\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7926 - loss: 0.6571 - val_accuracy: 0.9044 - val_loss: 0.3192\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8627 - loss: 0.4493 - val_accuracy: 0.9062 - val_loss: 0.3041\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8851 - loss: 0.3716 - val_accuracy: 0.9289 - val_loss: 0.2522\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9034 - loss: 0.3233 - val_accuracy: 0.9254 - val_loss: 0.2546\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9134 - loss: 0.2941 - val_accuracy: 0.9297 - val_loss: 0.2546\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 0.2555 - val_accuracy: 0.9367 - val_loss: 0.2277\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9276 - loss: 0.2550 - val_accuracy: 0.9259 - val_loss: 0.2607\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.2359 - val_accuracy: 0.9225 - val_loss: 0.2736\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.2316 - val_accuracy: 0.9403 - val_loss: 0.2088\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.2186 - val_accuracy: 0.9341 - val_loss: 0.2647\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.2114 - val_accuracy: 0.9388 - val_loss: 0.2262\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.1998 - val_accuracy: 0.9354 - val_loss: 0.2318\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}: 0.9426\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1641 - loss: 2.5592 - val_accuracy: 0.3246 - val_loss: 1.9465\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3100 - loss: 1.9301 - val_accuracy: 0.5014 - val_loss: 1.4664\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4111 - loss: 1.6707 - val_accuracy: 0.6001 - val_loss: 1.2110\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5007 - loss: 1.4462 - val_accuracy: 0.6913 - val_loss: 0.9809\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5699 - loss: 1.2467 - val_accuracy: 0.7534 - val_loss: 0.7929\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6321 - loss: 1.0798 - val_accuracy: 0.7987 - val_loss: 0.6570\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6841 - loss: 0.9433 - val_accuracy: 0.8299 - val_loss: 0.5571\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.8386 - val_accuracy: 0.8547 - val_loss: 0.4828\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7518 - loss: 0.7625 - val_accuracy: 0.8689 - val_loss: 0.4365\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.6882 - val_accuracy: 0.8816 - val_loss: 0.3987\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.6466 - val_accuracy: 0.8870 - val_loss: 0.3737\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.5970 - val_accuracy: 0.8981 - val_loss: 0.3419\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.5593 - val_accuracy: 0.9048 - val_loss: 0.3239\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8377 - loss: 0.5131 - val_accuracy: 0.9069 - val_loss: 0.3097\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.4985 - val_accuracy: 0.9084 - val_loss: 0.3128\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1632 - loss: 2.5865 - val_accuracy: 0.2634 - val_loss: 2.1007\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3082 - loss: 1.9313 - val_accuracy: 0.5070 - val_loss: 1.5048\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3918 - loss: 1.7044 - val_accuracy: 0.6007 - val_loss: 1.2541\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4675 - loss: 1.5138 - val_accuracy: 0.6755 - val_loss: 1.0367\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5456 - loss: 1.3293 - val_accuracy: 0.7306 - val_loss: 0.8636\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5999 - loss: 1.1681 - val_accuracy: 0.7767 - val_loss: 0.7259\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6491 - loss: 1.0462 - val_accuracy: 0.8219 - val_loss: 0.5990\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6856 - loss: 0.9431 - val_accuracy: 0.8373 - val_loss: 0.5312\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7289 - loss: 0.8378 - val_accuracy: 0.8571 - val_loss: 0.4696\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.7680 - val_accuracy: 0.8734 - val_loss: 0.4174\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7738 - loss: 0.7045 - val_accuracy: 0.8878 - val_loss: 0.3737\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.6425 - val_accuracy: 0.8935 - val_loss: 0.3484\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8037 - loss: 0.6144 - val_accuracy: 0.9028 - val_loss: 0.3140\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.5667 - val_accuracy: 0.9101 - val_loss: 0.2959\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 0.5292 - val_accuracy: 0.9181 - val_loss: 0.2772\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1645 - loss: 2.5682 - val_accuracy: 0.3124 - val_loss: 1.9832\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3138 - loss: 1.9266 - val_accuracy: 0.5148 - val_loss: 1.4672\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4032 - loss: 1.6889 - val_accuracy: 0.6054 - val_loss: 1.2089\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4912 - loss: 1.4574 - val_accuracy: 0.7000 - val_loss: 0.9731\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5698 - loss: 1.2495 - val_accuracy: 0.7655 - val_loss: 0.7873\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6347 - loss: 1.0924 - val_accuracy: 0.8039 - val_loss: 0.6553\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6804 - loss: 0.9597 - val_accuracy: 0.8367 - val_loss: 0.5592\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7170 - loss: 0.8555 - val_accuracy: 0.8565 - val_loss: 0.4904\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.7488 - val_accuracy: 0.8696 - val_loss: 0.4408\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.6972 - val_accuracy: 0.8806 - val_loss: 0.3958\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7943 - loss: 0.6505 - val_accuracy: 0.8898 - val_loss: 0.3721\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.5959 - val_accuracy: 0.9008 - val_loss: 0.3369\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.5625 - val_accuracy: 0.9073 - val_loss: 0.3225\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8283 - loss: 0.5322 - val_accuracy: 0.9140 - val_loss: 0.2939\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8463 - loss: 0.4944 - val_accuracy: 0.9137 - val_loss: 0.2941\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1576 - loss: 2.5706 - val_accuracy: 0.2393 - val_loss: 2.2258\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2923 - loss: 1.9730 - val_accuracy: 0.4885 - val_loss: 1.5422\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3916 - loss: 1.7219 - val_accuracy: 0.5945 - val_loss: 1.2553\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4833 - loss: 1.4788 - val_accuracy: 0.6697 - val_loss: 1.0290\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5566 - loss: 1.2819 - val_accuracy: 0.7361 - val_loss: 0.8470\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6160 - loss: 1.1270 - val_accuracy: 0.7752 - val_loss: 0.7180\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6654 - loss: 0.9903 - val_accuracy: 0.8021 - val_loss: 0.6348\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7064 - loss: 0.8859 - val_accuracy: 0.8315 - val_loss: 0.5465\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7419 - loss: 0.7954 - val_accuracy: 0.8484 - val_loss: 0.4964\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7663 - loss: 0.7309 - val_accuracy: 0.8626 - val_loss: 0.4436\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7865 - loss: 0.6589 - val_accuracy: 0.8767 - val_loss: 0.4051\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.6153 - val_accuracy: 0.8859 - val_loss: 0.3767\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.5710 - val_accuracy: 0.8852 - val_loss: 0.3757\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.5427 - val_accuracy: 0.8989 - val_loss: 0.3398\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8408 - loss: 0.5054 - val_accuracy: 0.9034 - val_loss: 0.3238\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.1616 - loss: 2.5617 - val_accuracy: 0.2956 - val_loss: 1.9939\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3062 - loss: 1.9373 - val_accuracy: 0.5384 - val_loss: 1.4392\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4070 - loss: 1.6740 - val_accuracy: 0.6309 - val_loss: 1.1543\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 1.4318 - val_accuracy: 0.7021 - val_loss: 0.9542\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5696 - loss: 1.2496 - val_accuracy: 0.7585 - val_loss: 0.7846\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6225 - loss: 1.1044 - val_accuracy: 0.7999 - val_loss: 0.6488\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6757 - loss: 0.9743 - val_accuracy: 0.8253 - val_loss: 0.5673\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7105 - loss: 0.8834 - val_accuracy: 0.8498 - val_loss: 0.4825\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.7875 - val_accuracy: 0.8571 - val_loss: 0.4555\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7647 - loss: 0.7356 - val_accuracy: 0.8774 - val_loss: 0.3936\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.6747 - val_accuracy: 0.8879 - val_loss: 0.3574\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8008 - loss: 0.6324 - val_accuracy: 0.8976 - val_loss: 0.3264\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8128 - loss: 0.5900 - val_accuracy: 0.9060 - val_loss: 0.3002\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.5516 - val_accuracy: 0.9128 - val_loss: 0.2838\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 0.5175 - val_accuracy: 0.9167 - val_loss: 0.2695\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}: 0.9121\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2754 - loss: 2.2086 - val_accuracy: 0.6482 - val_loss: 1.0508\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6575 - loss: 1.0319 - val_accuracy: 0.8134 - val_loss: 0.5784\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7788 - loss: 0.7186 - val_accuracy: 0.8376 - val_loss: 0.4959\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.5759 - val_accuracy: 0.8997 - val_loss: 0.3221\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 0.5168 - val_accuracy: 0.9148 - val_loss: 0.2779\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8573 - loss: 0.4751 - val_accuracy: 0.9172 - val_loss: 0.2737\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8721 - loss: 0.4352 - val_accuracy: 0.9215 - val_loss: 0.2557\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.4182 - val_accuracy: 0.9044 - val_loss: 0.3240\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8830 - loss: 0.3942 - val_accuracy: 0.9155 - val_loss: 0.2822\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8886 - loss: 0.3807 - val_accuracy: 0.9252 - val_loss: 0.2612\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.3778 - val_accuracy: 0.9264 - val_loss: 0.2492\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.3703 - val_accuracy: 0.9240 - val_loss: 0.2627\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.3510 - val_accuracy: 0.9178 - val_loss: 0.3263\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.3482 - val_accuracy: 0.9282 - val_loss: 0.2658\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8976 - loss: 0.3407 - val_accuracy: 0.9282 - val_loss: 0.2497\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2768 - loss: 2.1818 - val_accuracy: 0.6377 - val_loss: 1.0849\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6605 - loss: 1.0292 - val_accuracy: 0.8647 - val_loss: 0.4538\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7857 - loss: 0.6935 - val_accuracy: 0.8890 - val_loss: 0.3695\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8312 - loss: 0.5542 - val_accuracy: 0.9101 - val_loss: 0.3060\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8550 - loss: 0.4889 - val_accuracy: 0.9169 - val_loss: 0.2808\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8689 - loss: 0.4367 - val_accuracy: 0.9216 - val_loss: 0.2697\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8816 - loss: 0.3993 - val_accuracy: 0.9283 - val_loss: 0.2381\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.3804 - val_accuracy: 0.9371 - val_loss: 0.2160\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8935 - loss: 0.3629 - val_accuracy: 0.9278 - val_loss: 0.2391\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8959 - loss: 0.3478 - val_accuracy: 0.9323 - val_loss: 0.2302\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8986 - loss: 0.3444 - val_accuracy: 0.9360 - val_loss: 0.2216\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2715 - loss: 2.1799 - val_accuracy: 0.6007 - val_loss: 1.1259\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6421 - loss: 1.0757 - val_accuracy: 0.8423 - val_loss: 0.5119\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.7170 - val_accuracy: 0.8723 - val_loss: 0.4365\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8190 - loss: 0.5841 - val_accuracy: 0.9044 - val_loss: 0.3174\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8463 - loss: 0.5087 - val_accuracy: 0.8809 - val_loss: 0.4650\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8606 - loss: 0.4511 - val_accuracy: 0.9181 - val_loss: 0.2761\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8724 - loss: 0.4254 - val_accuracy: 0.9131 - val_loss: 0.2992\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.4081 - val_accuracy: 0.9232 - val_loss: 0.2726\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8877 - loss: 0.3871 - val_accuracy: 0.9169 - val_loss: 0.2817\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8941 - loss: 0.3600 - val_accuracy: 0.9221 - val_loss: 0.2723\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8951 - loss: 0.3513 - val_accuracy: 0.9187 - val_loss: 0.2993\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2901 - loss: 2.1428 - val_accuracy: 0.7005 - val_loss: 0.9342\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6730 - loss: 0.9993 - val_accuracy: 0.8442 - val_loss: 0.5167\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.7122 - val_accuracy: 0.8986 - val_loss: 0.3363\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.5807 - val_accuracy: 0.8984 - val_loss: 0.3372\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8491 - loss: 0.4989 - val_accuracy: 0.9243 - val_loss: 0.2629\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8634 - loss: 0.4653 - val_accuracy: 0.9261 - val_loss: 0.2579\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8746 - loss: 0.4260 - val_accuracy: 0.9340 - val_loss: 0.2346\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.4104 - val_accuracy: 0.9221 - val_loss: 0.2695\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8887 - loss: 0.3853 - val_accuracy: 0.9281 - val_loss: 0.2508\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.3718 - val_accuracy: 0.9327 - val_loss: 0.2514\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2737 - loss: 2.2303 - val_accuracy: 0.5622 - val_loss: 1.2566\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6327 - loss: 1.1028 - val_accuracy: 0.8322 - val_loss: 0.5566\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7641 - loss: 0.7519 - val_accuracy: 0.8658 - val_loss: 0.4445\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.5841 - val_accuracy: 0.8914 - val_loss: 0.3585\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8447 - loss: 0.5133 - val_accuracy: 0.9211 - val_loss: 0.2745\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8583 - loss: 0.4671 - val_accuracy: 0.8854 - val_loss: 0.3743\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8719 - loss: 0.4304 - val_accuracy: 0.9232 - val_loss: 0.2616\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8781 - loss: 0.4134 - val_accuracy: 0.9198 - val_loss: 0.2736\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8853 - loss: 0.3943 - val_accuracy: 0.9259 - val_loss: 0.2648\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8880 - loss: 0.3818 - val_accuracy: 0.9277 - val_loss: 0.2654\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8973 - loss: 0.3425 - val_accuracy: 0.9337 - val_loss: 0.2348\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8982 - loss: 0.3466 - val_accuracy: 0.9352 - val_loss: 0.2280\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8991 - loss: 0.3381 - val_accuracy: 0.9335 - val_loss: 0.2534\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9039 - loss: 0.3248 - val_accuracy: 0.9383 - val_loss: 0.2219\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9062 - loss: 0.3276 - val_accuracy: 0.9334 - val_loss: 0.2392\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}: 0.9322\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.2020 - loss: 2.3542 - val_accuracy: 0.1123 - val_loss: 4.4075\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3932 - loss: 1.7212 - val_accuracy: 0.5101 - val_loss: 1.4744\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5162 - loss: 1.3881 - val_accuracy: 0.7193 - val_loss: 0.9244\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6127 - loss: 1.1309 - val_accuracy: 0.7765 - val_loss: 0.7127\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6837 - loss: 0.9358 - val_accuracy: 0.8232 - val_loss: 0.5742\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7389 - loss: 0.7913 - val_accuracy: 0.8458 - val_loss: 0.4923\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7713 - loss: 0.6964 - val_accuracy: 0.8664 - val_loss: 0.4330\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8027 - loss: 0.6148 - val_accuracy: 0.8798 - val_loss: 0.3809\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8217 - loss: 0.5509 - val_accuracy: 0.8935 - val_loss: 0.3424\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8412 - loss: 0.4966 - val_accuracy: 0.9021 - val_loss: 0.3140\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8536 - loss: 0.4584 - val_accuracy: 0.9083 - val_loss: 0.2987\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8661 - loss: 0.4176 - val_accuracy: 0.9128 - val_loss: 0.2791\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8724 - loss: 0.3956 - val_accuracy: 0.9145 - val_loss: 0.2746\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8813 - loss: 0.3729 - val_accuracy: 0.9194 - val_loss: 0.2572\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8903 - loss: 0.3440 - val_accuracy: 0.9217 - val_loss: 0.2527\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.1845 - loss: 2.4303 - val_accuracy: 0.1124 - val_loss: 4.2350\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3751 - loss: 1.7586 - val_accuracy: 0.4929 - val_loss: 1.5065\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5006 - loss: 1.4381 - val_accuracy: 0.7051 - val_loss: 0.9460\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5961 - loss: 1.1813 - val_accuracy: 0.7702 - val_loss: 0.7399\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6756 - loss: 0.9674 - val_accuracy: 0.8201 - val_loss: 0.5930\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7262 - loss: 0.8288 - val_accuracy: 0.8486 - val_loss: 0.5006\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7594 - loss: 0.7342 - val_accuracy: 0.8733 - val_loss: 0.4218\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7864 - loss: 0.6497 - val_accuracy: 0.8820 - val_loss: 0.3832\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8165 - loss: 0.5684 - val_accuracy: 0.8931 - val_loss: 0.3491\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8316 - loss: 0.5190 - val_accuracy: 0.9036 - val_loss: 0.3152\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8454 - loss: 0.4786 - val_accuracy: 0.9091 - val_loss: 0.2971\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8568 - loss: 0.4474 - val_accuracy: 0.9168 - val_loss: 0.2729\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8664 - loss: 0.4207 - val_accuracy: 0.9176 - val_loss: 0.2667\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8791 - loss: 0.3800 - val_accuracy: 0.9228 - val_loss: 0.2514\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8845 - loss: 0.3610 - val_accuracy: 0.9256 - val_loss: 0.2360\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1936 - loss: 2.4161 - val_accuracy: 0.1124 - val_loss: 7.2143\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3902 - loss: 1.7269 - val_accuracy: 0.4787 - val_loss: 1.5573\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5144 - loss: 1.3899 - val_accuracy: 0.7190 - val_loss: 0.9219\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6121 - loss: 1.1377 - val_accuracy: 0.7765 - val_loss: 0.7250\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6779 - loss: 0.9554 - val_accuracy: 0.8259 - val_loss: 0.5805\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7299 - loss: 0.8143 - val_accuracy: 0.8542 - val_loss: 0.4862\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7691 - loss: 0.7072 - val_accuracy: 0.8709 - val_loss: 0.4262\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8003 - loss: 0.6157 - val_accuracy: 0.8823 - val_loss: 0.3882\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8244 - loss: 0.5388 - val_accuracy: 0.8967 - val_loss: 0.3429\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8360 - loss: 0.5089 - val_accuracy: 0.9027 - val_loss: 0.3218\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8543 - loss: 0.4575 - val_accuracy: 0.9095 - val_loss: 0.3034\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8653 - loss: 0.4205 - val_accuracy: 0.9160 - val_loss: 0.2784\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8737 - loss: 0.3919 - val_accuracy: 0.9182 - val_loss: 0.2628\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8808 - loss: 0.3712 - val_accuracy: 0.9237 - val_loss: 0.2535\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8902 - loss: 0.3475 - val_accuracy: 0.9271 - val_loss: 0.2375\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1866 - loss: 2.4174 - val_accuracy: 0.1128 - val_loss: 3.7843\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3784 - loss: 1.7637 - val_accuracy: 0.5033 - val_loss: 1.4838\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5021 - loss: 1.4355 - val_accuracy: 0.6925 - val_loss: 0.9797\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5937 - loss: 1.1893 - val_accuracy: 0.7667 - val_loss: 0.7679\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6675 - loss: 0.9898 - val_accuracy: 0.8047 - val_loss: 0.6345\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7172 - loss: 0.8634 - val_accuracy: 0.8382 - val_loss: 0.5316\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7572 - loss: 0.7424 - val_accuracy: 0.8537 - val_loss: 0.4704\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7948 - loss: 0.6389 - val_accuracy: 0.8676 - val_loss: 0.4294\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8098 - loss: 0.5884 - val_accuracy: 0.8792 - val_loss: 0.3891\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8226 - loss: 0.5470 - val_accuracy: 0.8917 - val_loss: 0.3553\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8440 - loss: 0.4813 - val_accuracy: 0.9018 - val_loss: 0.3275\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8543 - loss: 0.4599 - val_accuracy: 0.9062 - val_loss: 0.3165\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8648 - loss: 0.4290 - val_accuracy: 0.9111 - val_loss: 0.2934\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.3867 - val_accuracy: 0.9147 - val_loss: 0.2809\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8827 - loss: 0.3761 - val_accuracy: 0.9166 - val_loss: 0.2768\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1966 - loss: 2.3891 - val_accuracy: 0.1124 - val_loss: 5.2006\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3950 - loss: 1.7215 - val_accuracy: 0.5034 - val_loss: 1.4922\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5204 - loss: 1.3891 - val_accuracy: 0.7125 - val_loss: 0.9092\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6134 - loss: 1.1319 - val_accuracy: 0.7803 - val_loss: 0.7216\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6793 - loss: 0.9531 - val_accuracy: 0.8172 - val_loss: 0.5922\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7293 - loss: 0.8170 - val_accuracy: 0.8405 - val_loss: 0.5131\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7620 - loss: 0.7243 - val_accuracy: 0.8585 - val_loss: 0.4519\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7906 - loss: 0.6380 - val_accuracy: 0.8730 - val_loss: 0.4101\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8162 - loss: 0.5699 - val_accuracy: 0.8848 - val_loss: 0.3700\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8307 - loss: 0.5308 - val_accuracy: 0.8915 - val_loss: 0.3484\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8494 - loss: 0.4685 - val_accuracy: 0.9013 - val_loss: 0.3206\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8531 - loss: 0.4469 - val_accuracy: 0.9076 - val_loss: 0.3027\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8662 - loss: 0.4107 - val_accuracy: 0.9104 - val_loss: 0.2928\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8744 - loss: 0.3942 - val_accuracy: 0.9189 - val_loss: 0.2722\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8836 - loss: 0.3625 - val_accuracy: 0.9197 - val_loss: 0.2659\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9221\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.3310 - loss: 2.0415 - val_accuracy: 0.1309 - val_loss: 6.1965\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7634 - loss: 0.7352 - val_accuracy: 0.7546 - val_loss: 0.7273\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8550 - loss: 0.4574 - val_accuracy: 0.8863 - val_loss: 0.3656\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8899 - loss: 0.3549 - val_accuracy: 0.9272 - val_loss: 0.2445\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9086 - loss: 0.2931 - val_accuracy: 0.9344 - val_loss: 0.2240\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9224 - loss: 0.2552 - val_accuracy: 0.9320 - val_loss: 0.2355\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9302 - loss: 0.2269 - val_accuracy: 0.9373 - val_loss: 0.2232\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9355 - loss: 0.2115 - val_accuracy: 0.9350 - val_loss: 0.2336\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9388 - loss: 0.1936 - val_accuracy: 0.9446 - val_loss: 0.2020\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.1770 - val_accuracy: 0.9405 - val_loss: 0.2080\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9494 - loss: 0.1686 - val_accuracy: 0.9429 - val_loss: 0.2160\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9513 - loss: 0.1558 - val_accuracy: 0.9463 - val_loss: 0.1885\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9543 - loss: 0.1520 - val_accuracy: 0.9440 - val_loss: 0.2292\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9571 - loss: 0.1396 - val_accuracy: 0.9447 - val_loss: 0.2063\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9595 - loss: 0.1322 - val_accuracy: 0.9471 - val_loss: 0.2067\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3192 - loss: 2.1053 - val_accuracy: 0.1698 - val_loss: 3.9817\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7425 - loss: 0.7913 - val_accuracy: 0.7743 - val_loss: 0.6779\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8371 - loss: 0.5160 - val_accuracy: 0.9061 - val_loss: 0.3092\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8788 - loss: 0.3843 - val_accuracy: 0.9175 - val_loss: 0.2636\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8969 - loss: 0.3302 - val_accuracy: 0.9279 - val_loss: 0.2504\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9109 - loss: 0.2881 - val_accuracy: 0.9244 - val_loss: 0.2455\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2466 - val_accuracy: 0.9361 - val_loss: 0.2112\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.2373 - val_accuracy: 0.9415 - val_loss: 0.1981\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9341 - loss: 0.2117 - val_accuracy: 0.9444 - val_loss: 0.2094\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9397 - loss: 0.1903 - val_accuracy: 0.9483 - val_loss: 0.1841\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9437 - loss: 0.1818 - val_accuracy: 0.9474 - val_loss: 0.1799\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9484 - loss: 0.1733 - val_accuracy: 0.9446 - val_loss: 0.2103\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9494 - loss: 0.1664 - val_accuracy: 0.9517 - val_loss: 0.1767\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9540 - loss: 0.1490 - val_accuracy: 0.9493 - val_loss: 0.1908\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1523 - val_accuracy: 0.9435 - val_loss: 0.2072\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.3213 - loss: 2.0742 - val_accuracy: 0.3004 - val_loss: 3.4880\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7454 - loss: 0.7752 - val_accuracy: 0.8288 - val_loss: 0.5271\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8438 - loss: 0.4909 - val_accuracy: 0.8983 - val_loss: 0.3316\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8802 - loss: 0.3833 - val_accuracy: 0.9202 - val_loss: 0.2599\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8963 - loss: 0.3291 - val_accuracy: 0.9282 - val_loss: 0.2460\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9143 - loss: 0.2794 - val_accuracy: 0.9372 - val_loss: 0.2175\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2412 - val_accuracy: 0.9328 - val_loss: 0.2429\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9329 - loss: 0.2164 - val_accuracy: 0.9424 - val_loss: 0.2033\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9345 - loss: 0.2124 - val_accuracy: 0.9291 - val_loss: 0.2389\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9440 - loss: 0.1879 - val_accuracy: 0.9442 - val_loss: 0.2087\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9473 - loss: 0.1692 - val_accuracy: 0.9409 - val_loss: 0.2104\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9507 - loss: 0.1645 - val_accuracy: 0.9458 - val_loss: 0.2232\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.1462 - val_accuracy: 0.9463 - val_loss: 0.1999\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9526 - loss: 0.1519 - val_accuracy: 0.9494 - val_loss: 0.1891\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9583 - loss: 0.1409 - val_accuracy: 0.9436 - val_loss: 0.2083\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.3230 - loss: 2.1148 - val_accuracy: 0.3058 - val_loss: 3.4879\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7496 - loss: 0.7724 - val_accuracy: 0.7523 - val_loss: 0.7389\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8501 - loss: 0.4770 - val_accuracy: 0.9216 - val_loss: 0.2649\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8847 - loss: 0.3743 - val_accuracy: 0.9232 - val_loss: 0.2560\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9048 - loss: 0.3109 - val_accuracy: 0.9367 - val_loss: 0.2145\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9168 - loss: 0.2688 - val_accuracy: 0.9347 - val_loss: 0.2176\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9265 - loss: 0.2393 - val_accuracy: 0.9438 - val_loss: 0.1942\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9318 - loss: 0.2249 - val_accuracy: 0.9478 - val_loss: 0.2003\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9387 - loss: 0.1921 - val_accuracy: 0.9453 - val_loss: 0.1967\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9423 - loss: 0.1825 - val_accuracy: 0.9432 - val_loss: 0.2221\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9452 - loss: 0.1775 - val_accuracy: 0.9177 - val_loss: 0.2830\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.3258 - loss: 2.1224 - val_accuracy: 0.1405 - val_loss: 5.9246\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7653 - loss: 0.7339 - val_accuracy: 0.6629 - val_loss: 0.9818\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.4697 - val_accuracy: 0.8968 - val_loss: 0.3269\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8866 - loss: 0.3640 - val_accuracy: 0.9145 - val_loss: 0.2909\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9087 - loss: 0.2990 - val_accuracy: 0.9195 - val_loss: 0.2682\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9187 - loss: 0.2617 - val_accuracy: 0.9339 - val_loss: 0.2259\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9282 - loss: 0.2326 - val_accuracy: 0.9393 - val_loss: 0.2105\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9344 - loss: 0.2180 - val_accuracy: 0.9419 - val_loss: 0.2148\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9405 - loss: 0.1965 - val_accuracy: 0.9406 - val_loss: 0.2332\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.1751 - val_accuracy: 0.9433 - val_loss: 0.2059\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.1662 - val_accuracy: 0.9428 - val_loss: 0.2173\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9511 - loss: 0.1550 - val_accuracy: 0.9464 - val_loss: 0.1941\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9533 - loss: 0.1570 - val_accuracy: 0.9440 - val_loss: 0.2195\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9577 - loss: 0.1447 - val_accuracy: 0.9390 - val_loss: 0.2081\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9570 - loss: 0.1408 - val_accuracy: 0.9434 - val_loss: 0.2465\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}: 0.9485\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1440 - loss: 2.7037 - val_accuracy: 0.1123 - val_loss: 5.5640\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2628 - loss: 2.0459 - val_accuracy: 0.3222 - val_loss: 2.0050\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3398 - loss: 1.8404 - val_accuracy: 0.5193 - val_loss: 1.4598\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4085 - loss: 1.6694 - val_accuracy: 0.6046 - val_loss: 1.2405\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4723 - loss: 1.4918 - val_accuracy: 0.6628 - val_loss: 1.0697\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5222 - loss: 1.3716 - val_accuracy: 0.7038 - val_loss: 0.9406\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5825 - loss: 1.2154 - val_accuracy: 0.7449 - val_loss: 0.8172\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6260 - loss: 1.0972 - val_accuracy: 0.7808 - val_loss: 0.7192\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6630 - loss: 1.0073 - val_accuracy: 0.8077 - val_loss: 0.6400\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6948 - loss: 0.9280 - val_accuracy: 0.8265 - val_loss: 0.5779\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7203 - loss: 0.8557 - val_accuracy: 0.8413 - val_loss: 0.5213\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7455 - loss: 0.7790 - val_accuracy: 0.8535 - val_loss: 0.4801\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7644 - loss: 0.7275 - val_accuracy: 0.8660 - val_loss: 0.4472\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7817 - loss: 0.6891 - val_accuracy: 0.8720 - val_loss: 0.4195\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7910 - loss: 0.6562 - val_accuracy: 0.8790 - val_loss: 0.4037\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1454 - loss: 2.7132 - val_accuracy: 0.1124 - val_loss: 5.3322\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2682 - loss: 2.0179 - val_accuracy: 0.3526 - val_loss: 1.9091\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3538 - loss: 1.8126 - val_accuracy: 0.5405 - val_loss: 1.4129\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4201 - loss: 1.6352 - val_accuracy: 0.6092 - val_loss: 1.1875\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4884 - loss: 1.4644 - val_accuracy: 0.6791 - val_loss: 1.0145\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5400 - loss: 1.3167 - val_accuracy: 0.7231 - val_loss: 0.8800\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5954 - loss: 1.1666 - val_accuracy: 0.7647 - val_loss: 0.7545\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6389 - loss: 1.0720 - val_accuracy: 0.7978 - val_loss: 0.6610\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6753 - loss: 0.9657 - val_accuracy: 0.8258 - val_loss: 0.5788\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7063 - loss: 0.8865 - val_accuracy: 0.8375 - val_loss: 0.5272\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7325 - loss: 0.8176 - val_accuracy: 0.8530 - val_loss: 0.4823\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7547 - loss: 0.7507 - val_accuracy: 0.8660 - val_loss: 0.4421\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7712 - loss: 0.7037 - val_accuracy: 0.8736 - val_loss: 0.4137\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7890 - loss: 0.6544 - val_accuracy: 0.8827 - val_loss: 0.3827\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.6281 - val_accuracy: 0.8836 - val_loss: 0.3737\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1432 - loss: 2.6364 - val_accuracy: 0.1124 - val_loss: 5.1200\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2612 - loss: 2.0516 - val_accuracy: 0.3204 - val_loss: 1.9617\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3311 - loss: 1.8775 - val_accuracy: 0.5054 - val_loss: 1.5137\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4032 - loss: 1.6899 - val_accuracy: 0.5760 - val_loss: 1.2979\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4622 - loss: 1.5285 - val_accuracy: 0.6431 - val_loss: 1.1236\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5219 - loss: 1.3820 - val_accuracy: 0.6984 - val_loss: 0.9748\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5736 - loss: 1.2559 - val_accuracy: 0.7400 - val_loss: 0.8406\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6169 - loss: 1.1378 - val_accuracy: 0.7816 - val_loss: 0.7200\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6545 - loss: 1.0312 - val_accuracy: 0.8085 - val_loss: 0.6343\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6838 - loss: 0.9571 - val_accuracy: 0.8243 - val_loss: 0.5670\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7187 - loss: 0.8584 - val_accuracy: 0.8475 - val_loss: 0.5050\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7356 - loss: 0.8069 - val_accuracy: 0.8610 - val_loss: 0.4612\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7548 - loss: 0.7440 - val_accuracy: 0.8761 - val_loss: 0.4141\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7742 - loss: 0.6946 - val_accuracy: 0.8813 - val_loss: 0.3932\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7856 - loss: 0.6647 - val_accuracy: 0.8889 - val_loss: 0.3675\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1508 - loss: 2.6394 - val_accuracy: 0.1124 - val_loss: 4.6686\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2676 - loss: 2.0385 - val_accuracy: 0.3521 - val_loss: 1.8869\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3459 - loss: 1.8390 - val_accuracy: 0.5350 - val_loss: 1.4250\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4156 - loss: 1.6499 - val_accuracy: 0.6085 - val_loss: 1.2194\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4826 - loss: 1.4762 - val_accuracy: 0.6672 - val_loss: 1.0462\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5364 - loss: 1.3300 - val_accuracy: 0.7235 - val_loss: 0.8935\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5858 - loss: 1.1872 - val_accuracy: 0.7679 - val_loss: 0.7610\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6382 - loss: 1.0686 - val_accuracy: 0.7964 - val_loss: 0.6723\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6792 - loss: 0.9591 - val_accuracy: 0.8194 - val_loss: 0.5875\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7038 - loss: 0.8902 - val_accuracy: 0.8449 - val_loss: 0.5223\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7275 - loss: 0.8157 - val_accuracy: 0.8611 - val_loss: 0.4658\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7520 - loss: 0.7527 - val_accuracy: 0.8711 - val_loss: 0.4234\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7721 - loss: 0.7036 - val_accuracy: 0.8773 - val_loss: 0.4029\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7903 - loss: 0.6469 - val_accuracy: 0.8843 - val_loss: 0.3748\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8003 - loss: 0.6186 - val_accuracy: 0.8934 - val_loss: 0.3416\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1551 - loss: 2.6298 - val_accuracy: 0.1126 - val_loss: 4.9975\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2637 - loss: 2.0368 - val_accuracy: 0.3403 - val_loss: 1.9393\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3400 - loss: 1.8524 - val_accuracy: 0.5094 - val_loss: 1.4847\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3951 - loss: 1.7034 - val_accuracy: 0.5830 - val_loss: 1.2772\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4645 - loss: 1.5236 - val_accuracy: 0.6475 - val_loss: 1.1002\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5210 - loss: 1.3854 - val_accuracy: 0.6845 - val_loss: 0.9711\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5612 - loss: 1.2618 - val_accuracy: 0.7262 - val_loss: 0.8445\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6092 - loss: 1.1398 - val_accuracy: 0.7666 - val_loss: 0.7345\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6516 - loss: 1.0402 - val_accuracy: 0.7947 - val_loss: 0.6507\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6849 - loss: 0.9451 - val_accuracy: 0.8286 - val_loss: 0.5655\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7080 - loss: 0.8773 - val_accuracy: 0.8367 - val_loss: 0.5239\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7361 - loss: 0.8114 - val_accuracy: 0.8503 - val_loss: 0.4809\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7492 - loss: 0.7603 - val_accuracy: 0.8601 - val_loss: 0.4399\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7691 - loss: 0.7148 - val_accuracy: 0.8788 - val_loss: 0.3968\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7867 - loss: 0.6641 - val_accuracy: 0.8857 - val_loss: 0.3697\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0001}: 0.8861\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.2712 - loss: 2.2836 - val_accuracy: 0.1581 - val_loss: 4.9848\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6356 - loss: 1.0840 - val_accuracy: 0.7317 - val_loss: 0.7889\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7649 - loss: 0.7291 - val_accuracy: 0.8935 - val_loss: 0.3546\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8243 - loss: 0.5595 - val_accuracy: 0.9031 - val_loss: 0.3119\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8535 - loss: 0.4743 - val_accuracy: 0.9190 - val_loss: 0.2684\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8725 - loss: 0.4194 - val_accuracy: 0.9171 - val_loss: 0.2749\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8830 - loss: 0.3847 - val_accuracy: 0.9345 - val_loss: 0.2227\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8969 - loss: 0.3413 - val_accuracy: 0.9249 - val_loss: 0.2472\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9032 - loss: 0.3131 - val_accuracy: 0.9314 - val_loss: 0.2358\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9043 - loss: 0.3099 - val_accuracy: 0.9424 - val_loss: 0.2002\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9106 - loss: 0.2997 - val_accuracy: 0.9381 - val_loss: 0.2070\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9152 - loss: 0.2750 - val_accuracy: 0.9400 - val_loss: 0.2057\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9194 - loss: 0.2653 - val_accuracy: 0.9409 - val_loss: 0.2025\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.2425 - loss: 2.3221 - val_accuracy: 0.1171 - val_loss: 6.9094\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5927 - loss: 1.1815 - val_accuracy: 0.5244 - val_loss: 1.2830\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7483 - loss: 0.7775 - val_accuracy: 0.8606 - val_loss: 0.4351\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8049 - loss: 0.6240 - val_accuracy: 0.8834 - val_loss: 0.3835\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8408 - loss: 0.5130 - val_accuracy: 0.8879 - val_loss: 0.3631\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8640 - loss: 0.4358 - val_accuracy: 0.9064 - val_loss: 0.3102\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8746 - loss: 0.4104 - val_accuracy: 0.9225 - val_loss: 0.2534\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8905 - loss: 0.3637 - val_accuracy: 0.9259 - val_loss: 0.2584\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8919 - loss: 0.3529 - val_accuracy: 0.9257 - val_loss: 0.2542\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9013 - loss: 0.3241 - val_accuracy: 0.9328 - val_loss: 0.2456\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9019 - loss: 0.3231 - val_accuracy: 0.9398 - val_loss: 0.2176\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9093 - loss: 0.2965 - val_accuracy: 0.9336 - val_loss: 0.2243\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.2916 - val_accuracy: 0.9381 - val_loss: 0.2187\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.2745 - val_accuracy: 0.9434 - val_loss: 0.2018\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9174 - loss: 0.2714 - val_accuracy: 0.9291 - val_loss: 0.2383\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.2558 - loss: 2.3278 - val_accuracy: 0.1500 - val_loss: 4.5962\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6092 - loss: 1.1471 - val_accuracy: 0.6510 - val_loss: 0.9916\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7595 - loss: 0.7525 - val_accuracy: 0.8782 - val_loss: 0.4021\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 0.5925 - val_accuracy: 0.9034 - val_loss: 0.3151\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8521 - loss: 0.4831 - val_accuracy: 0.9232 - val_loss: 0.2612\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8718 - loss: 0.4176 - val_accuracy: 0.9304 - val_loss: 0.2403\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8823 - loss: 0.3837 - val_accuracy: 0.9262 - val_loss: 0.2507\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8904 - loss: 0.3538 - val_accuracy: 0.9343 - val_loss: 0.2177\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9014 - loss: 0.3261 - val_accuracy: 0.9400 - val_loss: 0.2085\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9058 - loss: 0.3147 - val_accuracy: 0.9357 - val_loss: 0.2214\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9091 - loss: 0.2921 - val_accuracy: 0.9402 - val_loss: 0.2108\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9151 - loss: 0.2780 - val_accuracy: 0.9416 - val_loss: 0.2040\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9206 - loss: 0.2656 - val_accuracy: 0.9379 - val_loss: 0.2172\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9200 - loss: 0.2624 - val_accuracy: 0.9411 - val_loss: 0.1999\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9259 - loss: 0.2529 - val_accuracy: 0.9422 - val_loss: 0.2004\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2399 - loss: 2.3585 - val_accuracy: 0.1140 - val_loss: 4.4611\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5870 - loss: 1.2212 - val_accuracy: 0.7189 - val_loss: 0.8165\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7386 - loss: 0.8144 - val_accuracy: 0.8810 - val_loss: 0.3998\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8035 - loss: 0.6290 - val_accuracy: 0.9045 - val_loss: 0.3218\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8411 - loss: 0.5174 - val_accuracy: 0.9206 - val_loss: 0.2710\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8598 - loss: 0.4554 - val_accuracy: 0.9229 - val_loss: 0.2570\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8736 - loss: 0.4101 - val_accuracy: 0.9245 - val_loss: 0.2656\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8862 - loss: 0.3684 - val_accuracy: 0.9316 - val_loss: 0.2311\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8948 - loss: 0.3514 - val_accuracy: 0.9380 - val_loss: 0.2108\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8963 - loss: 0.3387 - val_accuracy: 0.9398 - val_loss: 0.2002\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9031 - loss: 0.3232 - val_accuracy: 0.9419 - val_loss: 0.1987\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.3068 - val_accuracy: 0.9351 - val_loss: 0.2196\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9103 - loss: 0.2955 - val_accuracy: 0.9414 - val_loss: 0.1988\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9158 - loss: 0.2806 - val_accuracy: 0.9320 - val_loss: 0.2338\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.2469 - loss: 2.3321 - val_accuracy: 0.1256 - val_loss: 5.0055\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5911 - loss: 1.2031 - val_accuracy: 0.7386 - val_loss: 0.7957\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7456 - loss: 0.7996 - val_accuracy: 0.8743 - val_loss: 0.4144\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8102 - loss: 0.6022 - val_accuracy: 0.9071 - val_loss: 0.3041\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8414 - loss: 0.5093 - val_accuracy: 0.9051 - val_loss: 0.3277\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8596 - loss: 0.4569 - val_accuracy: 0.9239 - val_loss: 0.2605\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8790 - loss: 0.3996 - val_accuracy: 0.9261 - val_loss: 0.2476\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8885 - loss: 0.3679 - val_accuracy: 0.9294 - val_loss: 0.2444\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8976 - loss: 0.3397 - val_accuracy: 0.9325 - val_loss: 0.2456\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9040 - loss: 0.3134 - val_accuracy: 0.9367 - val_loss: 0.2133\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9063 - loss: 0.3055 - val_accuracy: 0.9374 - val_loss: 0.2123\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9103 - loss: 0.2950 - val_accuracy: 0.9400 - val_loss: 0.2137\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9179 - loss: 0.2732 - val_accuracy: 0.9425 - val_loss: 0.2250\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9218 - loss: 0.2546 - val_accuracy: 0.9442 - val_loss: 0.1936\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9237 - loss: 0.2557 - val_accuracy: 0.9460 - val_loss: 0.1859\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.3, 'learning_rate': 0.001}: 0.9432\n",
            "Best parameters for outer fold 4: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "Best inner validation accuracy: 0.9485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outer Fold 4 - Test Accuracy: 0.9537\n",
            "\n",
            "=== Outer Fold 5/5 ===\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2120 - loss: 2.3326 - val_accuracy: 0.4726 - val_loss: 1.5817\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4533 - loss: 1.5549 - val_accuracy: 0.6874 - val_loss: 0.9754\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5901 - loss: 1.1875 - val_accuracy: 0.7689 - val_loss: 0.7235\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6864 - loss: 0.9315 - val_accuracy: 0.8374 - val_loss: 0.5322\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7475 - loss: 0.7658 - val_accuracy: 0.8635 - val_loss: 0.4393\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.6397 - val_accuracy: 0.8852 - val_loss: 0.3753\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.5536 - val_accuracy: 0.8963 - val_loss: 0.3339\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8483 - loss: 0.4791 - val_accuracy: 0.9109 - val_loss: 0.2939\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 0.4385 - val_accuracy: 0.9144 - val_loss: 0.2796\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8744 - loss: 0.3970 - val_accuracy: 0.9234 - val_loss: 0.2547\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8837 - loss: 0.3674 - val_accuracy: 0.9275 - val_loss: 0.2420\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8915 - loss: 0.3372 - val_accuracy: 0.9291 - val_loss: 0.2319\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9030 - loss: 0.3053 - val_accuracy: 0.9315 - val_loss: 0.2290\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9030 - loss: 0.3007 - val_accuracy: 0.9364 - val_loss: 0.2085\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9107 - loss: 0.2811 - val_accuracy: 0.9372 - val_loss: 0.2091\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2032 - loss: 2.3349 - val_accuracy: 0.4143 - val_loss: 1.6945\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4353 - loss: 1.6095 - val_accuracy: 0.6842 - val_loss: 1.0138\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5728 - loss: 1.2426 - val_accuracy: 0.7798 - val_loss: 0.7088\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6703 - loss: 0.9854 - val_accuracy: 0.8282 - val_loss: 0.5460\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7414 - loss: 0.7876 - val_accuracy: 0.8617 - val_loss: 0.4504\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.6704 - val_accuracy: 0.8849 - val_loss: 0.3708\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8166 - loss: 0.5661 - val_accuracy: 0.8961 - val_loss: 0.3354\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 0.5091 - val_accuracy: 0.9034 - val_loss: 0.3083\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 0.4619 - val_accuracy: 0.9102 - val_loss: 0.2838\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.4118 - val_accuracy: 0.9174 - val_loss: 0.2668\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8805 - loss: 0.3800 - val_accuracy: 0.9223 - val_loss: 0.2517\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8896 - loss: 0.3542 - val_accuracy: 0.9282 - val_loss: 0.2309\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8996 - loss: 0.3135 - val_accuracy: 0.9324 - val_loss: 0.2178\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9020 - loss: 0.3091 - val_accuracy: 0.9364 - val_loss: 0.2094\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9071 - loss: 0.2873 - val_accuracy: 0.9326 - val_loss: 0.2182\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2254 - loss: 2.2921 - val_accuracy: 0.4066 - val_loss: 1.7218\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4490 - loss: 1.5722 - val_accuracy: 0.6692 - val_loss: 1.0343\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 1.2082 - val_accuracy: 0.7743 - val_loss: 0.7333\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6793 - loss: 0.9485 - val_accuracy: 0.8292 - val_loss: 0.5641\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7434 - loss: 0.7741 - val_accuracy: 0.8523 - val_loss: 0.4749\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7867 - loss: 0.6550 - val_accuracy: 0.8741 - val_loss: 0.4109\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8164 - loss: 0.5702 - val_accuracy: 0.8923 - val_loss: 0.3590\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 0.5098 - val_accuracy: 0.8958 - val_loss: 0.3351\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.4396 - val_accuracy: 0.9070 - val_loss: 0.3065\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8661 - loss: 0.4179 - val_accuracy: 0.9162 - val_loss: 0.2836\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8794 - loss: 0.3751 - val_accuracy: 0.9192 - val_loss: 0.2722\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8917 - loss: 0.3465 - val_accuracy: 0.9211 - val_loss: 0.2643\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8937 - loss: 0.3362 - val_accuracy: 0.9264 - val_loss: 0.2494\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.3078 - val_accuracy: 0.9276 - val_loss: 0.2476\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 0.2797 - val_accuracy: 0.9328 - val_loss: 0.2366\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2152 - loss: 2.2991 - val_accuracy: 0.4301 - val_loss: 1.6805\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4481 - loss: 1.5735 - val_accuracy: 0.6839 - val_loss: 1.0221\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5800 - loss: 1.2304 - val_accuracy: 0.7771 - val_loss: 0.7343\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6797 - loss: 0.9604 - val_accuracy: 0.8236 - val_loss: 0.5765\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7443 - loss: 0.7834 - val_accuracy: 0.8551 - val_loss: 0.4673\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.6673 - val_accuracy: 0.8794 - val_loss: 0.3922\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.5749 - val_accuracy: 0.8922 - val_loss: 0.3505\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8401 - loss: 0.4955 - val_accuracy: 0.8998 - val_loss: 0.3241\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8587 - loss: 0.4410 - val_accuracy: 0.9093 - val_loss: 0.2950\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.4130 - val_accuracy: 0.9178 - val_loss: 0.2723\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8801 - loss: 0.3739 - val_accuracy: 0.9229 - val_loss: 0.2597\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8897 - loss: 0.3484 - val_accuracy: 0.9253 - val_loss: 0.2515\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8956 - loss: 0.3226 - val_accuracy: 0.9326 - val_loss: 0.2311\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9007 - loss: 0.3145 - val_accuracy: 0.9318 - val_loss: 0.2286\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9106 - loss: 0.2816 - val_accuracy: 0.9399 - val_loss: 0.2087\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2207 - loss: 2.3146 - val_accuracy: 0.4391 - val_loss: 1.6517\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4558 - loss: 1.5622 - val_accuracy: 0.6978 - val_loss: 0.9603\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5989 - loss: 1.1680 - val_accuracy: 0.7853 - val_loss: 0.6861\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6935 - loss: 0.9136 - val_accuracy: 0.8316 - val_loss: 0.5360\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7583 - loss: 0.7347 - val_accuracy: 0.8623 - val_loss: 0.4444\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.6073 - val_accuracy: 0.8816 - val_loss: 0.3795\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8313 - loss: 0.5384 - val_accuracy: 0.8939 - val_loss: 0.3405\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8485 - loss: 0.4687 - val_accuracy: 0.9059 - val_loss: 0.3035\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8675 - loss: 0.4198 - val_accuracy: 0.9179 - val_loss: 0.2760\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.3862 - val_accuracy: 0.9214 - val_loss: 0.2620\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.3544 - val_accuracy: 0.9221 - val_loss: 0.2548\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8929 - loss: 0.3422 - val_accuracy: 0.9226 - val_loss: 0.2500\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9025 - loss: 0.3028 - val_accuracy: 0.9281 - val_loss: 0.2352\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9106 - loss: 0.2859 - val_accuracy: 0.9261 - val_loss: 0.2458\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9151 - loss: 0.2681 - val_accuracy: 0.9332 - val_loss: 0.2250\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9359\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3719 - loss: 1.8817 - val_accuracy: 0.7531 - val_loss: 0.7708\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7886 - loss: 0.6669 - val_accuracy: 0.8917 - val_loss: 0.3592\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8602 - loss: 0.4670 - val_accuracy: 0.8995 - val_loss: 0.3591\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8863 - loss: 0.3706 - val_accuracy: 0.9187 - val_loss: 0.2751\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9020 - loss: 0.3367 - val_accuracy: 0.9224 - val_loss: 0.2817\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.2978 - val_accuracy: 0.9300 - val_loss: 0.2550\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9175 - loss: 0.2877 - val_accuracy: 0.9229 - val_loss: 0.2706\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2726 - val_accuracy: 0.9293 - val_loss: 0.2456\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9287 - loss: 0.2556 - val_accuracy: 0.9366 - val_loss: 0.2525\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9329 - loss: 0.2359 - val_accuracy: 0.9296 - val_loss: 0.2493\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.2399 - val_accuracy: 0.9309 - val_loss: 0.2529\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9390 - loss: 0.2142 - val_accuracy: 0.9187 - val_loss: 0.2973\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3668 - loss: 1.9146 - val_accuracy: 0.6593 - val_loss: 0.9757\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7855 - loss: 0.6789 - val_accuracy: 0.8881 - val_loss: 0.3724\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.4579 - val_accuracy: 0.9114 - val_loss: 0.3150\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8921 - loss: 0.3672 - val_accuracy: 0.9151 - val_loss: 0.2885\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9036 - loss: 0.3230 - val_accuracy: 0.9336 - val_loss: 0.2300\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 0.2800 - val_accuracy: 0.9335 - val_loss: 0.2309\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9192 - loss: 0.2770 - val_accuracy: 0.9285 - val_loss: 0.2486\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9229 - loss: 0.2608 - val_accuracy: 0.9311 - val_loss: 0.2349\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3637 - loss: 1.9483 - val_accuracy: 0.6538 - val_loss: 1.0369\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7925 - loss: 0.6674 - val_accuracy: 0.9044 - val_loss: 0.3168\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8558 - loss: 0.4585 - val_accuracy: 0.9187 - val_loss: 0.2830\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8911 - loss: 0.3596 - val_accuracy: 0.9252 - val_loss: 0.2720\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9042 - loss: 0.3244 - val_accuracy: 0.9156 - val_loss: 0.3052\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.2940 - val_accuracy: 0.9346 - val_loss: 0.2384\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9198 - loss: 0.2763 - val_accuracy: 0.9272 - val_loss: 0.2730\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.2679 - val_accuracy: 0.9391 - val_loss: 0.2129\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9292 - loss: 0.2545 - val_accuracy: 0.9182 - val_loss: 0.2910\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.2346 - val_accuracy: 0.9383 - val_loss: 0.2376\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.2251 - val_accuracy: 0.9370 - val_loss: 0.2223\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3832 - loss: 1.9121 - val_accuracy: 0.6753 - val_loss: 1.0061\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.6422 - val_accuracy: 0.8964 - val_loss: 0.3432\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8662 - loss: 0.4492 - val_accuracy: 0.8988 - val_loss: 0.3511\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8916 - loss: 0.3536 - val_accuracy: 0.9137 - val_loss: 0.2989\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.3287 - val_accuracy: 0.9266 - val_loss: 0.2569\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9166 - loss: 0.2903 - val_accuracy: 0.9199 - val_loss: 0.2759\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2919 - val_accuracy: 0.9389 - val_loss: 0.2284\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9239 - loss: 0.2690 - val_accuracy: 0.9385 - val_loss: 0.2291\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.2618 - val_accuracy: 0.9370 - val_loss: 0.2344\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9324 - loss: 0.2411 - val_accuracy: 0.9369 - val_loss: 0.2642\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3752 - loss: 1.9117 - val_accuracy: 0.7803 - val_loss: 0.7061\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7923 - loss: 0.6661 - val_accuracy: 0.9020 - val_loss: 0.3177\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8595 - loss: 0.4600 - val_accuracy: 0.9231 - val_loss: 0.2530\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.3627 - val_accuracy: 0.9297 - val_loss: 0.2391\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.3253 - val_accuracy: 0.9366 - val_loss: 0.2301\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.3021 - val_accuracy: 0.9355 - val_loss: 0.2283\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2692 - val_accuracy: 0.9377 - val_loss: 0.2340\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.2503 - val_accuracy: 0.9419 - val_loss: 0.2180\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9284 - loss: 0.2471 - val_accuracy: 0.9380 - val_loss: 0.2158\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.2387 - val_accuracy: 0.9442 - val_loss: 0.2026\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9344 - loss: 0.2281 - val_accuracy: 0.9248 - val_loss: 0.2749\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9371 - loss: 0.2216 - val_accuracy: 0.9498 - val_loss: 0.1972\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.2087 - val_accuracy: 0.9315 - val_loss: 0.2454\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.2120 - val_accuracy: 0.9371 - val_loss: 0.2354\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9414 - loss: 0.2083 - val_accuracy: 0.9380 - val_loss: 0.2130\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001}: 0.9396\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1589 - loss: 2.5830 - val_accuracy: 0.3118 - val_loss: 1.9750\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3019 - loss: 1.9489 - val_accuracy: 0.4931 - val_loss: 1.5155\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3935 - loss: 1.7103 - val_accuracy: 0.5970 - val_loss: 1.2511\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4667 - loss: 1.5101 - val_accuracy: 0.6730 - val_loss: 1.0363\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5363 - loss: 1.3337 - val_accuracy: 0.7186 - val_loss: 0.8632\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6013 - loss: 1.1700 - val_accuracy: 0.7670 - val_loss: 0.7406\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6549 - loss: 1.0342 - val_accuracy: 0.8070 - val_loss: 0.6132\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6907 - loss: 0.9293 - val_accuracy: 0.8273 - val_loss: 0.5468\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7245 - loss: 0.8319 - val_accuracy: 0.8511 - val_loss: 0.4659\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7512 - loss: 0.7612 - val_accuracy: 0.8656 - val_loss: 0.4287\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7803 - loss: 0.6805 - val_accuracy: 0.8748 - val_loss: 0.3972\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7909 - loss: 0.6495 - val_accuracy: 0.8882 - val_loss: 0.3543\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.6059 - val_accuracy: 0.8932 - val_loss: 0.3355\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.5636 - val_accuracy: 0.9024 - val_loss: 0.3149\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8302 - loss: 0.5388 - val_accuracy: 0.9051 - val_loss: 0.3034\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1616 - loss: 2.5825 - val_accuracy: 0.2454 - val_loss: 2.2330\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3064 - loss: 1.9456 - val_accuracy: 0.4876 - val_loss: 1.5102\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3976 - loss: 1.6950 - val_accuracy: 0.6032 - val_loss: 1.1998\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4957 - loss: 1.4535 - val_accuracy: 0.6773 - val_loss: 1.0015\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5663 - loss: 1.2581 - val_accuracy: 0.7473 - val_loss: 0.8185\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6334 - loss: 1.0872 - val_accuracy: 0.7923 - val_loss: 0.6706\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6751 - loss: 0.9722 - val_accuracy: 0.8263 - val_loss: 0.5745\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7144 - loss: 0.8740 - val_accuracy: 0.8439 - val_loss: 0.5214\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7425 - loss: 0.7894 - val_accuracy: 0.8641 - val_loss: 0.4547\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7665 - loss: 0.7172 - val_accuracy: 0.8753 - val_loss: 0.4237\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7858 - loss: 0.6618 - val_accuracy: 0.8859 - val_loss: 0.3945\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.6094 - val_accuracy: 0.8923 - val_loss: 0.3589\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 0.5752 - val_accuracy: 0.8972 - val_loss: 0.3433\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8290 - loss: 0.5379 - val_accuracy: 0.9045 - val_loss: 0.3253\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8428 - loss: 0.5061 - val_accuracy: 0.9073 - val_loss: 0.3108\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.1590 - loss: 2.5596 - val_accuracy: 0.3284 - val_loss: 1.9087\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3036 - loss: 1.9371 - val_accuracy: 0.5044 - val_loss: 1.4686\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4005 - loss: 1.6796 - val_accuracy: 0.5973 - val_loss: 1.2258\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4847 - loss: 1.4666 - val_accuracy: 0.6798 - val_loss: 0.9983\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5635 - loss: 1.2563 - val_accuracy: 0.7355 - val_loss: 0.8230\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6201 - loss: 1.1205 - val_accuracy: 0.7747 - val_loss: 0.7019\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6644 - loss: 0.9873 - val_accuracy: 0.8119 - val_loss: 0.5968\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7121 - loss: 0.8766 - val_accuracy: 0.8451 - val_loss: 0.5063\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7377 - loss: 0.8080 - val_accuracy: 0.8564 - val_loss: 0.4580\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7598 - loss: 0.7388 - val_accuracy: 0.8702 - val_loss: 0.4166\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.6703 - val_accuracy: 0.8865 - val_loss: 0.3748\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7970 - loss: 0.6342 - val_accuracy: 0.8955 - val_loss: 0.3472\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8139 - loss: 0.5849 - val_accuracy: 0.8986 - val_loss: 0.3340\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.5513 - val_accuracy: 0.9059 - val_loss: 0.3109\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8384 - loss: 0.5180 - val_accuracy: 0.9097 - val_loss: 0.2966\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1566 - loss: 2.5999 - val_accuracy: 0.2451 - val_loss: 2.1475\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3084 - loss: 1.9384 - val_accuracy: 0.5057 - val_loss: 1.4942\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4085 - loss: 1.6753 - val_accuracy: 0.6201 - val_loss: 1.1907\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4927 - loss: 1.4385 - val_accuracy: 0.7018 - val_loss: 0.9705\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5735 - loss: 1.2436 - val_accuracy: 0.7594 - val_loss: 0.7931\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6308 - loss: 1.0849 - val_accuracy: 0.8011 - val_loss: 0.6520\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6807 - loss: 0.9568 - val_accuracy: 0.8230 - val_loss: 0.5723\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 0.8612 - val_accuracy: 0.8455 - val_loss: 0.4947\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7469 - loss: 0.7754 - val_accuracy: 0.8683 - val_loss: 0.4260\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7783 - loss: 0.6982 - val_accuracy: 0.8808 - val_loss: 0.3878\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7882 - loss: 0.6545 - val_accuracy: 0.8841 - val_loss: 0.3706\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.5912 - val_accuracy: 0.8939 - val_loss: 0.3478\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8200 - loss: 0.5614 - val_accuracy: 0.9078 - val_loss: 0.3069\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8327 - loss: 0.5273 - val_accuracy: 0.9059 - val_loss: 0.3116\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8450 - loss: 0.5010 - val_accuracy: 0.9102 - val_loss: 0.2975\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1667 - loss: 2.5710 - val_accuracy: 0.3179 - val_loss: 1.9241\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3072 - loss: 1.9289 - val_accuracy: 0.5166 - val_loss: 1.4936\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4013 - loss: 1.6808 - val_accuracy: 0.6025 - val_loss: 1.2313\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4772 - loss: 1.4989 - val_accuracy: 0.6773 - val_loss: 1.0269\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5535 - loss: 1.2905 - val_accuracy: 0.7321 - val_loss: 0.8558\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6103 - loss: 1.1442 - val_accuracy: 0.7757 - val_loss: 0.7090\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6646 - loss: 1.0125 - val_accuracy: 0.8068 - val_loss: 0.6143\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6972 - loss: 0.9168 - val_accuracy: 0.8301 - val_loss: 0.5441\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7339 - loss: 0.8298 - val_accuracy: 0.8554 - val_loss: 0.4694\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7614 - loss: 0.7434 - val_accuracy: 0.8628 - val_loss: 0.4446\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.6723 - val_accuracy: 0.8739 - val_loss: 0.4051\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 0.6450 - val_accuracy: 0.8835 - val_loss: 0.3777\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8161 - loss: 0.5821 - val_accuracy: 0.8894 - val_loss: 0.3595\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.5482 - val_accuracy: 0.8972 - val_loss: 0.3357\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 0.5172 - val_accuracy: 0.9052 - val_loss: 0.3169\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001}: 0.9075\n",
            "\n",
            "Testing parameters: {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2652 - loss: 2.2312 - val_accuracy: 0.6360 - val_loss: 1.0848\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6438 - loss: 1.0758 - val_accuracy: 0.8467 - val_loss: 0.5149\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7801 - loss: 0.7116 - val_accuracy: 0.8885 - val_loss: 0.3712\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8222 - loss: 0.5916 - val_accuracy: 0.9038 - val_loss: 0.3255\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.5059 - val_accuracy: 0.9090 - val_loss: 0.2996\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8631 - loss: 0.4603 - val_accuracy: 0.9239 - val_loss: 0.2595\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8698 - loss: 0.4365 - val_accuracy: 0.9039 - val_loss: 0.2934\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8802 - loss: 0.4120 - val_accuracy: 0.9085 - val_loss: 0.3010\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8845 - loss: 0.3943 - val_accuracy: 0.9276 - val_loss: 0.2615\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8874 - loss: 0.3786 - val_accuracy: 0.9320 - val_loss: 0.2477\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8936 - loss: 0.3603 - val_accuracy: 0.9222 - val_loss: 0.2744\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8945 - loss: 0.3624 - val_accuracy: 0.9358 - val_loss: 0.2507\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8988 - loss: 0.3485 - val_accuracy: 0.9231 - val_loss: 0.2907\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.3318 - val_accuracy: 0.9306 - val_loss: 0.2448\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.3373 - val_accuracy: 0.9358 - val_loss: 0.2225\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2624 - loss: 2.2726 - val_accuracy: 0.6091 - val_loss: 1.1695\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6437 - loss: 1.0757 - val_accuracy: 0.7591 - val_loss: 0.7129\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7702 - loss: 0.7496 - val_accuracy: 0.8881 - val_loss: 0.3664\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.5977 - val_accuracy: 0.9038 - val_loss: 0.3359\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8437 - loss: 0.5164 - val_accuracy: 0.9026 - val_loss: 0.3278\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 0.4713 - val_accuracy: 0.8974 - val_loss: 0.3335\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8734 - loss: 0.4253 - val_accuracy: 0.9164 - val_loss: 0.2941\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8804 - loss: 0.4055 - val_accuracy: 0.9236 - val_loss: 0.2638\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8852 - loss: 0.3926 - val_accuracy: 0.9208 - val_loss: 0.2736\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8890 - loss: 0.3778 - val_accuracy: 0.9279 - val_loss: 0.2536\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8895 - loss: 0.3739 - val_accuracy: 0.9210 - val_loss: 0.2935\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.3659 - val_accuracy: 0.9151 - val_loss: 0.3064\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8976 - loss: 0.3530 - val_accuracy: 0.9159 - val_loss: 0.2926\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2745 - loss: 2.1917 - val_accuracy: 0.6782 - val_loss: 1.0424\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6570 - loss: 1.0423 - val_accuracy: 0.8624 - val_loss: 0.4692\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7778 - loss: 0.7132 - val_accuracy: 0.8770 - val_loss: 0.4195\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8245 - loss: 0.5814 - val_accuracy: 0.8955 - val_loss: 0.3438\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8470 - loss: 0.5067 - val_accuracy: 0.9166 - val_loss: 0.2923\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8628 - loss: 0.4670 - val_accuracy: 0.9159 - val_loss: 0.3063\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8788 - loss: 0.4223 - val_accuracy: 0.9174 - val_loss: 0.2827\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8794 - loss: 0.4121 - val_accuracy: 0.9303 - val_loss: 0.2594\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8843 - loss: 0.3992 - val_accuracy: 0.9179 - val_loss: 0.3007\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.3641 - val_accuracy: 0.9291 - val_loss: 0.2603\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8958 - loss: 0.3617 - val_accuracy: 0.9330 - val_loss: 0.2431\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8970 - loss: 0.3547 - val_accuracy: 0.9245 - val_loss: 0.2863\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.3483 - val_accuracy: 0.9346 - val_loss: 0.2465\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9015 - loss: 0.3368 - val_accuracy: 0.9326 - val_loss: 0.2435\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.3275 - val_accuracy: 0.9030 - val_loss: 0.3519\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2839 - loss: 2.1325 - val_accuracy: 0.6575 - val_loss: 1.0115\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6680 - loss: 1.0097 - val_accuracy: 0.8542 - val_loss: 0.4771\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7829 - loss: 0.6899 - val_accuracy: 0.8964 - val_loss: 0.3566\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8307 - loss: 0.5475 - val_accuracy: 0.9074 - val_loss: 0.3140\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8549 - loss: 0.4810 - val_accuracy: 0.9207 - val_loss: 0.2720\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8712 - loss: 0.4336 - val_accuracy: 0.9294 - val_loss: 0.2504\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8788 - loss: 0.4245 - val_accuracy: 0.9224 - val_loss: 0.2639\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8840 - loss: 0.3901 - val_accuracy: 0.9292 - val_loss: 0.2401\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.3760 - val_accuracy: 0.9212 - val_loss: 0.2851\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2658 - loss: 2.1834 - val_accuracy: 0.5646 - val_loss: 1.2405\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6425 - loss: 1.0756 - val_accuracy: 0.8003 - val_loss: 0.6107\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7703 - loss: 0.7309 - val_accuracy: 0.8753 - val_loss: 0.4058\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.5968 - val_accuracy: 0.8998 - val_loss: 0.3329\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8455 - loss: 0.5169 - val_accuracy: 0.9116 - val_loss: 0.2902\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.4685 - val_accuracy: 0.9162 - val_loss: 0.2819\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8673 - loss: 0.4447 - val_accuracy: 0.9225 - val_loss: 0.2773\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.4141 - val_accuracy: 0.9166 - val_loss: 0.2839\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3974 - val_accuracy: 0.9174 - val_loss: 0.2785\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8877 - loss: 0.3811 - val_accuracy: 0.9248 - val_loss: 0.2583\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8929 - loss: 0.3652 - val_accuracy: 0.9250 - val_loss: 0.2576\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8934 - loss: 0.3588 - val_accuracy: 0.9141 - val_loss: 0.2889\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8976 - loss: 0.3466 - val_accuracy: 0.9196 - val_loss: 0.2891\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.3296 - val_accuracy: 0.9325 - val_loss: 0.2353\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9064 - loss: 0.3271 - val_accuracy: 0.9301 - val_loss: 0.2471\n",
            "Mean validation accuracy for {'batch_size': 64, 'dropout_rate': 0.3, 'learning_rate': 0.001}: 0.9320\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.1972 - loss: 2.3413 - val_accuracy: 0.1124 - val_loss: 4.0362\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3841 - loss: 1.7450 - val_accuracy: 0.5236 - val_loss: 1.4479\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4971 - loss: 1.4320 - val_accuracy: 0.6853 - val_loss: 1.0058\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5934 - loss: 1.1813 - val_accuracy: 0.7521 - val_loss: 0.8003\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6636 - loss: 0.9938 - val_accuracy: 0.8005 - val_loss: 0.6442\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7106 - loss: 0.8546 - val_accuracy: 0.8379 - val_loss: 0.5297\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7608 - loss: 0.7317 - val_accuracy: 0.8614 - val_loss: 0.4613\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7873 - loss: 0.6429 - val_accuracy: 0.8744 - val_loss: 0.4083\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8149 - loss: 0.5699 - val_accuracy: 0.8855 - val_loss: 0.3724\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8343 - loss: 0.5165 - val_accuracy: 0.8951 - val_loss: 0.3423\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8440 - loss: 0.4791 - val_accuracy: 0.9045 - val_loss: 0.3171\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8549 - loss: 0.4482 - val_accuracy: 0.9097 - val_loss: 0.2968\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8705 - loss: 0.4002 - val_accuracy: 0.9116 - val_loss: 0.2825\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8746 - loss: 0.3824 - val_accuracy: 0.9181 - val_loss: 0.2643\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8854 - loss: 0.3546 - val_accuracy: 0.9223 - val_loss: 0.2517\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.1982 - loss: 2.3984 - val_accuracy: 0.1124 - val_loss: 3.5361\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3715 - loss: 1.7638 - val_accuracy: 0.5272 - val_loss: 1.4404\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4996 - loss: 1.4290 - val_accuracy: 0.7038 - val_loss: 0.9683\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5863 - loss: 1.1943 - val_accuracy: 0.7696 - val_loss: 0.7514\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6648 - loss: 0.9930 - val_accuracy: 0.8123 - val_loss: 0.6031\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7182 - loss: 0.8419 - val_accuracy: 0.8440 - val_loss: 0.5074\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7622 - loss: 0.7276 - val_accuracy: 0.8693 - val_loss: 0.4251\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7931 - loss: 0.6406 - val_accuracy: 0.8830 - val_loss: 0.3759\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8144 - loss: 0.5718 - val_accuracy: 0.8939 - val_loss: 0.3388\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8293 - loss: 0.5257 - val_accuracy: 0.9008 - val_loss: 0.3148\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8480 - loss: 0.4772 - val_accuracy: 0.9081 - val_loss: 0.2877\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8557 - loss: 0.4507 - val_accuracy: 0.9178 - val_loss: 0.2676\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8692 - loss: 0.4105 - val_accuracy: 0.9206 - val_loss: 0.2558\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8878 - loss: 0.3594 - val_accuracy: 0.9225 - val_loss: 0.2427\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8872 - loss: 0.3559 - val_accuracy: 0.9231 - val_loss: 0.2393\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.1836 - loss: 2.4197 - val_accuracy: 0.1135 - val_loss: 3.5795\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3713 - loss: 1.7748 - val_accuracy: 0.5138 - val_loss: 1.4665\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4828 - loss: 1.4795 - val_accuracy: 0.6720 - val_loss: 1.0480\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5771 - loss: 1.2268 - val_accuracy: 0.7521 - val_loss: 0.8077\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6417 - loss: 1.0579 - val_accuracy: 0.7925 - val_loss: 0.6644\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7027 - loss: 0.8986 - val_accuracy: 0.8347 - val_loss: 0.5445\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7462 - loss: 0.7729 - val_accuracy: 0.8585 - val_loss: 0.4801\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7837 - loss: 0.6684 - val_accuracy: 0.8758 - val_loss: 0.4132\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8071 - loss: 0.6066 - val_accuracy: 0.8833 - val_loss: 0.3760\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8287 - loss: 0.5346 - val_accuracy: 0.9010 - val_loss: 0.3243\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8473 - loss: 0.4790 - val_accuracy: 0.9089 - val_loss: 0.2958\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8555 - loss: 0.4551 - val_accuracy: 0.9126 - val_loss: 0.2871\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8642 - loss: 0.4195 - val_accuracy: 0.9172 - val_loss: 0.2724\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8769 - loss: 0.3860 - val_accuracy: 0.9233 - val_loss: 0.2548\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8798 - loss: 0.3665 - val_accuracy: 0.9250 - val_loss: 0.2442\n",
            "-- Inner fold: 4/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1900 - loss: 2.3961 - val_accuracy: 0.1123 - val_loss: 4.6929\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3722 - loss: 1.7789 - val_accuracy: 0.5063 - val_loss: 1.4733\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4938 - loss: 1.4495 - val_accuracy: 0.6864 - val_loss: 0.9889\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5817 - loss: 1.2104 - val_accuracy: 0.7591 - val_loss: 0.7724\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6581 - loss: 1.0187 - val_accuracy: 0.7986 - val_loss: 0.6329\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7097 - loss: 0.8731 - val_accuracy: 0.8325 - val_loss: 0.5346\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7533 - loss: 0.7461 - val_accuracy: 0.8633 - val_loss: 0.4478\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7813 - loss: 0.6682 - val_accuracy: 0.8748 - val_loss: 0.4002\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8043 - loss: 0.5959 - val_accuracy: 0.8874 - val_loss: 0.3593\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8255 - loss: 0.5334 - val_accuracy: 0.8970 - val_loss: 0.3268\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8437 - loss: 0.4880 - val_accuracy: 0.9079 - val_loss: 0.2968\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8544 - loss: 0.4498 - val_accuracy: 0.9102 - val_loss: 0.2872\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.4122 - val_accuracy: 0.9158 - val_loss: 0.2696\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8730 - loss: 0.3981 - val_accuracy: 0.9200 - val_loss: 0.2627\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8828 - loss: 0.3573 - val_accuracy: 0.9205 - val_loss: 0.2517\n",
            "-- Inner fold: 5/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1903 - loss: 2.4156 - val_accuracy: 0.1124 - val_loss: 3.8808\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3925 - loss: 1.7342 - val_accuracy: 0.5317 - val_loss: 1.4375\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5195 - loss: 1.3888 - val_accuracy: 0.7134 - val_loss: 0.9198\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6047 - loss: 1.1454 - val_accuracy: 0.7757 - val_loss: 0.7232\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6807 - loss: 0.9544 - val_accuracy: 0.8201 - val_loss: 0.5939\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7273 - loss: 0.8204 - val_accuracy: 0.8478 - val_loss: 0.4952\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7688 - loss: 0.6957 - val_accuracy: 0.8673 - val_loss: 0.4310\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7938 - loss: 0.6405 - val_accuracy: 0.8781 - val_loss: 0.3855\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8179 - loss: 0.5687 - val_accuracy: 0.8885 - val_loss: 0.3515\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8314 - loss: 0.5166 - val_accuracy: 0.8981 - val_loss: 0.3225\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8465 - loss: 0.4763 - val_accuracy: 0.9053 - val_loss: 0.3012\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8613 - loss: 0.4396 - val_accuracy: 0.9112 - val_loss: 0.2781\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8665 - loss: 0.4203 - val_accuracy: 0.9162 - val_loss: 0.2709\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8754 - loss: 0.3895 - val_accuracy: 0.9194 - val_loss: 0.2550\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8860 - loss: 0.3534 - val_accuracy: 0.9184 - val_loss: 0.2526\n",
            "Mean validation accuracy for {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001}: 0.9221\n",
            "\n",
            "Testing parameters: {'batch_size': 128, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-- Inner fold: 1/5  --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.3336 - loss: 2.1036 - val_accuracy: 0.2834 - val_loss: 3.5494\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7569 - loss: 0.7451 - val_accuracy: 0.8144 - val_loss: 0.5787\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8548 - loss: 0.4712 - val_accuracy: 0.9118 - val_loss: 0.2957\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8869 - loss: 0.3588 - val_accuracy: 0.9243 - val_loss: 0.2576\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9066 - loss: 0.2972 - val_accuracy: 0.9392 - val_loss: 0.1996\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9197 - loss: 0.2602 - val_accuracy: 0.9392 - val_loss: 0.2090\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.2307 - val_accuracy: 0.9408 - val_loss: 0.1979\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9350 - loss: 0.2118 - val_accuracy: 0.9431 - val_loss: 0.2153\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9417 - loss: 0.1887 - val_accuracy: 0.9408 - val_loss: 0.2329\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9458 - loss: 0.1755 - val_accuracy: 0.9415 - val_loss: 0.2053\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9501 - loss: 0.1582 - val_accuracy: 0.9502 - val_loss: 0.1872\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9501 - loss: 0.1631 - val_accuracy: 0.9466 - val_loss: 0.2046\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9549 - loss: 0.1520 - val_accuracy: 0.9460 - val_loss: 0.1892\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.1497 - val_accuracy: 0.9508 - val_loss: 0.1962\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9604 - loss: 0.1326 - val_accuracy: 0.9457 - val_loss: 0.1941\n",
            "-- Inner fold: 2/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.3377 - loss: 2.0618 - val_accuracy: 0.1153 - val_loss: 9.2551\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7723 - loss: 0.7128 - val_accuracy: 0.7579 - val_loss: 0.7246\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8543 - loss: 0.4625 - val_accuracy: 0.9090 - val_loss: 0.2985\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8884 - loss: 0.3602 - val_accuracy: 0.9089 - val_loss: 0.3446\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9083 - loss: 0.2958 - val_accuracy: 0.9314 - val_loss: 0.2256\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9207 - loss: 0.2581 - val_accuracy: 0.9373 - val_loss: 0.2227\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9296 - loss: 0.2273 - val_accuracy: 0.9375 - val_loss: 0.2051\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9333 - loss: 0.2176 - val_accuracy: 0.9456 - val_loss: 0.2120\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9412 - loss: 0.1892 - val_accuracy: 0.9379 - val_loss: 0.2529\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9483 - loss: 0.1701 - val_accuracy: 0.9468 - val_loss: 0.1932\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9466 - loss: 0.1699 - val_accuracy: 0.9479 - val_loss: 0.2048\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.1508 - val_accuracy: 0.9481 - val_loss: 0.1904\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.1491 - val_accuracy: 0.9456 - val_loss: 0.2037\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.1407 - val_accuracy: 0.9468 - val_loss: 0.1984\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9579 - loss: 0.1414 - val_accuracy: 0.9517 - val_loss: 0.2244\n",
            "-- Inner fold: 3/5  --\n",
            "Epoch 1/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.3453 - loss: 2.0249 - val_accuracy: 0.2075 - val_loss: 4.9976\n",
            "Epoch 2/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7667 - loss: 0.7118 - val_accuracy: 0.7898 - val_loss: 0.6232\n",
            "Epoch 3/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8495 - loss: 0.4690 - val_accuracy: 0.9184 - val_loss: 0.2624\n",
            "Epoch 4/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8910 - loss: 0.3597 - val_accuracy: 0.9220 - val_loss: 0.2529\n",
            "Epoch 5/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9088 - loss: 0.2923 - val_accuracy: 0.9348 - val_loss: 0.2299\n",
            "Epoch 6/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.2666 - val_accuracy: 0.9399 - val_loss: 0.2023\n",
            "Epoch 7/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9320 - loss: 0.2211 - val_accuracy: 0.9373 - val_loss: 0.2228\n",
            "Epoch 8/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9369 - loss: 0.2071 - val_accuracy: 0.9448 - val_loss: 0.2121\n",
            "Epoch 9/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 0.1919 - val_accuracy: 0.9300 - val_loss: 0.2524\n",
            "Epoch 10/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.1813 - val_accuracy: 0.9492 - val_loss: 0.1877\n",
            "Epoch 11/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.1599 - val_accuracy: 0.9444 - val_loss: 0.2020\n",
            "Epoch 12/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9521 - loss: 0.1564 - val_accuracy: 0.9480 - val_loss: 0.1919\n",
            "Epoch 13/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9542 - loss: 0.1492 - val_accuracy: 0.9509 - val_loss: 0.1819\n",
            "Epoch 14/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9561 - loss: 0.1419 - val_accuracy: 0.9319 - val_loss: 0.2361\n",
            "Epoch 15/15\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9599 - loss: 0.1307 - val_accuracy: 0.9505 - val_loss: 0.1867\n",
            "-- Inner fold: 4/5  --\n"
          ]
        }
      ],
      "source": [
        "# Outer CV loop\n",
        "outer_cv = StratifiedKFold(n_splits=outer_k_folds, shuffle=True)\n",
        "outer_results = []\n",
        "best_models = []\n",
        "\n",
        "for outer_fold, (outer_train_idx, outer_test_idx) in enumerate(outer_cv.split(X_train_cnn, y_train)):\n",
        "    print(f\"\\n=== Outer Fold {outer_fold + 1}/{outer_k_folds} ===\")\n",
        "\n",
        "    X_outer_train, X_outer_test = X_train_cnn[outer_train_idx], X_train_cnn[outer_test_idx]\n",
        "    y_outer_train, y_outer_test = y_train[outer_train_idx], y_train[outer_test_idx]\n",
        "\n",
        "    # Inner CV loop for hyperparameter tuning\n",
        "    inner_cv = StratifiedKFold(n_splits=inner_k_folds, shuffle=True)\n",
        "    best_inner_score = -np.inf\n",
        "    best_params = None\n",
        "    best_model = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"\\nTesting parameters: {params}\")\n",
        "        inner_scores = []\n",
        "\n",
        "        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_cv.split(X_outer_train, y_outer_train)):\n",
        "            print(f\"-- Inner fold: {inner_fold+1}/{inner_k_folds}  --\")\n",
        "            X_inner_train, X_inner_val = X_outer_train[inner_train_idx], X_outer_train[inner_val_idx]\n",
        "            y_inner_train, y_inner_val = y_outer_train[inner_train_idx], y_outer_train[inner_val_idx]\n",
        "\n",
        "            model = create_cnn_model(dropout_rate=params['dropout_rate'], learning_rate=params['learning_rate'])\n",
        "\n",
        "            history = model.fit(\n",
        "                X_inner_train, y_inner_train,\n",
        "                epochs=epochs_cnn,\n",
        "                batch_size=params['batch_size'],\n",
        "                validation_data=(X_inner_val, y_inner_val),\n",
        "                callbacks=[EarlyStopping(monitor=monitor_callback_cnn, patience=patience_callback_cnn, restore_best_weights=True)],\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            _, val_accuracy = model.evaluate(X_inner_val, y_inner_val, verbose=0, batch_size=params['batch_size'])\n",
        "            inner_scores.append(val_accuracy)\n",
        "\n",
        "        mean_inner_score = np.mean(inner_scores)\n",
        "        print(f\"Mean validation accuracy for {params}: {mean_inner_score:.4f}\")\n",
        "\n",
        "        if mean_inner_score > best_inner_score:\n",
        "            best_inner_score = mean_inner_score\n",
        "            best_params = params\n",
        "            best_model = model\n",
        "\n",
        "    print(f\"Best parameters for outer fold {outer_fold + 1}: {best_params}\")\n",
        "    print(f\"Best inner validation accuracy: {best_inner_score:.4f}\")\n",
        "\n",
        "    # Re-train the best model on the entire outer training set with the best parameters\n",
        "    best_model = create_cnn_model(dropout_rate=best_params['dropout_rate'], learning_rate=best_params['learning_rate'])\n",
        "    best_model.fit(\n",
        "        X_outer_train, y_outer_train,\n",
        "        epochs=epochs_cnn,\n",
        "        batch_size=best_params['batch_size'],  # Use the best batch_size\n",
        "        callbacks=[EarlyStopping(monitor=monitor_callback_cnn, patience=patience_callback_cnn, restore_best_weights=True)],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluate on the outer test set\n",
        "    _, outer_test_accuracy = best_model.evaluate(X_outer_test, y_outer_test, verbose=0, batch_size=best_params['batch_size'])\n",
        "    print(f\"Outer Fold {outer_fold + 1} - Test Accuracy: {outer_test_accuracy:.4f}\")\n",
        "    outer_results.append(outer_test_accuracy)\n",
        "    best_models.append(best_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1122ed01",
      "metadata": {
        "id": "1122ed01"
      },
      "outputs": [],
      "source": [
        "#  Print outer CV results\n",
        "print(\"\\n--- Nested Cross-Validation Results ---\")\n",
        "for i, accuracy in enumerate(outer_results):\n",
        "    print(f\"Outer Fold {i + 1}: Test accuracy = {accuracy:.4f}\")\n",
        "\n",
        "mean_accuracy = np.mean(outer_results)\n",
        "std_accuracy = np.std(outer_results)\n",
        "print(f\"\\nMean Test Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e6502af",
      "metadata": {
        "id": "1e6502af"
      },
      "outputs": [],
      "source": [
        "# Evaluate the best models on the test set\n",
        "test_accuracies = []\n",
        "for i, model in enumerate(best_models):\n",
        "    _, test_accuracy = model.evaluate(X_test_cnn, y_test, verbose=0)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    print(f\"Model from outer fold {i + 1} - Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "mean_test_accuracy = np.mean(test_accuracies)\n",
        "std_test_accuracy = np.std(test_accuracies)\n",
        "print(f\"\\nMean Test Accuracy on holdout set: {mean_test_accuracy:.4f} (±{std_test_accuracy:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa844aba",
      "metadata": {
        "id": "fa844aba"
      },
      "outputs": [],
      "source": [
        "# Select the best model based on outer CV performance\n",
        "best_model_idx = np.argmax(outer_results)\n",
        "best_model = best_models[best_model_idx]\n",
        "print(f\"\\nBest model is from outer fold {best_model_idx + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a66056",
      "metadata": {
        "id": "21a66056"
      },
      "outputs": [],
      "source": [
        "# Evaluate the best model on the test set\n",
        "best_test_loss, best_test_accuracy = best_model.evaluate(X_test_cnn, y_test, verbose=0)\n",
        "print(f\"Best Model Test Accuracy: {best_test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b136119",
      "metadata": {
        "id": "3b136119"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c472e8c",
      "metadata": {
        "id": "2c472e8c"
      },
      "source": [
        "#### For the best fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec81e715",
      "metadata": {
        "id": "ec81e715"
      },
      "outputs": [],
      "source": [
        "# Plot training history for the best model\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(best_model.history.history['accuracy'], label='Train')\n",
        "plt.plot(best_model.history.history['val_accuracy'], label='Validation')\n",
        "plt.title('Best Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(best_model.history.history['loss'], label='Train')\n",
        "plt.plot(best_model.history.history['val_loss'], label='Validation')\n",
        "plt.title('Best Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4f8c5c",
      "metadata": {
        "id": "df4f8c5c"
      },
      "outputs": [],
      "source": [
        "# Predict classes using the best model\n",
        "y_pred = best_model.predict(X_test_cnn)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e32e8a8d",
      "metadata": {
        "id": "e32e8a8d"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix (Best Model)')\n",
        "plt.show()\n",
        "\n",
        "# Calculate Sensitivity (SEV) and Specificity (SPE) for each class\n",
        "for i in range(matrix.shape[0]):\n",
        "    tp = matrix[i, i]\n",
        "    fn = np.sum(matrix[i, :]) - tp\n",
        "    fp = np.sum(matrix[:, i]) - tp\n",
        "    tn = np.sum(matrix) - tp - fn - fp\n",
        "    f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0  # F1-score\n",
        "    sev = tp / (tp + fn) if (tp + fn) > 0 else 0  # Sensitivity (Recall)\n",
        "    spe = tn / (tn + fp) if (tn + fp) > 0 else 0  # Specificity\n",
        "    accuracy = (tn + tp) / (tp + fn + tn + fp)\n",
        "    print(f'Class {i}:')\n",
        "    print(f'  Sensitivity (SEV): {sev:.4f}')\n",
        "    print(f'  Specificity (SPE): {spe:.4f}')\n",
        "    print(f'  Accuracy: {accuracy:.4f}')\n",
        "    print(f'  F1-score: {f1:.4f}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2e37e24",
      "metadata": {
        "id": "e2e37e24"
      },
      "outputs": [],
      "source": [
        "# Binarize the output for ROC curve (one-vs-rest)\n",
        "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curves for each class\n",
        "plt.figure(figsize=(10, 8))\n",
        "colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label=f'ROC curve of class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Each Class (Best Model)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "a843acae"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}